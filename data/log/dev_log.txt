2019-04-21 21:04:43,600 - brc - INFO - ====== preprocessing ======
2019-04-21 21:04:43,600 - brc - INFO - Checking the data files...
2019-04-21 21:04:43,625 - brc - INFO - Preparing the directories...
2019-04-21 21:04:43,641 - brc - INFO - Building vocabulary...
2019-04-21 21:13:59,717 - brc - INFO - Train set size: 76052 questions.
2019-04-21 21:19:21,933 - brc - INFO - Dev set size: 5000 questions.
2019-04-21 21:28:37,136 - brc - INFO - Test set size: 30000 questions.
2019-04-21 21:31:52,146 - brc - INFO - After filter 198127 tokens, the final vocab size is 306851
2019-04-21 21:31:52,158 - brc - INFO - After filter 2335 chars, the final char vocab size is 10520
2019-04-21 21:31:52,158 - brc - INFO - Assigning embeddings...
2019-04-21 21:33:11,740 - brc - INFO - Saving vocab...
2019-04-21 21:33:12,746 - brc - INFO - ====== Done with preparing! ======
2019-04-21 21:36:23,840 - brc - INFO - ====== training ======
2019-04-21 21:36:23,840 - brc - INFO - Load data_set and vocab...
2019-04-21 21:45:48,037 - brc - INFO - Train set size: 76052 questions.
2019-04-21 21:51:51,523 - brc - INFO - Dev set size: 5000 questions.
2019-04-21 21:51:51,654 - brc - INFO - Converting text into ids...
2019-04-21 22:25:57,047 - brc - INFO - ====== training ======
2019-04-21 22:25:57,047 - brc - INFO - Load data_set and vocab...
2019-04-21 22:26:37,139 - brc - INFO - ====== training ======
2019-04-21 22:26:37,139 - brc - INFO - Load data_set and vocab...
2019-04-21 22:28:00,297 - brc - INFO - ====== training ======
2019-04-21 22:28:00,297 - brc - INFO - Load data_set and vocab...
2019-04-21 22:28:21,774 - brc - INFO - ====== training ======
2019-04-21 22:28:21,775 - brc - INFO - Load data_set and vocab...
2019-04-21 22:30:34,707 - brc - INFO - ====== training ======
2019-04-21 22:30:34,708 - brc - INFO - Load data_set and vocab...
2019-04-21 22:30:43,140 - brc - INFO - ====== training ======
2019-04-21 22:30:43,140 - brc - INFO - Load data_set and vocab...
2019-04-21 22:37:04,119 - brc - INFO - ====== training ======
2019-04-21 22:37:04,119 - brc - INFO - Load data_set and vocab...
2019-04-21 22:44:51,029 - brc - INFO - ====== preprocessing ======
2019-04-21 22:44:51,030 - brc - INFO - Checking the data files...
2019-04-21 22:44:51,119 - brc - INFO - Preparing the directories...
2019-04-21 22:44:51,121 - brc - INFO - Building vocabulary...
2019-04-21 22:55:31,515 - brc - INFO - Train set size: 76052 questions.
2019-04-21 23:01:46,155 - brc - INFO - Dev set size: 5000 questions.
2019-04-22 09:37:14,211 - brc - INFO - ====== preprocessing ======
2019-04-22 09:37:14,218 - brc - INFO - Checking the data files...
2019-04-22 09:37:14,236 - brc - INFO - Preparing the directories...
2019-04-22 09:37:14,236 - brc - INFO - Building vocabulary...
2019-04-22 09:47:25,836 - brc - INFO - Train set size: 76052 questions.
2019-04-22 09:53:12,146 - brc - INFO - Dev set size: 5000 questions.
2019-04-22 10:03:25,197 - brc - INFO - Test set size: 30000 questions.
2019-04-22 10:06:44,470 - brc - INFO - After filter 198127 tokens, the final vocab size is 306851
2019-04-22 10:06:44,481 - brc - INFO - After filter 2335 chars, the final char vocab size is 10520
2019-04-22 10:06:44,482 - brc - INFO - Assigning embeddings...
2019-04-22 10:08:08,125 - brc - INFO - Saving vocab...
2019-04-22 10:08:08,543 - brc - INFO - ====== Done with preparing! ======
2019-04-22 10:12:17,141 - brc - INFO - ====== training ======
2019-04-22 10:12:17,141 - brc - INFO - Load data_set and vocab...
2019-04-22 10:14:46,043 - brc - INFO - ====== training ======
2019-04-22 10:14:46,043 - brc - INFO - Load data_set and vocab...
2019-04-22 10:15:03,200 - brc - INFO - ====== training ======
2019-04-22 10:15:03,200 - brc - INFO - Load data_set and vocab...
2019-04-22 10:15:14,246 - brc - INFO - ====== training ======
2019-04-22 10:15:14,246 - brc - INFO - Load data_set and vocab...
2019-04-22 10:16:49,580 - brc - INFO - ====== training ======
2019-04-22 10:16:49,580 - brc - INFO - Load data_set and vocab...
2019-04-22 10:16:58,667 - brc - INFO - ====== training ======
2019-04-22 10:16:58,667 - brc - INFO - Load data_set and vocab...
2019-04-22 10:17:21,377 - brc - INFO - ====== training ======
2019-04-22 10:17:21,377 - brc - INFO - Load data_set and vocab...
2019-04-22 10:17:33,527 - brc - INFO - ====== training ======
2019-04-22 10:17:33,527 - brc - INFO - Load data_set and vocab...
2019-04-22 10:37:24,135 - brc - INFO - ====== preprocessing ======
2019-04-22 10:37:24,135 - brc - INFO - Checking the data files...
2019-04-22 10:37:24,229 - brc - INFO - Preparing the directories...
2019-04-22 10:37:24,232 - brc - INFO - Building vocabulary...
2019-04-22 10:46:52,152 - brc - INFO - Train set size: 76052 questions.
2019-04-22 10:53:04,834 - brc - INFO - Dev set size: 5000 questions.
2019-04-22 11:06:39,166 - brc - INFO - ====== preprocessing ======
2019-04-22 11:06:39,181 - brc - INFO - Checking the data files...
2019-04-22 11:06:39,207 - brc - INFO - Preparing the directories...
2019-04-22 11:06:39,208 - brc - INFO - Building vocabulary...
2019-04-22 11:16:17,300 - brc - INFO - Train set size: 76052 questions.
2019-04-22 11:19:21,591 - brc - INFO - After filter 198127 tokens, the final vocab size is 306851
2019-04-22 11:19:21,616 - brc - INFO - After filter 2335 chars, the final char vocab size is 10520
2019-04-22 11:19:21,616 - brc - INFO - Assigning embeddings...
2019-04-22 11:30:07,294 - brc - INFO - ====== preprocessing ======
2019-04-22 11:30:07,294 - brc - INFO - Checking the data files...
2019-04-22 11:30:07,321 - brc - INFO - Preparing the directories...
2019-04-22 11:30:07,321 - brc - INFO - Building vocabulary...
2019-04-22 11:40:22,789 - brc - INFO - Train set size: 76052 questions.
2019-04-22 11:43:56,226 - brc - INFO - After filter 198127 tokens, the final vocab size is 306851
2019-04-22 11:43:56,405 - brc - INFO - After filter 2335 chars, the final char vocab size is 10520
2019-04-22 11:43:56,405 - brc - INFO - Assigning embeddings...
2019-04-22 11:45:30,690 - brc - INFO - save word vocab size is 165142
2019-04-22 11:45:30,727 - brc - INFO - save char vocab size is 9398
2019-04-22 11:45:30,727 - brc - INFO - Saving vocab...
2019-04-22 11:45:37,398 - brc - INFO - ====== Done with preparing! ======
2019-04-22 12:14:44,585 - brc - INFO - ====== preprocessing ======
2019-04-22 12:14:44,585 - brc - INFO - Checking the data files...
2019-04-22 12:14:44,608 - brc - INFO - Preparing the directories...
2019-04-22 12:14:44,608 - brc - INFO - Building vocabulary...
2019-04-22 12:14:53,351 - brc - INFO - Dev set size: 5000 questions.
2019-04-22 12:15:57,758 - brc - INFO - Test set size: 30000 questions.
2019-04-22 12:15:57,862 - brc - INFO - After filter 0 tokens, the final vocab size is 2
2019-04-22 12:15:57,863 - brc - INFO - After filter 0 chars, the final char vocab size is 2
2019-04-22 12:15:57,863 - brc - INFO - Assigning embeddings...
2019-04-22 12:17:14,560 - brc - INFO - save word vocab size is 2
2019-04-22 12:17:14,560 - brc - INFO - save char vocab size is 2
2019-04-22 12:17:14,560 - brc - INFO - Saving vocab...
2019-04-22 12:17:14,707 - brc - INFO - ====== Done with preparing! ======
2019-04-22 12:21:14,989 - brc - INFO - ====== preprocessing ======
2019-04-22 12:21:14,989 - brc - INFO - Checking the data files...
2019-04-22 12:21:15,019 - brc - INFO - Preparing the directories...
2019-04-22 12:21:15,021 - brc - INFO - Building vocabulary...
2019-04-22 12:21:23,763 - brc - INFO - Dev set size: 5000 questions.
2019-04-22 12:22:28,004 - brc - INFO - Test set size: 30000 questions.
2019-04-22 12:22:28,053 - brc - INFO - After filter 0 tokens, the final vocab size is 2
2019-04-22 12:22:28,053 - brc - INFO - After filter 0 chars, the final char vocab size is 2
2019-04-22 12:22:28,053 - brc - INFO - Assigning embeddings...
2019-04-22 12:23:45,205 - brc - INFO - save word vocab size is 2
2019-04-22 12:23:45,206 - brc - INFO - save char vocab size is 2
2019-04-22 12:23:45,206 - brc - INFO - Saving vocab...
2019-04-22 12:23:45,425 - brc - INFO - ====== Done with preparing! ======
2019-04-22 12:26:18,646 - brc - INFO - ====== training ======
2019-04-22 12:26:18,647 - brc - INFO - Load data_set and vocab...
2019-04-22 12:42:12,297 - brc - INFO - Train set size: 83646 questions.
2019-04-22 12:42:20,648 - brc - INFO - Dev set size: 5000 questions.
2019-04-22 12:42:20,754 - brc - INFO - Converting text into ids...
2019-04-22 13:46:13,808 - brc - INFO - ====== training ======
2019-04-22 13:46:13,824 - brc - INFO - Load data_set and vocab...
2019-04-22 14:02:39,295 - brc - INFO - Train set size: 83646 questions.
2019-04-22 14:02:46,229 - brc - INFO - Dev set size: 5000 questions.
2019-04-22 14:02:46,230 - brc - INFO - Converting text into ids...
2019-04-22 15:15:48,196 - brc - INFO - ====== training ======
2019-04-22 15:15:48,196 - brc - INFO - Load data_set and vocab...
2019-04-22 15:32:36,409 - brc - INFO - Train set size: 83646 questions.
2019-04-22 15:32:44,626 - brc - INFO - Dev set size: 5000 questions.
2019-04-22 15:32:44,665 - brc - INFO - Converting text into ids...
2019-04-22 16:00:49,440 - brc - INFO - ====== training ======
2019-04-22 16:00:49,443 - brc - INFO - Load data_set and vocab...
2019-04-22 16:18:22,639 - brc - INFO - Train set size: 83646 questions.
2019-04-22 16:18:30,261 - brc - INFO - Dev set size: 5000 questions.
2019-04-22 16:18:30,266 - brc - INFO - Converting text into ids...
2019-04-22 16:54:54,234 - brc - INFO - ====== training ======
2019-04-22 16:54:54,234 - brc - INFO - Load data_set and vocab...
2019-04-22 17:11:16,525 - brc - INFO - Train set size: 83646 questions.
2019-04-22 17:11:25,391 - brc - INFO - Dev set size: 5000 questions.
2019-04-22 17:11:25,398 - brc - INFO - Converting text into ids...
2019-04-22 17:44:16,607 - brc - INFO - Initialize the model...
2019-04-22 17:52:24,497 - brc - INFO - ====== training ======
2019-04-22 17:52:24,501 - brc - INFO - Load data_set and vocab...
2019-04-22 18:09:32,559 - brc - INFO - Train set size: 83646 questions.
2019-04-22 18:09:39,782 - brc - INFO - Dev set size: 5000 questions.
2019-04-22 18:09:39,784 - brc - INFO - Converting text into ids...
2019-04-22 18:46:20,818 - brc - INFO - Initialize the model...
2019-04-22 20:24:39,499 - brc - INFO - ====== training ======
2019-04-22 20:24:39,499 - brc - INFO - Load data_set and vocab...
2019-04-22 20:42:33,887 - brc - INFO - Train set size: 83646 questions.
2019-04-22 20:42:41,680 - brc - INFO - Dev set size: 5000 questions.
2019-04-22 20:42:41,691 - brc - INFO - Converting text into ids...
2019-04-22 21:22:22,882 - brc - INFO - Initialize the model...
2019-04-22 21:50:22,276 - brc - INFO - ====== training ======
2019-04-22 21:50:22,279 - brc - INFO - Load data_set and vocab...
2019-04-22 21:50:28,353 - brc - INFO - Initialize the model...
2019-04-22 21:57:57,948 - brc - INFO - ====== training ======
2019-04-22 21:57:57,961 - brc - INFO - Load data_set and vocab...
2019-04-22 21:58:04,312 - brc - INFO - Initialize the model...
2019-04-22 22:08:03,854 - brc - INFO - ====== training ======
2019-04-22 22:08:03,854 - brc - INFO - Load data_set and vocab...
2019-04-22 22:08:04,489 - brc - INFO - Initialize the model...
2019-04-22 22:20:55,166 - brc - INFO - ====== training ======
2019-04-22 22:20:55,166 - brc - INFO - Load data_set and vocab...
2019-04-22 22:20:55,779 - brc - INFO - Initialize the model...
2019-04-22 22:23:55,838 - brc - INFO - ====== training ======
2019-04-22 22:23:55,838 - brc - INFO - Load data_set and vocab...
2019-04-22 22:23:56,513 - brc - INFO - Initialize the model...
2019-04-22 22:25:04,731 - brc - INFO - ====== training ======
2019-04-22 22:25:04,731 - brc - INFO - Load data_set and vocab...
2019-04-22 22:25:05,380 - brc - INFO - Initialize the model...
2019-04-22 22:32:13,345 - brc - INFO - ====== training ======
2019-04-22 22:32:13,345 - brc - INFO - Load data_set and vocab...
2019-04-22 22:32:13,997 - brc - INFO - Initialize the model...
2019-04-22 22:33:57,118 - brc - INFO - ====== training ======
2019-04-22 22:33:57,118 - brc - INFO - Load data_set and vocab...
2019-04-22 22:33:57,761 - brc - INFO - Initialize the model...
2019-04-22 22:37:21,858 - brc - INFO - ====== training ======
2019-04-22 22:37:21,858 - brc - INFO - Load data_set and vocab...
2019-04-22 22:37:22,522 - brc - INFO - Initialize the model...
2019-04-22 22:37:56,962 - brc - INFO - ====== training ======
2019-04-22 22:37:56,962 - brc - INFO - Load data_set and vocab...
2019-04-22 22:37:57,602 - brc - INFO - Initialize the model...
2019-04-22 22:39:47,586 - brc - INFO - ====== training ======
2019-04-22 22:39:47,587 - brc - INFO - Load data_set and vocab...
2019-04-22 22:39:48,242 - brc - INFO - Initialize the model...
2019-04-22 22:41:07,469 - brc - INFO - ====== training ======
2019-04-22 22:41:07,469 - brc - INFO - Load data_set and vocab...
2019-04-22 22:41:08,120 - brc - INFO - Initialize the model...
2019-04-22 22:43:04,864 - brc - INFO - ====== training ======
2019-04-22 22:43:04,864 - brc - INFO - Load data_set and vocab...
2019-04-22 22:43:05,558 - brc - INFO - Initialize the model...
2019-04-22 22:45:22,265 - brc - INFO - ====== training ======
2019-04-22 22:45:22,265 - brc - INFO - Load data_set and vocab...
2019-04-22 22:45:22,927 - brc - INFO - Initialize the model...
2019-04-22 22:46:45,256 - brc - INFO - ====== training ======
2019-04-22 22:46:45,256 - brc - INFO - Load data_set and vocab...
2019-04-22 22:46:45,932 - brc - INFO - Initialize the model...
2019-04-22 22:47:20,810 - brc - INFO - ====== training ======
2019-04-22 22:47:20,810 - brc - INFO - Load data_set and vocab...
2019-04-22 22:47:21,488 - brc - INFO - Initialize the model...
2019-04-23 09:20:04,115 - brc - INFO - ====== training ======
2019-04-23 09:20:04,126 - brc - INFO - Load data_set and vocab...
2019-04-23 09:20:10,420 - brc - INFO - Initialize the model...
2019-04-23 10:02:07,917 - brc - INFO - ====== training ======
2019-04-23 10:02:07,917 - brc - INFO - Load data_set and vocab...
2019-04-23 10:02:08,538 - brc - INFO - Initialize the model...
2019-04-23 10:12:07,151 - brc - INFO - ====== training ======
2019-04-23 10:12:07,151 - brc - INFO - Load data_set and vocab...
2019-04-23 10:12:07,776 - brc - INFO - Initialize the model...
2019-04-23 12:43:30,725 - brc - INFO - ====== training ======
2019-04-23 12:43:30,725 - brc - INFO - Load data_set and vocab...
2019-04-23 12:43:31,340 - brc - INFO - Initialize the model...
2019-04-23 12:44:16,509 - brc - INFO - ====== training ======
2019-04-23 12:44:16,509 - brc - INFO - Load data_set and vocab...
2019-04-23 12:44:17,142 - brc - INFO - Initialize the model...
2019-04-23 12:46:36,775 - brc - INFO - ====== training ======
2019-04-23 12:46:36,775 - brc - INFO - Load data_set and vocab...
2019-04-23 12:46:37,398 - brc - INFO - Initialize the model...
2019-04-23 18:38:59,820 - brc - INFO - ====== training ======
2019-04-23 18:38:59,840 - brc - INFO - Load data_set and vocab...
2019-04-23 18:39:06,207 - brc - INFO - Initialize the model...
2019-04-23 21:29:35,364 - brc - INFO - ====== training ======
2019-04-23 21:29:35,364 - brc - INFO - Load data_set and vocab...
2019-04-23 21:29:36,048 - brc - INFO - Initialize the model...
2019-04-23 21:30:51,670 - brc - INFO - ====== training ======
2019-04-23 21:30:51,670 - brc - INFO - Load data_set and vocab...
2019-04-23 21:30:52,282 - brc - INFO - Initialize the model...
2019-04-23 21:32:28,595 - brc - INFO - ====== training ======
2019-04-23 21:32:28,595 - brc - INFO - Load data_set and vocab...
2019-04-23 21:32:29,235 - brc - INFO - Initialize the model...
2019-04-23 21:33:05,474 - brc - INFO - ====== training ======
2019-04-23 21:33:05,474 - brc - INFO - Load data_set and vocab...
2019-04-23 21:33:06,092 - brc - INFO - Initialize the model...
2019-04-23 21:36:56,017 - brc - INFO - ====== training ======
2019-04-23 21:36:56,017 - brc - INFO - Load data_set and vocab...
2019-04-23 21:36:56,664 - brc - INFO - Initialize the model...
2019-04-23 21:39:15,744 - brc - INFO - ====== training ======
2019-04-23 21:39:15,744 - brc - INFO - Load data_set and vocab...
2019-04-23 21:39:16,384 - brc - INFO - Initialize the model...
2019-04-23 21:41:44,264 - brc - INFO - ====== training ======
2019-04-23 21:41:44,264 - brc - INFO - Load data_set and vocab...
2019-04-23 21:41:44,921 - brc - INFO - Initialize the model...
2019-04-23 21:42:53,001 - brc - INFO - ====== training ======
2019-04-23 21:42:53,001 - brc - INFO - Load data_set and vocab...
2019-04-23 21:42:53,642 - brc - INFO - Initialize the model...
2019-04-23 21:46:28,025 - brc - INFO - ====== training ======
2019-04-23 21:46:28,025 - brc - INFO - Load data_set and vocab...
2019-04-23 21:46:28,672 - brc - INFO - Initialize the model...
2019-04-23 21:58:39,998 - brc - INFO - ====== training ======
2019-04-23 21:58:39,998 - brc - INFO - Load data_set and vocab...
2019-04-23 21:58:40,670 - brc - INFO - Initialize the model...
2019-04-23 22:12:45,982 - brc - INFO - ====== training ======
2019-04-23 22:12:45,982 - brc - INFO - Load data_set and vocab...
2019-04-23 22:12:46,610 - brc - INFO - Initialize the model...
2019-04-23 22:21:10,666 - brc - INFO - ====== training ======
2019-04-23 22:21:10,666 - brc - INFO - Load data_set and vocab...
2019-04-23 22:21:11,277 - brc - INFO - Initialize the model...
2019-04-23 22:23:09,686 - brc - INFO - ====== training ======
2019-04-23 22:23:09,686 - brc - INFO - Load data_set and vocab...
2019-04-23 22:23:10,301 - brc - INFO - Initialize the model...
2019-04-23 22:26:43,765 - brc - INFO - ====== training ======
2019-04-23 22:26:43,765 - brc - INFO - Load data_set and vocab...
2019-04-23 22:26:44,369 - brc - INFO - Initialize the model...
2019-04-23 22:30:30,643 - brc - INFO - ====== training ======
2019-04-23 22:30:30,643 - brc - INFO - Load data_set and vocab...
2019-04-23 22:30:31,262 - brc - INFO - Initialize the model...
2019-04-23 22:54:48,816 - brc - INFO - ====== training ======
2019-04-23 22:54:48,816 - brc - INFO - Load data_set and vocab...
2019-04-23 22:54:49,446 - brc - INFO - Initialize the model...
2019-04-23 22:58:33,804 - brc - INFO - ====== training ======
2019-04-23 22:58:33,804 - brc - INFO - Load data_set and vocab...
2019-04-23 22:58:34,439 - brc - INFO - Initialize the model...
2019-04-23 22:59:55,937 - brc - INFO - ====== training ======
2019-04-23 22:59:55,937 - brc - INFO - Load data_set and vocab...
2019-04-23 22:59:56,581 - brc - INFO - Initialize the model...
2019-04-23 23:01:11,760 - brc - INFO - ====== training ======
2019-04-23 23:01:11,760 - brc - INFO - Load data_set and vocab...
2019-04-23 23:01:12,370 - brc - INFO - Initialize the model...
2019-04-23 23:02:30,343 - brc - INFO - ====== training ======
2019-04-23 23:02:30,343 - brc - INFO - Load data_set and vocab...
2019-04-23 23:02:30,955 - brc - INFO - Initialize the model...
2019-04-23 23:03:23,948 - brc - INFO - ====== training ======
2019-04-23 23:03:23,948 - brc - INFO - Load data_set and vocab...
2019-04-23 23:03:24,558 - brc - INFO - Initialize the model...
2019-04-24 09:10:38,836 - brc - INFO - ====== training ======
2019-04-24 09:10:38,847 - brc - INFO - Load data_set and vocab...
2019-04-24 09:10:45,439 - brc - INFO - Initialize the model...
2019-04-24 09:21:48,836 - brc - INFO - ====== training ======
2019-04-24 09:21:48,836 - brc - INFO - Load data_set and vocab...
2019-04-24 09:21:49,514 - brc - INFO - Initialize the model...
2019-04-24 09:22:27,704 - brc - INFO - ====== training ======
2019-04-24 09:22:27,704 - brc - INFO - Load data_set and vocab...
2019-04-24 09:22:28,402 - brc - INFO - Initialize the model...
2019-04-24 09:24:10,742 - brc - INFO - ====== training ======
2019-04-24 09:24:10,742 - brc - INFO - Load data_set and vocab...
2019-04-24 09:24:11,422 - brc - INFO - Initialize the model...
2019-04-25 16:19:17,200 - brc - INFO - ====== training ======
2019-04-25 16:19:17,208 - brc - INFO - Load data_set and vocab...
2019-04-25 16:19:24,007 - brc - INFO - Initialize the model...
2019-04-25 16:49:44,495 - brc - INFO - ====== training ======
2019-04-25 16:49:44,495 - brc - INFO - Load data_set and vocab...
2019-04-25 16:49:45,084 - brc - INFO - Initialize the model...
2019-04-27 17:30:07,570 - brc - INFO - ====== training ======
2019-04-27 17:30:07,583 - brc - INFO - Load data_set and vocab...
2019-04-27 17:30:14,179 - brc - INFO - Initialize the model...
2019-04-27 19:26:36,279 - brc - INFO - ====== training ======
2019-04-27 19:26:36,372 - brc - INFO - Load data_set and vocab...
2019-04-27 19:26:37,015 - brc - INFO - Initialize the model...
2019-04-27 19:27:40,309 - brc - INFO - ====== training ======
2019-04-27 19:27:40,309 - brc - INFO - Load data_set and vocab...
2019-04-27 19:27:40,928 - brc - INFO - Initialize the model...
2019-04-27 19:28:25,314 - brc - INFO - ====== training ======
2019-04-27 19:28:25,314 - brc - INFO - Load data_set and vocab...
2019-04-27 19:28:25,928 - brc - INFO - Initialize the model...
2019-04-27 20:47:00,887 - brc - INFO - ====== training ======
2019-04-27 20:47:00,887 - brc - INFO - Load data_set and vocab...
2019-04-27 20:47:01,505 - brc - INFO - Initialize the model...
2019-04-27 20:48:48,356 - brc - INFO - ====== training ======
2019-04-27 20:48:48,356 - brc - INFO - Load data_set and vocab...
2019-04-27 20:48:48,971 - brc - INFO - Initialize the model...
2019-04-28 09:35:58,691 - brc - INFO - ====== training ======
2019-04-28 09:35:58,707 - brc - INFO - Load data_set and vocab...
2019-04-28 09:36:05,667 - brc - INFO - Initialize the model...
2019-04-28 20:58:05,714 - brc - INFO - ====== training ======
2019-04-28 20:58:05,729 - brc - INFO - Load data_set and vocab...
2019-04-28 20:58:12,719 - brc - INFO - Initialize the model...
2019-04-28 20:59:41,172 - brc - INFO - ====== training ======
2019-04-28 20:59:41,172 - brc - INFO - Load data_set and vocab...
2019-04-28 20:59:41,779 - brc - INFO - Initialize the model...
2019-04-28 21:35:41,290 - brc - INFO - ====== training ======
2019-04-28 21:35:41,290 - brc - INFO - Load data_set and vocab...
2019-04-28 21:35:41,958 - brc - INFO - Initialize the model...
2019-04-28 21:37:10,603 - brc - INFO - ====== training ======
2019-04-28 21:37:10,603 - brc - INFO - Load data_set and vocab...
2019-04-28 21:37:11,240 - brc - INFO - Initialize the model...
2019-04-29 09:26:02,732 - brc - INFO - ====== training ======
2019-04-29 09:26:02,739 - brc - INFO - Load data_set and vocab...
2019-04-29 09:26:09,450 - brc - INFO - Initialize the model...
2019-04-29 09:31:17,968 - brc - INFO - ====== training ======
2019-04-29 09:31:17,968 - brc - INFO - Load data_set and vocab...
2019-04-29 09:31:18,587 - brc - INFO - Initialize the model...
2019-04-29 16:43:49,893 - brc - INFO - ====== training ======
2019-04-29 16:43:49,904 - brc - INFO - Load data_set and vocab...
2019-04-29 16:43:56,530 - brc - INFO - Initialize the model...
2019-04-29 21:44:29,756 - brc - INFO - ====== training ======
2019-04-29 21:44:29,756 - brc - INFO - Load data_set and vocab...
2019-04-29 21:44:30,373 - brc - INFO - Initialize the model...
2019-04-29 21:46:29,051 - brc - INFO - ====== training ======
2019-04-29 21:46:29,051 - brc - INFO - Load data_set and vocab...
2019-04-29 21:46:29,685 - brc - INFO - Initialize the model...
2019-04-29 21:47:46,836 - brc - INFO - ====== training ======
2019-04-29 21:47:46,836 - brc - INFO - Load data_set and vocab...
2019-04-29 21:47:47,448 - brc - INFO - Initialize the model...
2019-04-29 21:48:50,486 - brc - INFO - ====== training ======
2019-04-29 21:48:50,486 - brc - INFO - Load data_set and vocab...
2019-04-29 21:48:51,111 - brc - INFO - Initialize the model...
2019-04-29 22:00:46,405 - brc - INFO - ====== training ======
2019-04-29 22:00:46,405 - brc - INFO - Load data_set and vocab...
2019-04-29 22:00:47,027 - brc - INFO - Initialize the model...
2019-04-29 22:01:11,220 - brc - INFO - ====== training ======
2019-04-29 22:01:11,220 - brc - INFO - Load data_set and vocab...
2019-04-29 22:01:11,840 - brc - INFO - Initialize the model...
2019-04-29 22:02:44,231 - brc - INFO - ====== training ======
2019-04-29 22:02:44,231 - brc - INFO - Load data_set and vocab...
2019-04-29 22:02:44,855 - brc - INFO - Initialize the model...
2019-04-29 22:29:14,347 - brc - INFO - ====== training ======
2019-04-29 22:29:14,347 - brc - INFO - Load data_set and vocab...
2019-04-29 22:29:14,976 - brc - INFO - Initialize the model...
2019-04-30 10:11:22,229 - brc - INFO - ====== training ======
2019-04-30 10:11:22,241 - brc - INFO - Load data_set and vocab...
2019-04-30 10:11:28,893 - brc - INFO - Initialize the model...
2019-05-01 22:15:56,851 - brc - INFO - ====== training ======
2019-05-01 22:15:56,876 - brc - INFO - Load data_set and vocab...
2019-05-01 22:16:03,585 - brc - INFO - Initialize the model...
2019-05-09 15:33:15,417 - brc - INFO - ====== training ======
2019-05-09 15:33:15,417 - brc - INFO - Load data_set and vocab...
2019-05-09 15:34:17,337 - brc - INFO - ====== training ======
2019-05-09 15:34:17,337 - brc - INFO - Load data_set and vocab...
2019-05-09 15:38:38,880 - brc - INFO - ====== training ======
2019-05-09 15:38:38,880 - brc - INFO - Load data_set and vocab...
2019-05-09 15:49:06,466 - brc - INFO - ====== training ======
2019-05-09 15:49:06,466 - brc - INFO - Load data_set and vocab...
2019-05-09 15:49:07,185 - brc - INFO - Initialize the model...
2019-05-09 16:00:17,565 - brc - INFO - ====== training ======
2019-05-09 16:00:17,565 - brc - INFO - Load data_set and vocab...
2019-05-09 16:00:18,190 - brc - INFO - Initialize the model...
2019-05-09 16:04:27,285 - brc - INFO - ====== training ======
2019-05-09 16:04:27,285 - brc - INFO - Load data_set and vocab...
2019-05-09 16:04:27,903 - brc - INFO - Initialize the model...
2019-05-09 16:06:59,950 - brc - INFO - ====== training ======
2019-05-09 16:06:59,950 - brc - INFO - Load data_set and vocab...
2019-05-09 16:07:00,614 - brc - INFO - Initialize the model...
2019-05-09 16:07:23,615 - brc - INFO - ====== training ======
2019-05-09 16:07:23,615 - brc - INFO - Load data_set and vocab...
2019-05-09 16:07:24,252 - brc - INFO - Initialize the model...
2019-05-09 16:19:41,505 - brc - INFO - ====== training ======
2019-05-09 16:19:41,505 - brc - INFO - Load data_set and vocab...
2019-05-09 16:19:42,167 - brc - INFO - Initialize the model...
2019-05-09 16:22:37,640 - brc - INFO - ====== training ======
2019-05-09 16:22:37,640 - brc - INFO - Load data_set and vocab...
2019-05-09 16:22:38,266 - brc - INFO - Initialize the model...
2019-05-09 16:45:11,928 - brc - INFO - ====== training ======
2019-05-09 16:45:11,928 - brc - INFO - Load data_set and vocab...
2019-05-09 16:45:12,609 - brc - INFO - Initialize the model...
2019-05-09 16:46:46,690 - brc - INFO - ====== training ======
2019-05-09 16:46:46,691 - brc - INFO - Load data_set and vocab...
2019-05-09 16:46:47,319 - brc - INFO - Initialize the model...
2019-05-09 17:16:11,841 - brc - INFO - ====== training ======
2019-05-09 17:16:11,842 - brc - INFO - Load data_set and vocab...
2019-05-09 17:16:12,469 - brc - INFO - Initialize the model...
2019-05-09 17:23:48,907 - brc - INFO - ====== training ======
2019-05-09 17:23:48,907 - brc - INFO - Load data_set and vocab...
2019-05-09 17:23:49,559 - brc - INFO - Initialize the model...
2019-05-09 17:29:13,210 - brc - INFO - ====== training ======
2019-05-09 17:29:13,210 - brc - INFO - Load data_set and vocab...
2019-05-09 17:29:13,826 - brc - INFO - Initialize the model...
2019-05-09 20:49:45,527 - brc - INFO - ====== training ======
2019-05-09 20:49:45,532 - brc - INFO - Load data_set and vocab...
2019-05-09 20:49:52,523 - brc - INFO - Initialize the model...
2019-05-09 20:52:37,779 - brc - INFO - ====== training ======
2019-05-09 20:52:37,779 - brc - INFO - Load data_set and vocab...
2019-05-09 20:52:38,388 - brc - INFO - Initialize the model...
2019-05-09 20:54:43,358 - brc - INFO - ====== training ======
2019-05-09 20:54:43,358 - brc - INFO - Load data_set and vocab...
2019-05-09 20:54:43,968 - brc - INFO - Initialize the model...
2019-05-09 20:55:26,214 - brc - INFO - ====== training ======
2019-05-09 20:55:26,214 - brc - INFO - Load data_set and vocab...
2019-05-09 20:55:26,829 - brc - INFO - Initialize the model...
2019-05-09 20:56:03,186 - brc - INFO - ====== training ======
2019-05-09 20:56:03,186 - brc - INFO - Load data_set and vocab...
2019-05-09 20:56:03,786 - brc - INFO - Initialize the model...
2019-05-09 20:56:56,441 - brc - INFO - ====== training ======
2019-05-09 20:56:56,441 - brc - INFO - Load data_set and vocab...
2019-05-09 20:56:57,041 - brc - INFO - Initialize the model...
2019-05-09 21:00:57,105 - brc - INFO - ====== training ======
2019-05-09 21:00:57,105 - brc - INFO - Load data_set and vocab...
2019-05-09 21:00:57,718 - brc - INFO - Initialize the model...
2019-05-09 21:01:52,994 - brc - INFO - ====== training ======
2019-05-09 21:01:52,994 - brc - INFO - Load data_set and vocab...
2019-05-09 21:01:53,596 - brc - INFO - Initialize the model...
2019-05-09 21:03:24,795 - brc - INFO - ====== training ======
2019-05-09 21:03:24,795 - brc - INFO - Load data_set and vocab...
2019-05-09 21:03:25,404 - brc - INFO - Initialize the model...
2019-05-09 21:04:10,605 - brc - INFO - ====== training ======
2019-05-09 21:04:10,605 - brc - INFO - Load data_set and vocab...
2019-05-09 21:04:11,228 - brc - INFO - Initialize the model...
2019-05-09 21:08:36,384 - brc - INFO - ====== training ======
2019-05-09 21:08:36,384 - brc - INFO - Load data_set and vocab...
2019-05-09 21:08:36,985 - brc - INFO - Initialize the model...
2019-05-09 21:09:15,416 - brc - INFO - ====== training ======
2019-05-09 21:09:15,416 - brc - INFO - Load data_set and vocab...
2019-05-09 21:09:16,056 - brc - INFO - Initialize the model...
2019-05-10 10:03:34,311 - brc - INFO - ====== training ======
2019-05-10 10:03:34,316 - brc - INFO - Load data_set and vocab...
2019-05-10 10:03:41,184 - brc - INFO - Initialize the model...
2019-05-10 10:05:35,658 - brc - INFO - ====== training ======
2019-05-10 10:05:35,659 - brc - INFO - Load data_set and vocab...
2019-05-10 10:05:36,292 - brc - INFO - Initialize the model...
2019-05-11 19:21:33,658 - brc - INFO - ====== training ======
2019-05-11 19:21:33,673 - brc - INFO - Load data_set and vocab...
2019-05-11 19:21:40,375 - brc - INFO - Initialize the model...
2019-05-13 21:47:20,977 - brc - INFO - ====== training ======
2019-05-13 21:47:20,995 - brc - INFO - Load data_set and vocab...
2019-05-13 21:47:27,790 - brc - INFO - Initialize the model...
2019-05-17 19:09:49,625 - brc - INFO - ====== training ======
2019-05-17 19:09:49,638 - brc - INFO - Load data_set and vocab...
2019-05-17 19:09:56,586 - brc - INFO - Initialize the model...
2019-05-17 21:03:42,562 - brc - INFO - ====== training ======
2019-05-17 21:03:42,562 - brc - INFO - Load data_set and vocab...
2019-05-17 21:03:43,156 - brc - INFO - Initialize the model...
2019-05-17 21:06:00,530 - brc - INFO - ====== training ======
2019-05-17 21:06:00,531 - brc - INFO - Load data_set and vocab...
2019-05-17 21:06:01,330 - brc - INFO - Initialize the model...
2019-05-17 21:06:05,902 - brc - INFO - applying optimize adam
2019-05-17 21:06:09,330 - brc - INFO - Time to build graph: 7.164802074432373 s
2019-05-17 21:52:02,460 - brc - INFO - ====== training ======
2019-05-17 21:52:02,461 - brc - INFO - Load data_set and vocab...
2019-05-17 21:52:03,066 - brc - INFO - Initialize the model...
2019-05-17 21:52:07,115 - brc - INFO - applying optimize adam
2019-05-17 21:52:09,867 - brc - INFO - Time to build graph: 6.134588241577148 s
2019-05-17 21:52:27,836 - brc - INFO - Training the model...
2019-05-17 21:52:27,836 - brc - INFO - ====== Done with model training! ======
2019-05-17 21:59:16,453 - brc - INFO - ====== training ======
2019-05-17 21:59:16,453 - brc - INFO - Load data_set and vocab...
2019-05-17 22:13:42,146 - brc - INFO - Train set size: 83646 questions.
2019-05-17 22:20:31,689 - brc - INFO - Dev set size: 5000 questions.
2019-05-17 22:20:31,833 - brc - INFO - Converting text into ids...
2019-05-18 09:50:37,227 - brc - INFO - ====== training ======
2019-05-18 09:50:37,246 - brc - INFO - Load data_set and vocab...
2019-05-18 10:05:08,957 - brc - INFO - Train set size: 83646 questions.
2019-05-18 10:12:50,566 - brc - INFO - Dev set size: 5000 questions.
2019-05-18 10:12:50,591 - brc - INFO - Converting text into ids...
2019-05-18 11:02:01,308 - brc - INFO - Initialize the model...
2019-05-18 11:02:33,347 - brc - INFO - applying optimize adam
2019-05-18 11:02:36,591 - brc - INFO - Time to build graph: 17.59138774871826 s
2019-05-18 11:03:03,615 - brc - INFO - Training the model...
2019-05-18 11:07:17,511 - brc - INFO - ====== training ======
2019-05-18 11:07:17,511 - brc - INFO - Load data_set and vocab...
2019-05-18 11:24:18,628 - brc - INFO - Train set size: 83646 questions.
2019-05-18 11:33:33,044 - brc - INFO - Dev set size: 5000 questions.
2019-05-18 11:33:33,097 - brc - INFO - Converting text into ids...
2019-05-18 12:24:23,348 - brc - INFO - Initialize the model...
2019-05-18 12:24:45,634 - brc - INFO - applying optimize adam
2019-05-18 12:24:48,768 - brc - INFO - Time to build graph: 11.033224821090698 s
2019-05-18 12:25:06,568 - brc - INFO - Training the model...
2019-05-18 12:38:12,244 - brc - INFO - ====== training ======
2019-05-18 12:38:12,255 - brc - INFO - Load data_set and vocab...
2019-05-18 12:51:53,568 - brc - INFO - Train set size: 83646 questions.
2019-05-18 12:58:53,094 - brc - INFO - Dev set size: 5000 questions.
2019-05-18 12:58:53,512 - brc - INFO - Converting text into ids...
2019-05-18 13:36:30,261 - brc - INFO - Initialize the model...
2019-05-18 13:36:54,876 - brc - INFO - applying optimize adam
2019-05-18 13:36:57,934 - brc - INFO - Time to build graph: 12.497806549072266 s
2019-05-18 13:37:22,837 - brc - INFO - Training the model...
2019-05-18 13:37:22,904 - brc - INFO - Training the model for epoch 1
2019-05-18 14:08:22,059 - brc - INFO - ====== training ======
2019-05-18 14:08:22,059 - brc - INFO - Load data_set and vocab...
2019-05-18 14:25:27,294 - brc - INFO - Train set size: 83646 questions.
2019-05-18 14:34:38,977 - brc - INFO - Dev set size: 5000 questions.
2019-05-18 14:34:39,151 - brc - INFO - Converting text into ids...
2019-05-18 15:32:23,032 - brc - INFO - ====== training ======
2019-05-18 15:32:23,032 - brc - INFO - Load data_set and vocab...
2019-05-18 15:46:33,791 - brc - INFO - Train set size: 83646 questions.
2019-05-18 15:53:03,231 - brc - INFO - Dev set size: 5000 questions.
2019-05-18 15:53:03,262 - brc - INFO - Converting text into ids...
2019-05-18 16:31:04,299 - brc - INFO - Initialize the model...
2019-05-18 16:31:30,786 - brc - INFO - applying optimize adam
2019-05-18 16:31:33,546 - brc - INFO - Time to build graph: 13.063213109970093 s
2019-05-18 16:32:02,470 - brc - INFO - Training the model...
2019-05-18 16:32:02,550 - brc - INFO - Training the model for epoch 1
2019-05-18 16:53:27,019 - brc - INFO - ====== training ======
2019-05-18 16:53:27,058 - brc - INFO - Load data_set and vocab...
2019-05-18 17:08:30,590 - brc - INFO - Train set size: 83646 questions.
2019-05-18 17:16:16,337 - brc - INFO - Dev set size: 5000 questions.
2019-05-18 17:16:16,367 - brc - INFO - Converting text into ids...
2019-05-18 18:02:05,424 - brc - INFO - Initialize the model...
2019-05-18 18:02:40,023 - brc - INFO - applying optimize adam
2019-05-18 18:02:42,744 - brc - INFO - Time to build graph: 9.847298383712769 s
2019-05-18 18:03:03,416 - brc - INFO - Training the model...
2019-05-18 18:03:03,426 - brc - INFO - Training the model for epoch 1
2019-05-18 18:34:53,777 - brc - INFO - ====== training ======
2019-05-18 18:34:53,789 - brc - INFO - Load data_set and vocab...
2019-05-18 18:48:48,892 - brc - INFO - Train set size: 83646 questions.
2019-05-18 18:55:23,160 - brc - INFO - Dev set size: 5000 questions.
2019-05-18 18:55:23,256 - brc - INFO - Converting text into ids...
2019-05-18 19:34:35,357 - brc - INFO - Initialize the model...
2019-05-18 19:34:59,818 - brc - INFO - applying optimize adam
2019-05-18 19:35:02,507 - brc - INFO - Time to build graph: 12.143243074417114 s
2019-05-18 19:35:31,942 - brc - INFO - Training the model...
2019-05-18 19:35:31,985 - brc - INFO - Training the model for epoch 1
2019-05-18 19:51:36,624 - brc - INFO - ====== training ======
2019-05-18 19:51:36,624 - brc - INFO - Load data_set and vocab...
2019-05-18 20:08:19,934 - brc - INFO - Train set size: 83646 questions.
2019-05-18 20:16:41,570 - brc - INFO - Dev set size: 5000 questions.
2019-05-18 20:16:41,718 - brc - INFO - Converting text into ids...
2019-05-18 21:03:11,438 - brc - INFO - Initialize the model...
2019-05-18 21:03:38,081 - brc - INFO - applying optimize adam
2019-05-18 21:03:40,819 - brc - INFO - Time to build graph: 13.981340169906616 s
2019-05-18 21:04:15,870 - brc - INFO - Training the model...
2019-05-18 21:04:15,924 - brc - INFO - Training the model for epoch 1
2019-05-18 21:16:09,997 - brc - INFO - ====== training ======
2019-05-18 21:16:09,997 - brc - INFO - Load data_set and vocab...
2019-05-18 21:32:06,084 - brc - INFO - Train set size: 83646 questions.
2019-05-18 21:40:20,661 - brc - INFO - Dev set size: 5000 questions.
2019-05-18 21:40:20,721 - brc - INFO - Converting text into ids...
2019-05-18 22:26:40,695 - brc - INFO - Initialize the model...
2019-05-18 22:27:07,868 - brc - INFO - applying optimize adam
2019-05-18 22:27:10,743 - brc - INFO - Time to build graph: 11.87124228477478 s
2019-05-18 22:27:48,563 - brc - INFO - Training the model...
2019-05-18 22:27:48,708 - brc - INFO - Training the model for epoch 1
2019-05-18 22:54:05,424 - brc - INFO - ====== training ======
2019-05-18 22:54:05,424 - brc - INFO - Load data_set and vocab...
2019-05-18 22:54:20,985 - brc - INFO - Dev set size: 5000 questions.
2019-05-18 22:54:20,986 - brc - INFO - Converting text into ids...
2019-05-18 22:54:27,975 - brc - INFO - Initialize the model...
2019-05-18 22:54:43,719 - brc - INFO - applying optimize adam
2019-05-18 22:54:46,446 - brc - INFO - Time to build graph: 6.4021992683410645 s
2019-05-18 22:54:57,376 - brc - INFO - Training the model...
2019-05-18 22:54:57,377 - brc - INFO - Training the model for epoch 1
2019-05-18 22:58:37,562 - brc - INFO - ====== training ======
2019-05-18 22:58:37,562 - brc - INFO - Load data_set and vocab...
2019-05-18 22:58:43,443 - brc - INFO - Train set size: 4353 questions.
2019-05-18 22:58:43,443 - brc - INFO - Converting text into ids...
2019-05-18 22:58:50,054 - brc - INFO - Initialize the model...
2019-05-18 22:58:53,716 - brc - INFO - applying optimize adam
2019-05-18 22:58:56,075 - brc - INFO - Time to build graph: 5.377651691436768 s
2019-05-18 22:59:06,248 - brc - INFO - Training the model...
2019-05-18 22:59:06,248 - brc - INFO - Training the model for epoch 1
2019-05-18 23:02:49,254 - brc - INFO - ====== training ======
2019-05-18 23:02:49,254 - brc - INFO - Load data_set and vocab...
2019-05-18 23:02:55,211 - brc - INFO - Train set size: 4353 questions.
2019-05-18 23:02:55,211 - brc - INFO - Converting text into ids...
2019-05-18 23:03:01,793 - brc - INFO - Initialize the model...
2019-05-18 23:03:05,496 - brc - INFO - applying optimize adam
2019-05-18 23:03:07,900 - brc - INFO - Time to build graph: 5.45740532875061 s
2019-05-18 23:03:17,923 - brc - INFO - Training the model...
2019-05-18 23:03:17,923 - brc - INFO - Training the model for epoch 1
2019-05-18 23:04:32,216 - brc - INFO - ====== training ======
2019-05-18 23:04:32,216 - brc - INFO - Load data_set and vocab...
2019-05-18 23:04:38,128 - brc - INFO - Train set size: 4353 questions.
2019-05-18 23:04:38,128 - brc - INFO - Converting text into ids...
2019-05-18 23:04:44,751 - brc - INFO - Initialize the model...
2019-05-18 23:04:48,420 - brc - INFO - applying optimize adam
2019-05-18 23:04:50,807 - brc - INFO - Time to build graph: 5.415517330169678 s
2019-05-18 23:05:00,893 - brc - INFO - Training the model...
2019-05-18 23:05:00,893 - brc - INFO - Training the model for epoch 1
2019-05-18 23:24:02,458 - brc - INFO - ====== training ======
2019-05-18 23:24:02,459 - brc - INFO - Load data_set and vocab...
2019-05-18 23:24:08,376 - brc - INFO - Train set size: 4353 questions.
2019-05-18 23:24:08,376 - brc - INFO - Converting text into ids...
2019-05-18 23:24:15,071 - brc - INFO - Initialize the model...
2019-05-18 23:24:18,749 - brc - INFO - applying optimize adam
2019-05-18 23:24:21,119 - brc - INFO - Time to build graph: 5.4015562534332275 s
2019-05-18 23:24:31,090 - brc - INFO - Training the model...
2019-05-18 23:24:31,090 - brc - INFO - Training the model for epoch 1
2019-05-18 23:32:27,028 - brc - INFO - ====== training ======
2019-05-18 23:32:27,028 - brc - INFO - Load data_set and vocab...
2019-05-18 23:32:32,931 - brc - INFO - Train set size: 4353 questions.
2019-05-18 23:32:32,931 - brc - INFO - Converting text into ids...
2019-05-18 23:32:39,561 - brc - INFO - Initialize the model...
2019-05-18 23:42:46,887 - brc - INFO - ====== training ======
2019-05-18 23:42:46,887 - brc - INFO - Load data_set and vocab...
2019-05-18 23:43:01,384 - brc - INFO - Train set size: 4353 questions.
2019-05-18 23:43:01,385 - brc - INFO - Converting text into ids...
2019-05-18 23:43:18,271 - brc - INFO - Initialize the model...
2019-05-18 23:48:53,660 - brc - INFO - ====== training ======
2019-05-18 23:48:53,660 - brc - INFO - Load data_set and vocab...
2019-05-18 23:49:08,105 - brc - INFO - Train set size: 4353 questions.
2019-05-18 23:49:08,105 - brc - INFO - Converting text into ids...
2019-05-18 23:49:25,088 - brc - INFO - Initialize the model...
2019-05-19 09:20:25,529 - brc - INFO - ====== training ======
2019-05-19 09:20:25,547 - brc - INFO - Load data_set and vocab...
2019-05-19 09:20:38,801 - brc - INFO - Train set size: 4353 questions.
2019-05-19 09:20:38,801 - brc - INFO - Converting text into ids...
2019-05-19 09:20:45,458 - brc - INFO - Initialize the model...
2019-05-19 09:22:26,043 - brc - INFO - ====== training ======
2019-05-19 09:22:26,043 - brc - INFO - Load data_set and vocab...
2019-05-19 09:22:31,973 - brc - INFO - Train set size: 4353 questions.
2019-05-19 09:22:31,973 - brc - INFO - Converting text into ids...
2019-05-19 09:22:38,592 - brc - INFO - Initialize the model...
2019-05-19 09:22:42,308 - brc - INFO - applying optimize adam
2019-05-19 09:22:45,038 - brc - INFO - Time to build graph: 5.788787364959717 s
2019-05-19 09:23:03,284 - brc - INFO - Training the model...
2019-05-19 09:23:03,285 - brc - INFO - Training the model for epoch 1
2019-05-19 09:25:48,432 - brc - INFO - ====== training ======
2019-05-19 09:25:48,432 - brc - INFO - Load data_set and vocab...
2019-05-19 09:25:54,435 - brc - INFO - Train set size: 4353 questions.
2019-05-19 09:25:54,435 - brc - INFO - Converting text into ids...
2019-05-19 09:26:01,128 - brc - INFO - Initialize the model...
2019-05-19 09:26:04,813 - brc - INFO - applying optimize adam
2019-05-19 09:26:07,299 - brc - INFO - Time to build graph: 5.522232532501221 s
2019-05-19 09:26:17,367 - brc - INFO - Training the model...
2019-05-19 09:26:17,368 - brc - INFO - Training the model for epoch 1
2019-05-19 09:38:40,553 - brc - INFO - ====== training ======
2019-05-19 09:38:40,553 - brc - INFO - Load data_set and vocab...
2019-05-19 09:38:46,510 - brc - INFO - Train set size: 4353 questions.
2019-05-19 09:38:46,510 - brc - INFO - Converting text into ids...
2019-05-19 09:38:53,152 - brc - INFO - Initialize the model...
2019-05-19 09:38:56,820 - brc - INFO - applying optimize adam
2019-05-19 09:38:59,238 - brc - INFO - Time to build graph: 5.437489986419678 s
2019-05-19 09:39:09,896 - brc - INFO - Training the model...
2019-05-19 09:39:09,896 - brc - INFO - Training the model for epoch 1
2019-05-19 09:42:03,496 - brc - INFO - ====== training ======
2019-05-19 09:42:03,496 - brc - INFO - Load data_set and vocab...
2019-05-19 09:42:09,458 - brc - INFO - Train set size: 4353 questions.
2019-05-19 09:42:09,458 - brc - INFO - Converting text into ids...
2019-05-19 09:42:16,074 - brc - INFO - Initialize the model...
2019-05-19 09:42:19,737 - brc - INFO - applying optimize adam
2019-05-19 09:42:22,249 - brc - INFO - Time to build graph: 5.534200668334961 s
2019-05-19 09:42:32,486 - brc - INFO - Training the model...
2019-05-19 09:42:32,487 - brc - INFO - Training the model for epoch 1
2019-05-19 09:50:34,818 - brc - INFO - ====== training ======
2019-05-19 09:50:34,818 - brc - INFO - Load data_set and vocab...
2019-05-19 09:50:40,753 - brc - INFO - Train set size: 4353 questions.
2019-05-19 09:50:40,753 - brc - INFO - Converting text into ids...
2019-05-19 09:50:47,327 - brc - INFO - Initialize the model...
2019-05-19 09:50:50,980 - brc - INFO - applying optimize adam
2019-05-19 09:50:53,390 - brc - INFO - Time to build graph: 5.411559581756592 s
2019-05-19 09:51:03,488 - brc - INFO - Training the model...
2019-05-19 09:51:03,488 - brc - INFO - Training the model for epoch 1
2019-05-19 09:56:31,622 - brc - INFO - ====== training ======
2019-05-19 09:56:31,622 - brc - INFO - Load data_set and vocab...
2019-05-19 09:56:37,569 - brc - INFO - Train set size: 4353 questions.
2019-05-19 09:56:37,569 - brc - INFO - Converting text into ids...
2019-05-19 09:56:44,175 - brc - INFO - Initialize the model...
2019-05-19 10:07:57,180 - brc - INFO - ====== training ======
2019-05-19 10:07:57,180 - brc - INFO - Load data_set and vocab...
2019-05-19 10:08:03,240 - brc - INFO - Train set size: 4353 questions.
2019-05-19 10:08:03,241 - brc - INFO - Converting text into ids...
2019-05-19 10:08:10,094 - brc - INFO - Initialize the model...
2019-05-19 16:28:39,403 - brc - INFO - ====== training ======
2019-05-19 16:28:39,403 - brc - INFO - Load data_set and vocab...
2019-05-19 16:28:45,325 - brc - INFO - Train set size: 4353 questions.
2019-05-19 16:28:45,325 - brc - INFO - Converting text into ids...
2019-05-19 16:28:51,937 - brc - INFO - Initialize the model...
2019-05-19 16:30:21,022 - brc - INFO - ====== training ======
2019-05-19 16:30:21,022 - brc - INFO - Load data_set and vocab...
2019-05-19 16:30:26,991 - brc - INFO - Train set size: 4353 questions.
2019-05-19 16:30:26,991 - brc - INFO - Converting text into ids...
2019-05-19 16:30:33,723 - brc - INFO - Initialize the model...
2019-05-19 16:42:58,707 - brc - INFO - ====== training ======
2019-05-19 16:42:58,707 - brc - INFO - Load data_set and vocab...
2019-05-19 16:43:04,699 - brc - INFO - Train set size: 4353 questions.
2019-05-19 16:43:04,699 - brc - INFO - Converting text into ids...
2019-05-19 16:43:11,440 - brc - INFO - Initialize the model...
2019-05-19 16:44:30,404 - brc - INFO - ====== training ======
2019-05-19 16:44:30,404 - brc - INFO - Load data_set and vocab...
2019-05-19 16:44:36,369 - brc - INFO - Train set size: 4353 questions.
2019-05-19 16:44:36,369 - brc - INFO - Converting text into ids...
2019-05-19 16:44:42,992 - brc - INFO - Initialize the model...
2019-05-19 16:44:46,749 - brc - INFO - applying optimize adam
2019-05-19 16:44:49,146 - brc - INFO - Time to build graph: 5.509268045425415 s
2019-05-19 16:44:59,381 - brc - INFO - Training the model...
2019-05-19 16:44:59,381 - brc - INFO - Training the model for epoch 1
2019-05-19 16:57:03,133 - brc - INFO - ====== training ======
2019-05-19 16:57:03,134 - brc - INFO - Load data_set and vocab...
2019-05-19 16:57:16,736 - brc - INFO - Train set size: 4353 questions.
2019-05-19 16:57:16,736 - brc - INFO - Converting text into ids...
2019-05-19 16:57:23,407 - brc - INFO - Initialize the model...
2019-05-19 16:57:27,530 - brc - INFO - applying optimize adam
2019-05-19 16:57:30,163 - brc - INFO - Time to build graph: 6.097811460494995 s
2019-05-19 16:57:46,928 - brc - INFO - Training the model...
2019-05-19 16:57:46,928 - brc - INFO - Training the model for epoch 1
2019-05-19 17:04:28,122 - brc - INFO - ====== training ======
2019-05-19 17:04:28,123 - brc - INFO - Load data_set and vocab...
2019-05-19 17:04:41,542 - brc - INFO - Train set size: 4353 questions.
2019-05-19 17:04:41,542 - brc - INFO - Converting text into ids...
2019-05-19 17:04:48,209 - brc - INFO - Initialize the model...
2019-05-19 17:05:04,403 - brc - INFO - applying optimize adam
2019-05-19 17:05:06,981 - brc - INFO - Time to build graph: 5.9366455078125 s
2019-05-19 17:05:23,669 - brc - INFO - Training the model...
2019-05-19 17:05:23,670 - brc - INFO - Training the model for epoch 1
2019-05-19 17:09:43,506 - brc - INFO - ====== training ======
2019-05-19 17:09:43,506 - brc - INFO - Load data_set and vocab...
2019-05-19 17:09:56,412 - brc - INFO - Train set size: 4353 questions.
2019-05-19 17:09:56,412 - brc - INFO - Converting text into ids...
2019-05-19 17:10:03,150 - brc - INFO - Initialize the model...
2019-05-19 17:10:06,822 - brc - INFO - applying optimize adam
2019-05-19 17:10:09,244 - brc - INFO - Time to build graph: 5.4544150829315186 s
2019-05-19 17:10:19,267 - brc - INFO - Training the model...
2019-05-19 17:10:19,267 - brc - INFO - Training the model for epoch 1
2019-05-19 17:18:54,924 - brc - INFO - ====== training ======
2019-05-19 17:18:54,924 - brc - INFO - Load data_set and vocab...
2019-05-19 17:19:00,833 - brc - INFO - Train set size: 4353 questions.
2019-05-19 17:19:00,833 - brc - INFO - Converting text into ids...
2019-05-19 17:19:07,560 - brc - INFO - Initialize the model...
2019-05-19 17:20:18,854 - brc - INFO - ====== training ======
2019-05-19 17:20:18,854 - brc - INFO - Load data_set and vocab...
2019-05-19 17:20:24,889 - brc - INFO - Train set size: 4353 questions.
2019-05-19 17:20:24,889 - brc - INFO - Converting text into ids...
2019-05-19 17:20:31,517 - brc - INFO - Initialize the model...
2019-05-19 17:21:36,858 - brc - INFO - ====== training ======
2019-05-19 17:21:36,858 - brc - INFO - Load data_set and vocab...
2019-05-19 17:21:42,896 - brc - INFO - Train set size: 4353 questions.
2019-05-19 17:21:42,896 - brc - INFO - Converting text into ids...
2019-05-19 17:21:49,761 - brc - INFO - Initialize the model...
2019-05-19 17:26:34,469 - brc - INFO - ====== training ======
2019-05-19 17:26:34,469 - brc - INFO - Load data_set and vocab...
2019-05-19 17:26:40,484 - brc - INFO - Train set size: 4353 questions.
2019-05-19 17:26:40,484 - brc - INFO - Converting text into ids...
2019-05-19 17:26:47,102 - brc - INFO - Initialize the model...
2019-05-19 17:39:55,986 - brc - INFO - ====== training ======
2019-05-19 17:39:55,986 - brc - INFO - Load data_set and vocab...
2019-05-19 17:40:01,922 - brc - INFO - Train set size: 4353 questions.
2019-05-19 17:40:01,923 - brc - INFO - Converting text into ids...
2019-05-19 17:40:08,561 - brc - INFO - Initialize the model...
2019-05-19 18:57:22,333 - brc - INFO - ====== training ======
2019-05-19 18:57:22,333 - brc - INFO - Load data_set and vocab...
2019-05-19 18:57:28,266 - brc - INFO - Train set size: 4353 questions.
2019-05-19 18:57:28,267 - brc - INFO - Converting text into ids...
2019-05-19 18:57:34,915 - brc - INFO - Initialize the model...
2019-05-19 19:02:46,898 - brc - INFO - ====== training ======
2019-05-19 19:02:46,898 - brc - INFO - Load data_set and vocab...
2019-05-19 19:02:52,867 - brc - INFO - Train set size: 4353 questions.
2019-05-19 19:02:52,868 - brc - INFO - Converting text into ids...
2019-05-19 19:02:59,469 - brc - INFO - Initialize the model...
2019-05-19 20:08:08,976 - brc - INFO - ====== training ======
2019-05-19 20:08:08,977 - brc - INFO - Load data_set and vocab...
2019-05-19 20:08:14,961 - brc - INFO - Train set size: 4353 questions.
2019-05-19 20:08:14,961 - brc - INFO - Converting text into ids...
2019-05-19 20:08:21,591 - brc - INFO - Initialize the model...
2019-05-19 20:08:25,312 - brc - INFO - applying optimize adam
2019-05-19 20:08:27,696 - brc - INFO - Time to build graph: 5.44247579574585 s
2019-05-19 20:08:37,930 - brc - INFO - Training the model...
2019-05-19 20:08:37,930 - brc - INFO - Training the model for epoch 1
2019-05-19 20:10:09,855 - brc - INFO - ====== training ======
2019-05-19 20:10:09,856 - brc - INFO - Load data_set and vocab...
2019-05-19 20:10:15,933 - brc - INFO - Train set size: 4353 questions.
2019-05-19 20:10:15,933 - brc - INFO - Converting text into ids...
2019-05-19 20:10:22,598 - brc - INFO - Initialize the model...
2019-05-19 20:10:26,316 - brc - INFO - applying optimize adam
2019-05-19 20:10:28,715 - brc - INFO - Time to build graph: 5.474361181259155 s
2019-05-19 20:10:38,828 - brc - INFO - Training the model...
2019-05-19 20:10:38,829 - brc - INFO - Training the model for epoch 1
2019-05-19 20:11:09,740 - brc - INFO - ====== training ======
2019-05-19 20:11:09,740 - brc - INFO - Load data_set and vocab...
2019-05-19 20:11:15,820 - brc - INFO - Train set size: 4353 questions.
2019-05-19 20:11:15,820 - brc - INFO - Converting text into ids...
2019-05-19 20:11:22,556 - brc - INFO - Initialize the model...
2019-05-19 20:11:26,346 - brc - INFO - applying optimize adam
2019-05-19 20:11:28,801 - brc - INFO - Time to build graph: 5.591466426849365 s
2019-05-19 20:11:39,225 - brc - INFO - Training the model...
2019-05-19 20:11:39,225 - brc - INFO - Training the model for epoch 1
2019-05-19 20:35:42,581 - brc - INFO - ====== training ======
2019-05-19 20:35:42,582 - brc - INFO - Load data_set and vocab...
2019-05-19 20:35:56,338 - brc - INFO - Train set size: 4353 questions.
2019-05-19 20:35:56,338 - brc - INFO - Converting text into ids...
2019-05-19 20:36:03,204 - brc - INFO - Initialize the model...
2019-05-19 20:36:17,993 - brc - INFO - applying optimize adam
2019-05-19 20:36:20,794 - brc - INFO - Time to build graph: 6.229130983352661 s
2019-05-19 20:36:37,813 - brc - INFO - Training the model...
2019-05-19 20:36:37,813 - brc - INFO - Training the model for epoch 1
2019-05-19 20:48:23,935 - brc - INFO - ====== training ======
2019-05-19 20:48:23,935 - brc - INFO - Load data_set and vocab...
2019-05-19 20:48:43,718 - brc - INFO - ====== preprocessing ======
2019-05-19 20:48:43,718 - brc - INFO - Checking the data files...
2019-05-19 20:48:43,816 - brc - INFO - Preparing the directories...
2019-05-19 20:48:43,818 - brc - INFO - Building vocabulary...
2019-05-19 21:04:42,648 - brc - INFO - Train set size: 83646 questions.
2019-05-19 21:11:35,640 - brc - INFO - Dev set size: 5000 questions.
2019-05-19 21:26:29,282 - brc - INFO - Test set size: 30000 questions.
2019-05-19 21:30:44,922 - brc - INFO - After filter 211195 tokens, the final vocab size is 330802
2019-05-19 21:30:45,048 - brc - INFO - After filter 2065 chars, the final char vocab size is 11071
2019-05-19 21:30:45,048 - brc - INFO - Assigning embeddings...
2019-05-19 21:32:37,312 - brc - INFO - save word vocab size is 171570
2019-05-19 21:32:37,312 - brc - INFO - save char vocab size is 9658
2019-05-19 21:32:37,315 - brc - INFO - Saving vocab...
2019-05-19 21:32:45,027 - brc - INFO - ====== Done with preparing! ======
2019-05-19 21:37:24,374 - brc - INFO - ====== training ======
2019-05-19 21:37:24,374 - brc - INFO - Load data_set and vocab...
2019-05-19 21:37:31,506 - brc - INFO - Train set size: 4353 questions.
2019-05-19 21:37:31,506 - brc - INFO - Converting text into ids...
2019-05-19 21:37:38,155 - brc - INFO - Initialize the model...
2019-05-19 21:37:55,145 - brc - INFO - applying optimize adam
2019-05-19 21:37:57,805 - brc - INFO - Time to build graph: 6.455573081970215 s
2019-05-19 21:38:15,000 - brc - INFO - Training the model...
2019-05-19 21:38:15,000 - brc - INFO - Training the model for epoch 1
2019-05-19 21:44:15,322 - brc - INFO - ====== training ======
2019-05-19 21:44:15,322 - brc - INFO - Load data_set and vocab...
2019-05-19 21:44:21,472 - brc - INFO - Train set size: 4353 questions.
2019-05-19 21:44:21,472 - brc - INFO - Converting text into ids...
2019-05-19 21:44:28,371 - brc - INFO - Initialize the model...
2019-05-19 21:44:32,128 - brc - INFO - applying optimize adam
2019-05-19 21:44:34,507 - brc - INFO - Time to build graph: 5.478380918502808 s
2019-05-19 21:44:44,538 - brc - INFO - Training the model...
2019-05-19 21:44:44,538 - brc - INFO - Training the model for epoch 1
2019-05-19 21:52:28,480 - brc - INFO - ====== training ======
2019-05-19 21:52:28,480 - brc - INFO - Load data_set and vocab...
2019-05-19 21:52:34,543 - brc - INFO - Train set size: 4353 questions.
2019-05-19 21:52:34,543 - brc - INFO - Converting text into ids...
2019-05-19 21:52:41,264 - brc - INFO - Initialize the model...
2019-05-19 21:52:45,000 - brc - INFO - applying optimize adam
2019-05-19 21:52:47,379 - brc - INFO - Time to build graph: 5.47735333442688 s
2019-05-19 21:52:57,424 - brc - INFO - Training the model...
2019-05-19 21:52:57,424 - brc - INFO - Training the model for epoch 1
2019-05-19 21:54:05,170 - brc - INFO - ====== training ======
2019-05-19 21:54:05,171 - brc - INFO - Load data_set and vocab...
2019-05-19 21:54:11,199 - brc - INFO - Train set size: 4353 questions.
2019-05-19 21:54:11,199 - brc - INFO - Converting text into ids...
2019-05-19 21:54:17,935 - brc - INFO - Initialize the model...
2019-05-19 21:54:21,691 - brc - INFO - applying optimize adam
2019-05-19 21:54:24,072 - brc - INFO - Time to build graph: 5.485332727432251 s
2019-05-19 21:54:34,083 - brc - INFO - Training the model...
2019-05-19 21:54:34,084 - brc - INFO - Training the model for epoch 1
2019-05-19 22:03:08,667 - brc - INFO - ====== training ======
2019-05-19 22:03:08,667 - brc - INFO - Load data_set and vocab...
2019-05-19 22:03:14,847 - brc - INFO - Train set size: 4353 questions.
2019-05-19 22:03:14,848 - brc - INFO - Converting text into ids...
2019-05-19 22:03:21,746 - brc - INFO - Initialize the model...
2019-05-19 22:03:25,542 - brc - INFO - applying optimize adam
2019-05-19 22:03:27,934 - brc - INFO - Time to build graph: 5.529214859008789 s
2019-05-19 22:03:37,992 - brc - INFO - Training the model...
2019-05-19 22:03:37,992 - brc - INFO - Training the model for epoch 1
2019-05-19 22:13:11,854 - brc - INFO - ====== training ======
2019-05-19 22:13:11,854 - brc - INFO - Load data_set and vocab...
2019-05-19 22:13:18,018 - brc - INFO - Train set size: 4353 questions.
2019-05-19 22:13:18,018 - brc - INFO - Converting text into ids...
2019-05-19 22:13:24,879 - brc - INFO - Initialize the model...
2019-05-19 22:13:28,638 - brc - INFO - applying optimize adam
2019-05-19 22:13:31,053 - brc - INFO - Time to build graph: 5.519240617752075 s
2019-05-19 22:13:41,109 - brc - INFO - Training the model...
2019-05-19 22:13:41,109 - brc - INFO - Training the model for epoch 1
2019-05-19 22:18:37,349 - brc - INFO - ====== training ======
2019-05-19 22:18:37,349 - brc - INFO - Load data_set and vocab...
2019-05-19 22:18:43,424 - brc - INFO - Train set size: 4353 questions.
2019-05-19 22:18:43,424 - brc - INFO - Converting text into ids...
2019-05-19 22:18:50,183 - brc - INFO - Initialize the model...
2019-05-19 22:18:53,930 - brc - INFO - applying optimize adam
2019-05-19 22:18:56,332 - brc - INFO - Time to build graph: 5.497323751449585 s
2019-05-19 22:19:06,355 - brc - INFO - Training the model...
2019-05-19 22:19:06,355 - brc - INFO - Training the model for epoch 1
2019-05-19 22:26:32,419 - brc - INFO - ====== training ======
2019-05-19 22:26:32,419 - brc - INFO - Load data_set and vocab...
2019-05-19 22:26:38,465 - brc - INFO - Train set size: 4353 questions.
2019-05-19 22:26:38,465 - brc - INFO - Converting text into ids...
2019-05-19 22:26:45,202 - brc - INFO - Initialize the model...
2019-05-19 22:26:49,009 - brc - INFO - applying optimize adam
2019-05-19 22:26:51,464 - brc - INFO - Time to build graph: 5.597033500671387 s
2019-05-19 22:27:01,485 - brc - INFO - Training the model...
2019-05-19 22:27:01,485 - brc - INFO - Training the model for epoch 1
2019-05-19 22:36:53,250 - brc - INFO - ====== training ======
2019-05-19 22:36:53,251 - brc - INFO - Load data_set and vocab...
2019-05-19 22:36:59,254 - brc - INFO - Train set size: 4353 questions.
2019-05-19 22:36:59,254 - brc - INFO - Converting text into ids...
2019-05-19 22:37:05,927 - brc - INFO - Initialize the model...
2019-05-19 22:37:09,663 - brc - INFO - applying optimize adam
2019-05-19 22:37:12,075 - brc - INFO - Time to build graph: 5.5122597217559814 s
2019-05-19 22:37:22,061 - brc - INFO - Training the model...
2019-05-19 22:37:22,061 - brc - INFO - Training the model for epoch 1
2019-05-19 22:41:45,186 - brc - INFO - Average train loss for epoch 1 is nan
2019-05-19 22:41:45,186 - brc - INFO - Evaluating the model after epoch 1
2019-05-19 22:43:13,750 - brc - INFO - ====== training ======
2019-05-19 22:43:13,750 - brc - INFO - Load data_set and vocab...
2019-05-19 22:43:19,749 - brc - INFO - Train set size: 4353 questions.
2019-05-19 22:43:19,749 - brc - INFO - Converting text into ids...
2019-05-19 22:43:26,437 - brc - INFO - Initialize the model...
2019-05-19 22:43:30,169 - brc - INFO - applying optimize adam
2019-05-19 22:43:32,678 - brc - INFO - Time to build graph: 5.601918697357178 s
2019-05-19 22:43:42,645 - brc - INFO - Training the model...
2019-05-19 22:43:42,645 - brc - INFO - Training the model for epoch 1
2019-05-19 22:46:09,721 - brc - INFO - ====== training ======
2019-05-19 22:46:09,721 - brc - INFO - Load data_set and vocab...
2019-05-19 22:46:15,754 - brc - INFO - Train set size: 4353 questions.
2019-05-19 22:46:15,754 - brc - INFO - Converting text into ids...
2019-05-19 22:46:22,356 - brc - INFO - Initialize the model...
2019-05-19 22:46:26,120 - brc - INFO - applying optimize adam
2019-05-19 22:46:28,516 - brc - INFO - Time to build graph: 5.497331142425537 s
2019-05-19 22:46:38,633 - brc - INFO - Training the model...
2019-05-19 22:46:38,633 - brc - INFO - Training the model for epoch 1
2019-05-19 22:49:22,471 - brc - INFO - ====== training ======
2019-05-19 22:49:22,471 - brc - INFO - Load data_set and vocab...
2019-05-19 22:49:28,546 - brc - INFO - Train set size: 4353 questions.
2019-05-19 22:49:28,546 - brc - INFO - Converting text into ids...
2019-05-19 22:49:35,531 - brc - INFO - Initialize the model...
2019-05-19 22:54:49,652 - brc - INFO - ====== training ======
2019-05-19 22:54:49,652 - brc - INFO - Load data_set and vocab...
2019-05-19 22:54:55,742 - brc - INFO - Train set size: 4353 questions.
2019-05-19 22:54:55,742 - brc - INFO - Converting text into ids...
2019-05-19 22:55:02,426 - brc - INFO - Initialize the model...
2019-05-19 22:55:06,184 - brc - INFO - applying optimize adam
2019-05-19 22:55:08,535 - brc - INFO - Time to build graph: 5.4683778285980225 s
2019-05-19 22:55:18,487 - brc - INFO - Training the model...
2019-05-19 22:55:18,487 - brc - INFO - Training the model for epoch 1
2019-05-19 22:56:51,877 - brc - INFO - ====== training ======
2019-05-19 22:56:51,877 - brc - INFO - Load data_set and vocab...
2019-05-19 22:56:57,895 - brc - INFO - Train set size: 4353 questions.
2019-05-19 22:56:57,895 - brc - INFO - Converting text into ids...
2019-05-19 22:57:04,559 - brc - INFO - Initialize the model...
2019-05-19 22:57:08,330 - brc - INFO - applying optimize adam
2019-05-19 22:57:10,647 - brc - INFO - Time to build graph: 5.434467077255249 s
2019-05-19 22:57:20,646 - brc - INFO - Training the model...
2019-05-19 22:57:20,646 - brc - INFO - Training the model for epoch 1
2019-05-19 23:01:41,090 - brc - INFO - Average train loss for epoch 1 is 1.4761029844998357e+30
2019-05-19 23:01:41,090 - brc - INFO - Evaluating the model after epoch 1
2019-05-19 23:08:01,519 - brc - INFO - ====== training ======
2019-05-19 23:08:01,520 - brc - INFO - Load data_set and vocab...
2019-05-19 23:08:07,583 - brc - INFO - Train set size: 4353 questions.
2019-05-19 23:08:07,583 - brc - INFO - Converting text into ids...
2019-05-19 23:08:14,371 - brc - INFO - Initialize the model...
2019-05-19 23:08:21,395 - brc - INFO - applying optimize adam
2019-05-19 23:08:28,175 - brc - INFO - Time to build graph: 13.163506269454956 s
2019-05-19 23:08:53,463 - brc - INFO - Training the model...
2019-05-19 23:08:53,464 - brc - INFO - Training the model for epoch 1
2019-05-19 23:15:09,377 - brc - INFO - Average train loss for epoch 1 is 1.444852986529679e+30
2019-05-19 23:15:09,378 - brc - INFO - Evaluating the model after epoch 1
2019-05-19 23:16:37,988 - brc - INFO - ====== training ======
2019-05-19 23:16:37,988 - brc - INFO - Load data_set and vocab...
2019-05-19 23:16:53,203 - brc - INFO - Train set size: 4353 questions.
2019-05-19 23:16:53,203 - brc - INFO - Converting text into ids...
2019-05-19 23:17:11,155 - brc - INFO - Initialize the model...
2019-05-19 23:17:21,568 - brc - INFO - applying optimize adam
2019-05-19 23:17:56,623 - brc - INFO - ====== training ======
2019-05-19 23:17:56,623 - brc - INFO - Load data_set and vocab...
2019-05-19 23:18:11,317 - brc - INFO - Train set size: 4353 questions.
2019-05-19 23:18:11,317 - brc - INFO - Converting text into ids...
2019-05-19 23:18:28,474 - brc - INFO - Initialize the model...
2019-05-19 23:18:38,672 - brc - INFO - applying optimize adam
2019-05-19 23:18:45,466 - brc - INFO - Time to build graph: 15.346960306167603 s
2019-05-19 23:19:10,473 - brc - INFO - Training the model...
2019-05-19 23:19:10,473 - brc - INFO - Training the model for epoch 1
2019-05-19 23:25:50,451 - brc - INFO - Average train loss for epoch 1 is 1.5275735751763494e+30
2019-05-19 23:25:50,451 - brc - INFO - Evaluating the model after epoch 1
2019-05-20 08:51:16,058 - brc - INFO - ====== training ======
2019-05-20 08:51:16,063 - brc - INFO - Load data_set and vocab...
2019-05-20 08:51:29,665 - brc - INFO - Train set size: 4353 questions.
2019-05-20 08:51:36,924 - brc - INFO - Dev set size: 5000 questions.
2019-05-20 08:51:36,924 - brc - INFO - Converting text into ids...
2019-05-20 08:51:50,186 - brc - INFO - Initialize the model...
2019-05-20 08:52:07,100 - brc - INFO - applying optimize adam
2019-05-20 08:52:09,665 - brc - INFO - Time to build graph: 6.422261476516724 s
2019-05-20 08:52:27,047 - brc - INFO - Training the model...
2019-05-20 08:52:27,048 - brc - INFO - Training the model for epoch 1
2019-05-20 08:56:49,512 - brc - INFO - Average train loss for epoch 1 is 1.3327206277344005e+30
2019-05-20 08:56:49,512 - brc - INFO - Evaluating the model after epoch 1
2019-05-20 09:00:16,067 - brc - INFO - Dev eval loss 1.4736000449017515e+30
2019-05-20 09:00:16,068 - brc - INFO - Dev eval result: {'Bleu-1': 8.359350008696323e-16, 'Bleu-2': 7.613472026876079e-16, 'Bleu-3': 7.127845985887319e-16, 'Bleu-4': 6.793540362001314e-16, 'Rouge-L': 0.047134491271907886}
2019-05-20 09:00:27,311 - brc - INFO - Model saved in data\models, with prefix r-net.
2019-05-20 09:00:27,311 - brc - INFO - Training the model for epoch 2
2019-05-20 14:33:34,508 - brc - INFO - ====== training ======
2019-05-20 14:33:34,508 - brc - INFO - Load data_set and vocab...
2019-05-20 14:33:40,455 - brc - INFO - Train set size: 4353 questions.
2019-05-20 14:33:47,636 - brc - INFO - Dev set size: 5000 questions.
2019-05-20 14:33:47,636 - brc - INFO - Converting text into ids...
2019-05-20 14:34:01,192 - brc - INFO - Initialize the model...
2019-05-20 15:00:32,789 - brc - INFO - ====== training ======
2019-05-20 15:00:32,789 - brc - INFO - Load data_set and vocab...
2019-05-20 15:00:38,765 - brc - INFO - Train set size: 4353 questions.
2019-05-20 15:00:45,902 - brc - INFO - Dev set size: 5000 questions.
2019-05-20 15:00:45,902 - brc - INFO - Converting text into ids...
2019-05-20 15:00:59,437 - brc - INFO - Initialize the model...
2019-05-21 20:06:27,092 - brc - INFO - ====== training ======
2019-05-21 20:06:27,092 - brc - INFO - Load data_set and vocab...
2019-05-21 20:06:42,117 - brc - INFO - Train set size: 4353 questions.
2019-05-21 20:06:53,259 - brc - INFO - Dev set size: 5000 questions.
2019-05-21 20:06:53,259 - brc - INFO - Converting text into ids...
2019-05-21 20:07:24,130 - brc - INFO - Initialize the model...
2019-05-21 20:09:20,066 - brc - INFO - ====== training ======
2019-05-21 20:09:20,066 - brc - INFO - Load data_set and vocab...
2019-05-21 20:09:26,324 - brc - INFO - Train set size: 4353 questions.
2019-05-21 20:09:33,907 - brc - INFO - Dev set size: 5000 questions.
2019-05-21 20:09:33,908 - brc - INFO - Converting text into ids...
2019-05-21 20:09:48,516 - brc - INFO - Initialize the model...
2019-05-21 20:20:04,296 - brc - INFO - ====== training ======
2019-05-21 20:20:04,296 - brc - INFO - Load data_set and vocab...
2019-05-21 20:20:10,457 - brc - INFO - Train set size: 4353 questions.
2019-05-21 20:20:17,959 - brc - INFO - Dev set size: 5000 questions.
2019-05-21 20:20:17,959 - brc - INFO - Converting text into ids...
2019-05-21 20:20:32,349 - brc - INFO - Initialize the model...
2019-05-21 21:00:54,131 - brc - INFO - ====== training ======
2019-05-21 21:00:54,131 - brc - INFO - Load data_set and vocab...
2019-05-21 21:01:00,266 - brc - INFO - Train set size: 4353 questions.
2019-05-21 21:01:07,784 - brc - INFO - Dev set size: 5000 questions.
2019-05-21 21:01:07,784 - brc - INFO - Converting text into ids...
2019-05-21 21:01:21,512 - brc - INFO - Initialize the model...
2019-05-21 21:02:44,330 - brc - INFO - ====== training ======
2019-05-21 21:02:44,330 - brc - INFO - Load data_set and vocab...
2019-05-21 21:02:50,490 - brc - INFO - Train set size: 4353 questions.
2019-05-21 21:02:57,815 - brc - INFO - Dev set size: 5000 questions.
2019-05-21 21:02:57,815 - brc - INFO - Converting text into ids...
2019-05-21 21:03:11,403 - brc - INFO - Initialize the model...
2019-05-21 21:05:58,991 - brc - INFO - ====== training ======
2019-05-21 21:05:58,991 - brc - INFO - Load data_set and vocab...
2019-05-21 21:06:05,188 - brc - INFO - Train set size: 4353 questions.
2019-05-21 21:06:12,575 - brc - INFO - Dev set size: 5000 questions.
2019-05-21 21:06:12,575 - brc - INFO - Converting text into ids...
2019-05-21 21:06:26,349 - brc - INFO - Initialize the model...
2019-05-21 21:10:52,240 - brc - INFO - ====== training ======
2019-05-21 21:10:52,240 - brc - INFO - Load data_set and vocab...
2019-05-21 21:10:58,398 - brc - INFO - Train set size: 4353 questions.
2019-05-21 21:11:05,814 - brc - INFO - Dev set size: 5000 questions.
2019-05-21 21:11:05,814 - brc - INFO - Converting text into ids...
2019-05-21 21:11:19,513 - brc - INFO - Initialize the model...
2019-05-21 21:16:31,513 - brc - INFO - ====== training ======
2019-05-21 21:16:31,513 - brc - INFO - Load data_set and vocab...
2019-05-21 21:16:37,700 - brc - INFO - Train set size: 4353 questions.
2019-05-21 21:16:45,011 - brc - INFO - Dev set size: 5000 questions.
2019-05-21 21:16:45,012 - brc - INFO - Converting text into ids...
2019-05-21 21:16:58,594 - brc - INFO - Initialize the model...
2019-05-21 21:17:56,791 - brc - INFO - ====== training ======
2019-05-21 21:17:56,791 - brc - INFO - Load data_set and vocab...
2019-05-21 21:18:02,996 - brc - INFO - Train set size: 4353 questions.
2019-05-21 21:18:10,428 - brc - INFO - Dev set size: 5000 questions.
2019-05-21 21:18:10,428 - brc - INFO - Converting text into ids...
2019-05-21 21:18:24,167 - brc - INFO - Initialize the model...
2019-05-21 21:19:21,111 - brc - INFO - ====== training ======
2019-05-21 21:19:21,111 - brc - INFO - Load data_set and vocab...
2019-05-21 21:19:27,307 - brc - INFO - Train set size: 4353 questions.
2019-05-21 21:19:34,658 - brc - INFO - Dev set size: 5000 questions.
2019-05-21 21:19:34,658 - brc - INFO - Converting text into ids...
2019-05-21 21:19:48,158 - brc - INFO - Initialize the model...
2019-05-21 21:20:58,741 - brc - INFO - ====== training ======
2019-05-21 21:20:58,741 - brc - INFO - Load data_set and vocab...
2019-05-21 21:21:05,036 - brc - INFO - Train set size: 4353 questions.
2019-05-21 21:21:12,417 - brc - INFO - Dev set size: 5000 questions.
2019-05-21 21:21:12,417 - brc - INFO - Converting text into ids...
2019-05-21 21:21:26,331 - brc - INFO - Initialize the model...
2019-05-21 21:23:44,760 - brc - INFO - ====== training ======
2019-05-21 21:23:44,760 - brc - INFO - Load data_set and vocab...
2019-05-21 21:23:50,962 - brc - INFO - Train set size: 4353 questions.
2019-05-21 21:23:58,333 - brc - INFO - Dev set size: 5000 questions.
2019-05-21 21:23:58,333 - brc - INFO - Converting text into ids...
2019-05-21 21:24:11,936 - brc - INFO - Initialize the model...
2019-05-21 21:25:43,839 - brc - INFO - ====== training ======
2019-05-21 21:25:43,839 - brc - INFO - Load data_set and vocab...
2019-05-21 21:25:50,014 - brc - INFO - Train set size: 4353 questions.
2019-05-21 21:25:57,445 - brc - INFO - Dev set size: 5000 questions.
2019-05-21 21:25:57,445 - brc - INFO - Converting text into ids...
2019-05-21 21:26:11,202 - brc - INFO - Initialize the model...
2019-05-21 21:26:47,180 - brc - INFO - ====== training ======
2019-05-21 21:26:47,180 - brc - INFO - Load data_set and vocab...
2019-05-21 21:26:53,376 - brc - INFO - Train set size: 4353 questions.
2019-05-21 21:27:00,744 - brc - INFO - Dev set size: 5000 questions.
2019-05-21 21:27:00,744 - brc - INFO - Converting text into ids...
2019-05-21 21:27:14,508 - brc - INFO - Initialize the model...
2019-05-21 21:27:18,594 - brc - INFO - applying optimize adam
2019-05-21 21:30:56,902 - brc - INFO - ====== training ======
2019-05-21 21:30:56,902 - brc - INFO - Load data_set and vocab...
2019-05-21 21:31:03,093 - brc - INFO - Train set size: 4353 questions.
2019-05-21 21:31:10,518 - brc - INFO - Dev set size: 5000 questions.
2019-05-21 21:31:10,518 - brc - INFO - Converting text into ids...
2019-05-21 21:31:24,430 - brc - INFO - Initialize the model...
2019-05-21 21:31:28,520 - brc - INFO - applying optimize adam
2019-05-21 21:34:46,001 - brc - INFO - ====== training ======
2019-05-21 21:34:46,002 - brc - INFO - Load data_set and vocab...
2019-05-21 21:34:52,217 - brc - INFO - Train set size: 4353 questions.
2019-05-21 21:34:59,622 - brc - INFO - Dev set size: 5000 questions.
2019-05-21 21:34:59,622 - brc - INFO - Converting text into ids...
2019-05-21 21:35:13,365 - brc - INFO - Initialize the model...
2019-05-21 21:35:17,425 - brc - INFO - applying optimize adam
2019-05-21 21:35:19,797 - brc - INFO - Time to build graph: 5.749634504318237 s
2019-05-21 21:35:38,432 - brc - INFO - Training the model...
2019-05-21 21:35:39,730 - brc - INFO - Training the model for epoch 1
2019-05-21 21:37:31,267 - brc - INFO - ====== training ======
2019-05-21 21:37:31,267 - brc - INFO - Load data_set and vocab...
2019-05-21 21:37:45,450 - brc - INFO - Train set size: 4353 questions.
2019-05-21 21:37:53,044 - brc - INFO - Dev set size: 5000 questions.
2019-05-21 21:37:53,044 - brc - INFO - Converting text into ids...
2019-05-21 21:38:06,905 - brc - INFO - Initialize the model...
2019-05-21 21:38:23,499 - brc - INFO - applying optimize adam
2019-05-21 21:38:26,054 - brc - INFO - Time to build graph: 5.9756410121917725 s
2019-05-21 21:38:37,444 - brc - INFO - Training the model...
2019-05-21 21:38:38,549 - brc - INFO - Training the model for epoch 1
2019-05-21 21:44:59,014 - brc - INFO - ====== training ======
2019-05-21 21:44:59,015 - brc - INFO - Load data_set and vocab...
2019-05-21 21:45:13,375 - brc - INFO - Train set size: 4353 questions.
2019-05-21 21:45:20,838 - brc - INFO - Dev set size: 5000 questions.
2019-05-21 21:45:20,838 - brc - INFO - Converting text into ids...
2019-05-21 21:45:34,787 - brc - INFO - Initialize the model...
2019-05-21 21:45:39,398 - brc - INFO - applying optimize adam
2019-05-21 21:45:41,792 - brc - INFO - Time to build graph: 5.798722982406616 s
2019-05-21 21:45:52,729 - brc - INFO - Training the model...
2019-05-21 21:45:53,903 - brc - INFO - Training the model for epoch 1
2019-05-21 21:47:10,871 - brc - INFO - ====== training ======
2019-05-21 21:47:10,871 - brc - INFO - Load data_set and vocab...
2019-05-21 21:47:17,155 - brc - INFO - Train set size: 4353 questions.
2019-05-21 21:47:24,599 - brc - INFO - Dev set size: 5000 questions.
2019-05-21 21:47:24,599 - brc - INFO - Converting text into ids...
2019-05-21 21:47:38,255 - brc - INFO - Initialize the model...
2019-05-21 21:47:42,322 - brc - INFO - applying optimize adam
2019-05-21 21:47:44,734 - brc - INFO - Time to build graph: 5.802495718002319 s
2019-05-21 21:47:55,329 - brc - INFO - Training the model...
2019-05-21 21:47:56,439 - brc - INFO - Training the model for epoch 1
2019-05-21 21:54:17,776 - brc - INFO - ====== training ======
2019-05-21 21:54:17,790 - brc - INFO - Load data_set and vocab...
2019-05-21 21:54:32,390 - brc - INFO - Train set size: 4353 questions.
2019-05-21 21:54:39,651 - brc - INFO - Dev set size: 5000 questions.
2019-05-21 21:54:39,651 - brc - INFO - Converting text into ids...
2019-05-21 21:54:53,248 - brc - INFO - Initialize the model...
2019-05-21 21:55:10,892 - brc - INFO - applying optimize adam
2019-05-21 21:55:13,510 - brc - INFO - Time to build graph: 6.91141414642334 s
2019-05-21 21:55:31,684 - brc - INFO - Training the model...
2019-05-21 21:55:32,984 - brc - INFO - Training the model for epoch 1
2019-05-21 21:59:32,742 - brc - INFO - ====== training ======
2019-05-21 21:59:32,742 - brc - INFO - Load data_set and vocab...
2019-05-21 21:59:46,928 - brc - INFO - Train set size: 4353 questions.
2019-05-21 21:59:54,267 - brc - INFO - Dev set size: 5000 questions.
2019-05-21 21:59:54,267 - brc - INFO - Converting text into ids...
2019-05-21 22:00:07,779 - brc - INFO - Initialize the model...
2019-05-21 22:00:11,784 - brc - INFO - applying optimize adam
2019-05-21 22:00:14,159 - brc - INFO - Time to build graph: 5.744666576385498 s
2019-05-21 22:00:25,969 - brc - INFO - Training the model...
2019-05-21 22:00:27,155 - brc - INFO - Training the model for epoch 1
2019-05-21 22:10:33,920 - brc - INFO - ====== training ======
2019-05-21 22:10:33,920 - brc - INFO - Load data_set and vocab...
2019-05-21 22:10:40,158 - brc - INFO - Train set size: 4353 questions.
2019-05-21 22:10:47,775 - brc - INFO - Dev set size: 5000 questions.
2019-05-21 22:10:47,775 - brc - INFO - Converting text into ids...
2019-05-21 22:11:01,323 - brc - INFO - Initialize the model...
2019-05-21 22:11:05,356 - brc - INFO - applying optimize adam
2019-05-21 22:11:07,728 - brc - INFO - Time to build graph: 5.751613616943359 s
2019-05-21 22:11:18,873 - brc - INFO - Training the model...
2019-05-21 22:11:20,068 - brc - INFO - Training the model for epoch 1
2019-05-21 22:13:49,792 - brc - INFO - ====== training ======
2019-05-21 22:13:49,793 - brc - INFO - Load data_set and vocab...
2019-05-21 22:13:55,902 - brc - INFO - Train set size: 4353 questions.
2019-05-21 22:14:03,231 - brc - INFO - Dev set size: 5000 questions.
2019-05-21 22:14:03,231 - brc - INFO - Converting text into ids...
2019-05-21 22:14:16,849 - brc - INFO - Initialize the model...
2019-05-21 22:14:20,753 - brc - INFO - applying optimize adam
2019-05-21 22:14:23,130 - brc - INFO - Time to build graph: 5.636888027191162 s
2019-05-21 22:14:34,575 - brc - INFO - Training the model...
2019-05-21 22:14:35,767 - brc - INFO - Training the model for epoch 1
2019-05-21 22:18:40,640 - brc - INFO - Average train loss for epoch 1 is 71.97898848617778
2019-05-21 22:18:40,642 - brc - INFO - Evaluating the model after epoch 1
2019-05-21 22:20:35,982 - brc - INFO - Dev eval loss 1.4272000408185568e+30
2019-05-21 22:20:35,983 - brc - INFO - Dev eval result: None
2019-05-21 22:24:18,817 - brc - INFO - ====== training ======
2019-05-21 22:24:18,817 - brc - INFO - Load data_set and vocab...
2019-05-21 22:24:24,956 - brc - INFO - Train set size: 4353 questions.
2019-05-21 22:24:32,338 - brc - INFO - Dev set size: 5000 questions.
2019-05-21 22:24:32,338 - brc - INFO - Converting text into ids...
2019-05-21 22:24:45,954 - brc - INFO - Initialize the model...
2019-05-21 22:24:49,989 - brc - INFO - applying optimize adam
2019-05-21 22:24:52,386 - brc - INFO - Time to build graph: 5.792505741119385 s
2019-05-21 22:25:03,972 - brc - INFO - Training the model...
2019-05-21 22:25:05,216 - brc - INFO - Training the model for epoch 1
2019-05-21 22:29:12,670 - brc - INFO - Average train loss for epoch 1 is 73.54615062124589
2019-05-21 22:29:12,670 - brc - INFO - Evaluating the model after epoch 1
2019-05-21 22:31:15,388 - brc - INFO - Dev eval loss 1.4272000408185568e+30
2019-05-21 22:31:15,388 - brc - INFO - Dev eval result: None
2019-05-21 22:34:42,279 - brc - INFO - ====== training ======
2019-05-21 22:34:42,279 - brc - INFO - Load data_set and vocab...
2019-05-21 22:34:48,445 - brc - INFO - Train set size: 4353 questions.
2019-05-21 22:34:55,788 - brc - INFO - Dev set size: 5000 questions.
2019-05-21 22:34:55,788 - brc - INFO - Converting text into ids...
2019-05-21 22:35:09,307 - brc - INFO - Initialize the model...
2019-05-21 22:35:13,217 - brc - INFO - applying optimize adam
2019-05-21 22:35:15,589 - brc - INFO - Time to build graph: 5.640910863876343 s
2019-05-21 22:35:27,081 - brc - INFO - Training the model...
2019-05-21 22:35:28,288 - brc - INFO - Training the model for epoch 1
2019-05-21 22:39:35,639 - brc - INFO - Average train loss for epoch 1 is 73.42078595301685
2019-05-21 22:39:35,639 - brc - INFO - Evaluating the model after epoch 1
2019-05-21 22:44:31,750 - brc - INFO - ====== training ======
2019-05-21 22:44:31,750 - brc - INFO - Load data_set and vocab...
2019-05-21 22:44:37,902 - brc - INFO - Train set size: 4353 questions.
2019-05-21 22:44:45,304 - brc - INFO - Dev set size: 5000 questions.
2019-05-21 22:44:45,304 - brc - INFO - Converting text into ids...
2019-05-21 22:44:58,986 - brc - INFO - Initialize the model...
2019-05-21 22:45:02,847 - brc - INFO - applying optimize adam
2019-05-21 22:45:05,208 - brc - INFO - Time to build graph: 5.5781090259552 s
2019-05-21 22:45:16,702 - brc - INFO - Training the model...
2019-05-21 22:45:17,815 - brc - INFO - Training the model for epoch 1
2019-05-21 22:49:26,012 - brc - INFO - Average train loss for epoch 1 is 72.36668717159944
2019-05-21 22:49:26,012 - brc - INFO - Evaluating the model after epoch 1
2019-05-21 22:52:54,266 - brc - INFO - Dev eval loss 1.4272000408185568e+30
2019-05-21 22:52:54,267 - brc - INFO - Dev eval result: {'Bleu-1': 2.9738893416815505e-06, 'Bleu-2': 2.378756549991698e-06, 'Bleu-3': 2.041802535849978e-06, 'Bleu-4': 1.8334600388735186e-06, 'Rouge-L': 0.06535882475309583}
2019-05-21 22:53:05,469 - brc - INFO - Model saved in data\models, with prefix r-net.
2019-05-21 22:53:06,228 - brc - INFO - Training the model for epoch 2
2019-05-21 22:57:33,472 - brc - INFO - Average train loss for epoch 2 is 61.64867705457351
2019-05-21 22:57:33,472 - brc - INFO - Evaluating the model after epoch 2
2019-05-21 23:01:06,425 - brc - INFO - Dev eval loss 1.4272000408185568e+30
2019-05-21 23:01:06,425 - brc - INFO - Dev eval result: {'Bleu-1': 0.00016762241318870192, 'Bleu-2': 0.00013517336346557859, 'Bleu-3': 0.0001178767839996355, 'Bleu-4': 0.00010756211273263961, 'Rouge-L': 0.08264758413213888}
2019-05-21 23:01:17,720 - brc - INFO - Model saved in data\models, with prefix r-net.
2019-05-21 23:01:18,419 - brc - INFO - Training the model for epoch 3
2019-05-21 23:05:36,304 - brc - INFO - Average train loss for epoch 3 is 59.29715921948938
2019-05-21 23:05:36,305 - brc - INFO - Evaluating the model after epoch 3
2019-05-21 23:10:04,211 - brc - INFO - Dev eval loss 1.4272000408185568e+30
2019-05-21 23:10:04,211 - brc - INFO - Dev eval result: {'Bleu-1': 0.0003062486580344732, 'Bleu-2': 0.0002426341203636444, 'Bleu-3': 0.00020792514862789604, 'Bleu-4': 0.0001869853165116668, 'Rouge-L': 0.08180574608152519}
2019-05-21 23:10:06,160 - brc - INFO - Training the model for epoch 4
2019-05-21 23:16:13,074 - brc - INFO - Average train loss for epoch 4 is 57.756476272554956
2019-05-21 23:16:13,075 - brc - INFO - Evaluating the model after epoch 4
2019-05-22 07:38:57,072 - brc - INFO - ====== training ======
2019-05-22 07:38:57,073 - brc - INFO - Load data_set and vocab...
2019-05-22 07:53:23,232 - brc - INFO - Train set size: 83646 questions.
2019-05-22 08:01:16,593 - brc - INFO - Dev set size: 5000 questions.
2019-05-22 08:01:16,651 - brc - INFO - Converting text into ids...
2019-05-22 08:08:28,883 - brc - INFO - ====== training ======
2019-05-22 08:08:28,884 - brc - INFO - Load data_set and vocab...
2019-05-22 08:08:42,561 - brc - INFO - Train set size: 4353 questions.
2019-05-22 08:08:49,791 - brc - INFO - Dev set size: 5000 questions.
2019-05-22 08:08:49,791 - brc - INFO - Converting text into ids...
2019-05-22 08:09:03,329 - brc - INFO - Initialize the model...
2019-05-22 08:09:21,482 - brc - INFO - applying optimize adam
2019-05-22 08:09:24,139 - brc - INFO - Time to build graph: 6.812443256378174 s
2019-05-22 08:09:42,058 - brc - INFO - Training the model...
2019-05-22 08:11:40,540 - brc - INFO - ====== training ======
2019-05-22 08:11:40,540 - brc - INFO - Load data_set and vocab...
2019-05-22 08:11:46,590 - brc - INFO - Train set size: 4353 questions.
2019-05-22 08:11:53,770 - brc - INFO - Dev set size: 5000 questions.
2019-05-22 08:11:53,770 - brc - INFO - Converting text into ids...
2019-05-22 08:12:07,047 - brc - INFO - Initialize the model...
2019-05-22 08:12:11,721 - brc - INFO - applying optimize adam
2019-05-22 08:12:14,095 - brc - INFO - Time to build graph: 5.565113544464111 s
2019-05-22 08:12:24,180 - brc - INFO - Training the model...
2019-05-22 08:12:41,237 - brc - INFO - Training the model for epoch 1
2019-05-22 08:16:47,266 - brc - INFO - Average train loss for epoch 1 is 73.29137943772709
2019-05-22 08:16:47,608 - brc - INFO - Evaluating the model after epoch 1
2019-05-22 08:20:02,688 - brc - INFO - Dev eval loss 1.4272000408185568e+30
2019-05-22 08:20:02,688 - brc - INFO - Dev eval result: {'Bleu-1': 6.96065557036281e-13, 'Bleu-2': 6.034334419413101e-13, 'Bleu-3': 5.320232960900153e-13, 'Bleu-4': 4.809953027260114e-13, 'Rouge-L': 0.04750919522511176}
2019-05-22 08:20:14,455 - brc - INFO - Model saved in data\models, with prefix r-net.
2019-05-22 08:20:15,128 - brc - INFO - Training the model for epoch 2
2019-05-22 08:24:25,958 - brc - INFO - Average train loss for epoch 2 is 62.4986751500298
2019-05-22 08:24:25,958 - brc - INFO - Evaluating the model after epoch 2
2019-05-22 08:27:52,083 - brc - INFO - Dev eval loss 1.4272000408185568e+30
2019-05-22 08:27:52,083 - brc - INFO - Dev eval result: {'Bleu-1': 0.0001669377525317252, 'Bleu-2': 0.0001338157082550118, 'Bleu-3': 0.00011603915005733938, 'Bleu-4': 0.0001054492524889871, 'Rouge-L': 0.08519124745147594}
2019-05-22 08:28:05,345 - brc - INFO - Model saved in data\models, with prefix r-net.
2019-05-22 08:28:06,023 - brc - INFO - Training the model for epoch 3
2019-05-22 08:32:23,752 - brc - INFO - Average train loss for epoch 3 is 59.51403631182278
2019-05-22 08:32:23,752 - brc - INFO - Evaluating the model after epoch 3
2019-05-22 08:36:04,261 - brc - INFO - Dev eval loss 1.4272000408185568e+30
2019-05-22 08:36:04,261 - brc - INFO - Dev eval result: {'Bleu-1': 0.00017987446345176474, 'Bleu-2': 0.0001454216782145839, 'Bleu-3': 0.00012682428052910978, 'Bleu-4': 0.00011569301367875642, 'Rouge-L': 0.09074883236815304}
2019-05-22 08:36:17,944 - brc - INFO - Model saved in data\models, with prefix r-net.
2019-05-22 08:36:18,619 - brc - INFO - Training the model for epoch 4
2019-05-22 08:41:04,961 - brc - INFO - Average train loss for epoch 4 is 57.83766094025444
2019-05-22 08:41:04,961 - brc - INFO - Evaluating the model after epoch 4
2019-05-22 08:44:49,078 - brc - INFO - Dev eval loss 1.4272000408185568e+30
2019-05-22 08:44:49,078 - brc - INFO - Dev eval result: {'Bleu-1': 0.00024412749877874982, 'Bleu-2': 0.0001988845507346213, 'Bleu-3': 0.00017446340439126226, 'Bleu-4': 0.00015987012541809653, 'Rouge-L': 0.09035854272473215}
2019-05-22 08:44:49,817 - brc - INFO - Training the model for epoch 5
2019-05-22 08:49:39,696 - brc - INFO - Average train loss for epoch 5 is 56.56044263699476
2019-05-22 08:49:39,696 - brc - INFO - Evaluating the model after epoch 5
2019-05-22 08:53:28,689 - brc - INFO - Dev eval loss 1.4272000408185568e+30
2019-05-22 08:53:28,689 - brc - INFO - Dev eval result: {'Bleu-1': 0.0002167259368363094, 'Bleu-2': 0.00017500798935679725, 'Bleu-3': 0.0001522806292418256, 'Bleu-4': 0.00013855861183137435, 'Rouge-L': 0.08616031074907618}
2019-05-22 08:53:29,915 - brc - INFO - Training the model for epoch 6
2019-05-22 08:58:14,177 - brc - INFO - Average train loss for epoch 6 is 55.36172717809677
2019-05-22 08:58:14,178 - brc - INFO - Evaluating the model after epoch 6
2019-05-22 09:01:57,340 - brc - INFO - Dev eval loss 1.4272000408185568e+30
2019-05-22 09:01:57,340 - brc - INFO - Dev eval result: {'Bleu-1': 0.00019160561403230774, 'Bleu-2': 0.00015662099653465748, 'Bleu-3': 0.00013767997139486058, 'Bleu-4': 0.00012629473715051917, 'Rouge-L': 0.08970364844978666}
2019-05-22 09:01:58,222 - brc - INFO - Training the model for epoch 7
2019-05-22 09:06:44,694 - brc - INFO - Average train loss for epoch 7 is 54.293578519540674
2019-05-22 09:06:44,694 - brc - INFO - Evaluating the model after epoch 7
2019-05-22 09:10:29,288 - brc - INFO - Dev eval loss 1.4272000408185568e+30
2019-05-22 09:10:29,288 - brc - INFO - Dev eval result: {'Bleu-1': 0.0005548413268596109, 'Bleu-2': 0.0004496595013426699, 'Bleu-3': 0.00039197896347224195, 'Bleu-4': 0.0003571950473696692, 'Rouge-L': 0.09517327376830859}
2019-05-22 09:10:43,372 - brc - INFO - Model saved in data\models, with prefix r-net.
2019-05-22 09:10:44,042 - brc - INFO - Training the model for epoch 8
2019-05-22 09:15:29,570 - brc - INFO - Average train loss for epoch 8 is 53.12306625001571
2019-05-22 09:15:29,570 - brc - INFO - Evaluating the model after epoch 8
2019-05-22 09:19:10,693 - brc - INFO - Dev eval loss 1.4272000408185568e+30
2019-05-22 09:19:10,693 - brc - INFO - Dev eval result: {'Bleu-1': 0.0003683162743508089, 'Bleu-2': 0.00030180239495361587, 'Bleu-3': 0.00026603513552546674, 'Bleu-4': 0.00024498156907311336, 'Rouge-L': 0.0899834810982623}
2019-05-22 09:19:11,859 - brc - INFO - Training the model for epoch 9
2019-05-22 09:23:56,190 - brc - INFO - Average train loss for epoch 9 is 51.82013752881218
2019-05-22 09:23:56,190 - brc - INFO - Evaluating the model after epoch 9
2019-05-22 09:27:39,273 - brc - INFO - Dev eval loss 1.4272000408185568e+30
2019-05-22 09:27:39,273 - brc - INFO - Dev eval result: {'Bleu-1': 0.000207751789590587, 'Bleu-2': 0.0001713414165323148, 'Bleu-3': 0.00015155843778223485, 'Bleu-4': 0.00013963223939713075, 'Rouge-L': 0.09024771443982618}
2019-05-22 09:27:40,401 - brc - INFO - Training the model for epoch 10
2019-05-22 09:32:26,921 - brc - INFO - Average train loss for epoch 10 is 50.90157215384876
2019-05-22 09:32:26,921 - brc - INFO - Evaluating the model after epoch 10
2019-05-22 09:36:06,098 - brc - INFO - Dev eval loss 1.4272000408185568e+30
2019-05-22 09:36:06,098 - brc - INFO - Dev eval result: {'Bleu-1': 0.00028302718069431106, 'Bleu-2': 0.0002323232945054215, 'Bleu-3': 0.00020490673553375858, 'Bleu-4': 0.00018833653411842182, 'Rouge-L': 0.09127889616987248}
2019-05-22 09:36:07,286 - brc - INFO - Training the model for epoch 11
2019-05-22 09:40:50,995 - brc - INFO - Average train loss for epoch 11 is 49.57843467417885
2019-05-22 09:40:50,995 - brc - INFO - Evaluating the model after epoch 11
2019-05-22 09:44:30,756 - brc - INFO - Dev eval loss 1.4272000408185568e+30
2019-05-22 09:44:30,756 - brc - INFO - Dev eval result: {'Bleu-1': 0.0008105488367007855, 'Bleu-2': 0.0006576363412991434, 'Bleu-3': 0.0005744432925364043, 'Bleu-4': 0.000524498804305313, 'Rouge-L': 0.09172285155531076}
2019-05-22 09:44:31,950 - brc - INFO - Training the model for epoch 12
2019-05-22 09:49:15,743 - brc - INFO - Average train loss for epoch 12 is 48.50755073393093
2019-05-22 09:49:15,744 - brc - INFO - Evaluating the model after epoch 12
2019-05-22 09:52:55,563 - brc - INFO - Dev eval loss 1.4272000408185568e+30
2019-05-22 09:52:55,563 - brc - INFO - Dev eval result: {'Bleu-1': 0.00029477035677655857, 'Bleu-2': 0.0002398575150475484, 'Bleu-3': 0.00021016743128676917, 'Bleu-4': 0.0001925042268386254, 'Rouge-L': 0.08516572035047608}
2019-05-22 09:52:56,892 - brc - INFO - Training the model for epoch 13
2019-05-22 09:57:39,898 - brc - INFO - Average train loss for epoch 13 is 47.42127473214094
2019-05-22 09:57:39,899 - brc - INFO - Evaluating the model after epoch 13
2019-05-22 10:01:19,820 - brc - INFO - Dev eval loss 1.4272000408185568e+30
2019-05-22 10:01:19,820 - brc - INFO - Dev eval result: {'Bleu-1': 0.00022779419002081673, 'Bleu-2': 0.00018715059091101586, 'Bleu-3': 0.00016517509231123091, 'Bleu-4': 0.00015180303742089814, 'Rouge-L': 0.08381130030963137}
2019-05-22 10:01:21,039 - brc - INFO - Training the model for epoch 14
2019-05-22 10:05:41,805 - brc - INFO - Average train loss for epoch 14 is 46.515525688143335
2019-05-22 10:05:41,805 - brc - INFO - Evaluating the model after epoch 14
2019-05-22 10:09:09,142 - brc - INFO - Dev eval loss 1.4272000408185568e+30
2019-05-22 10:09:09,142 - brc - INFO - Dev eval result: {'Bleu-1': 0.000979550347439104, 'Bleu-2': 0.0008131253769103104, 'Bleu-3': 0.0007238437482024195, 'Bleu-4': 0.0006703023507283397, 'Rouge-L': 0.09411975195589771}
2019-05-22 10:09:10,456 - brc - INFO - Training the model for epoch 15
2019-05-22 10:13:27,185 - brc - INFO - Average train loss for epoch 15 is 45.841572652844825
2019-05-22 10:13:27,185 - brc - INFO - Evaluating the model after epoch 15
2019-05-22 10:16:54,111 - brc - INFO - Dev eval loss 1.4272000408185568e+30
2019-05-22 10:16:54,111 - brc - INFO - Dev eval result: {'Bleu-1': 0.00025097270050802113, 'Bleu-2': 0.0002066580811978063, 'Bleu-3': 0.00018276392009303826, 'Bleu-4': 0.0001684182514029863, 'Rouge-L': 0.08522526217496058}
2019-05-22 10:16:55,324 - brc - INFO - Training the model for epoch 16
2019-05-22 10:21:12,428 - brc - INFO - Average train loss for epoch 16 is 44.71626194785623
2019-05-22 10:21:12,429 - brc - INFO - Evaluating the model after epoch 16
2019-05-22 10:28:08,420 - brc - INFO - ====== evaluating ======
2019-05-22 10:28:08,421 - brc - INFO - Load data_set and vocab...
2019-05-22 10:28:24,142 - brc - INFO - Dev set size: 5000 questions.
2019-05-22 10:28:24,142 - brc - INFO - Converting text into ids...
2019-05-22 10:28:31,118 - brc - INFO - Restoring the model...
2019-05-22 10:28:39,833 - brc - INFO - applying optimize adam
2019-05-22 10:28:42,373 - brc - INFO - Time to build graph: 5.931354522705078 s
2019-05-22 10:29:28,987 - brc - INFO - ====== evaluating ======
2019-05-22 10:29:28,987 - brc - INFO - Load data_set and vocab...
2019-05-22 10:29:36,983 - brc - INFO - Dev set size: 5000 questions.
2019-05-22 10:29:36,983 - brc - INFO - Converting text into ids...
2019-05-22 10:29:43,769 - brc - INFO - Restoring the model...
2019-05-22 10:29:47,524 - brc - INFO - applying optimize adam
2019-05-22 10:29:49,844 - brc - INFO - Time to build graph: 5.418535947799683 s
2019-05-22 10:30:05,100 - brc - INFO - Model restored from data\models, with prefix r-net
2019-05-22 10:30:05,101 - brc - INFO - Evaluating the model on dev set...
2019-05-22 10:32:22,337 - brc - INFO - ====== evaluating ======
2019-05-22 10:32:22,338 - brc - INFO - Load data_set and vocab...
2019-05-22 10:32:30,268 - brc - INFO - Dev set size: 5000 questions.
2019-05-22 10:32:30,268 - brc - INFO - Converting text into ids...
2019-05-22 10:32:37,056 - brc - INFO - Restoring the model...
2019-05-22 10:32:40,943 - brc - INFO - applying optimize adam
2019-05-22 10:32:43,313 - brc - INFO - Time to build graph: 5.613011837005615 s
2019-05-22 10:32:54,103 - brc - INFO - Model restored from data\models, with prefix r-net
2019-05-22 10:32:54,103 - brc - INFO - Evaluating the model on dev set...
2019-05-22 10:36:08,190 - brc - INFO - Saving dev.predicted results to data\output\dev.predicted.json
2019-05-22 10:36:16,389 - brc - INFO - Loss on dev set: 1.4272000408185568e+30
2019-05-22 10:36:16,389 - brc - INFO - Result on dev set: {'Bleu-1': 0.0005548413268596109, 'Bleu-2': 0.0004496595013426699, 'Bleu-3': 0.00039197896347224195, 'Bleu-4': 0.0003571950473696692, 'Rouge-L': 0.09517327376830859}
2019-05-22 10:36:16,389 - brc - INFO - Predicted answers are saved to data\output
2019-05-22 11:31:35,798 - brc - INFO - ====== evaluating ======
2019-05-22 11:31:35,798 - brc - INFO - Load data_set and vocab...
2019-05-22 11:31:44,007 - brc - INFO - Dev set size: 5000 questions.
2019-05-22 11:31:44,008 - brc - INFO - Converting text into ids...
2019-05-22 11:31:51,096 - brc - INFO - Restoring the model...
2019-05-22 11:32:08,833 - brc - INFO - ====== evaluating ======
2019-05-22 11:32:08,833 - brc - INFO - Load data_set and vocab...
2019-05-22 11:32:16,834 - brc - INFO - Dev set size: 5000 questions.
2019-05-22 11:32:16,834 - brc - INFO - Converting text into ids...
2019-05-22 11:32:23,739 - brc - INFO - Restoring the model...
2019-05-22 11:32:27,526 - brc - INFO - Time to build graph: 3.1186583042144775 s
2019-05-22 11:32:37,826 - brc - INFO - Model restored from data\models, with prefix r-net
2019-05-22 11:32:37,826 - brc - INFO - Evaluating the model on dev set...
2019-05-22 11:35:10,219 - brc - INFO - ====== evaluating ======
2019-05-22 11:35:10,219 - brc - INFO - Load data_set and vocab...
2019-05-22 11:35:18,546 - brc - INFO - Dev set size: 5000 questions.
2019-05-22 11:35:18,546 - brc - INFO - Converting text into ids...
2019-05-22 11:35:25,634 - brc - INFO - Restoring the model...
2019-05-22 11:35:29,444 - brc - INFO - Time to build graph: 3.1635677814483643 s
2019-05-22 11:35:39,773 - brc - INFO - Model restored from data\models, with prefix r-net
2019-05-22 11:35:39,773 - brc - INFO - Evaluating the model on dev set...
2019-05-22 11:38:54,549 - brc - INFO - Saving dev.predicted results to data\output\dev.predicted.json
2019-05-22 11:39:03,175 - brc - INFO - Loss on dev set: 1.4272000408185568e+30
2019-05-22 11:39:03,175 - brc - INFO - Result on dev set: {'Bleu-1': 0.0005548413268596109, 'Bleu-2': 0.0004496595013426699, 'Bleu-3': 0.00039197896347224195, 'Bleu-4': 0.0003571950473696692, 'Rouge-L': 0.09517327376830859}
2019-05-22 11:39:03,176 - brc - INFO - Predicted answers are saved to data\output
2019-05-22 11:47:46,274 - brc - INFO - ====== training ======
2019-05-22 11:47:46,274 - brc - INFO - Load data_set and vocab...
2019-05-22 11:47:52,344 - brc - INFO - Train set size: 4353 questions.
2019-05-22 11:47:59,581 - brc - INFO - Dev set size: 5000 questions.
2019-05-22 11:47:59,581 - brc - INFO - Converting text into ids...
2019-05-22 11:48:13,407 - brc - INFO - Initialize the model...
2019-05-22 11:48:19,825 - brc - INFO - Time to build graph: 5.781534194946289 s
2019-05-22 11:48:30,410 - brc - INFO - Training the model...
2019-05-22 11:48:47,817 - brc - INFO - Training the model for epoch 1
2019-05-22 11:49:02,953 - brc - INFO - Average loss from batch 1 to 8 is 97.06610012054443
2019-05-22 11:49:07,281 - brc - INFO - Average loss from batch 9 to 16 is 90.11544895172119
2019-05-22 11:49:11,610 - brc - INFO - Average loss from batch 17 to 24 is 90.42142391204834
2019-05-22 11:49:16,034 - brc - INFO - Average loss from batch 25 to 32 is 77.63985347747803
2019-05-22 11:49:20,330 - brc - INFO - Average loss from batch 33 to 40 is 84.58415985107422
2019-05-22 11:49:24,829 - brc - INFO - Average loss from batch 41 to 48 is 85.2568473815918
2019-05-22 11:49:29,074 - brc - INFO - Average loss from batch 49 to 56 is 88.84104633331299
2019-05-22 11:49:33,372 - brc - INFO - Average loss from batch 57 to 64 is 81.85954189300537
2019-05-22 11:49:37,751 - brc - INFO - Average loss from batch 65 to 72 is 82.35890197753906
2019-05-22 11:49:42,148 - brc - INFO - Average loss from batch 73 to 80 is 80.40031623840332
2019-05-22 11:49:46,448 - brc - INFO - Average loss from batch 81 to 88 is 78.9688367843628
2019-05-22 11:49:50,763 - brc - INFO - Average loss from batch 89 to 96 is 75.49275064468384
2019-05-22 11:49:55,091 - brc - INFO - Average loss from batch 97 to 104 is 79.71187400817871
2019-05-22 11:49:59,360 - brc - INFO - Average loss from batch 105 to 112 is 73.46906280517578
2019-05-22 11:50:03,782 - brc - INFO - Average loss from batch 113 to 120 is 77.55863571166992
2019-05-22 11:50:08,121 - brc - INFO - Average loss from batch 121 to 128 is 74.50208520889282
2019-05-22 11:50:12,391 - brc - INFO - Average loss from batch 129 to 136 is 70.89883375167847
2019-05-22 11:50:16,772 - brc - INFO - Average loss from batch 137 to 144 is 68.4373288154602
2019-05-22 11:50:21,136 - brc - INFO - Average loss from batch 145 to 152 is 73.43491458892822
2019-05-22 11:50:25,481 - brc - INFO - Average loss from batch 153 to 160 is 72.12709903717041
2019-05-22 11:50:29,873 - brc - INFO - Average loss from batch 161 to 168 is 71.94472694396973
2019-05-22 11:50:34,241 - brc - INFO - Average loss from batch 169 to 176 is 77.78245735168457
2019-05-22 11:50:38,532 - brc - INFO - Average loss from batch 177 to 184 is 70.77057600021362
2019-05-22 11:50:42,956 - brc - INFO - Average loss from batch 185 to 192 is 67.53098678588867
2019-05-22 11:50:47,265 - brc - INFO - Average loss from batch 193 to 200 is 61.26497507095337
2019-05-22 11:50:51,605 - brc - INFO - Average loss from batch 201 to 208 is 69.81879329681396
2019-05-22 11:50:55,982 - brc - INFO - Average loss from batch 209 to 216 is 73.29071521759033
2019-05-22 11:51:00,293 - brc - INFO - Average loss from batch 217 to 224 is 70.82474899291992
2019-05-22 11:51:04,621 - brc - INFO - Average loss from batch 225 to 232 is 70.95083141326904
2019-05-22 11:51:08,921 - brc - INFO - Average loss from batch 233 to 240 is 70.29534721374512
2019-05-22 11:51:13,243 - brc - INFO - Average loss from batch 241 to 248 is 73.09987545013428
2019-05-22 11:51:17,585 - brc - INFO - Average loss from batch 249 to 256 is 68.69818687438965
2019-05-22 11:51:21,968 - brc - INFO - Average loss from batch 257 to 264 is 67.00372886657715
2019-05-22 11:51:26,285 - brc - INFO - Average loss from batch 265 to 272 is 64.42203760147095
2019-05-22 11:51:30,694 - brc - INFO - Average loss from batch 273 to 280 is 74.87815189361572
2019-05-22 11:51:35,025 - brc - INFO - Average loss from batch 281 to 288 is 66.24840593338013
2019-05-22 11:51:39,413 - brc - INFO - Average loss from batch 289 to 296 is 70.73302936553955
2019-05-22 11:51:43,796 - brc - INFO - Average loss from batch 297 to 304 is 71.1913833618164
2019-05-22 11:51:48,097 - brc - INFO - Average loss from batch 305 to 312 is 69.02061653137207
2019-05-22 11:51:52,424 - brc - INFO - Average loss from batch 313 to 320 is 66.04804992675781
2019-05-22 11:51:56,787 - brc - INFO - Average loss from batch 321 to 328 is 64.49684381484985
2019-05-22 11:52:01,067 - brc - INFO - Average loss from batch 329 to 336 is 65.41108751296997
2019-05-22 11:52:05,451 - brc - INFO - Average loss from batch 337 to 344 is 69.08514356613159
2019-05-22 11:52:09,882 - brc - INFO - Average loss from batch 345 to 352 is 63.233338832855225
2019-05-22 11:52:14,221 - brc - INFO - Average loss from batch 353 to 360 is 70.45164966583252
2019-05-22 11:52:18,571 - brc - INFO - Average loss from batch 361 to 368 is 64.12637090682983
2019-05-22 11:52:22,890 - brc - INFO - Average loss from batch 369 to 376 is 66.15634632110596
2019-05-22 11:52:27,271 - brc - INFO - Average loss from batch 377 to 384 is 62.28989934921265
2019-05-22 11:52:31,526 - brc - INFO - Average loss from batch 385 to 392 is 63.544766426086426
2019-05-22 11:52:35,916 - brc - INFO - Average loss from batch 393 to 400 is 61.9034423828125
2019-05-22 11:52:40,275 - brc - INFO - Average loss from batch 401 to 408 is 63.44020318984985
2019-05-22 11:52:44,627 - brc - INFO - Average loss from batch 409 to 416 is 70.28626823425293
2019-05-22 11:52:48,997 - brc - INFO - Average loss from batch 417 to 424 is 69.05225276947021
2019-05-22 11:52:53,349 - brc - INFO - Average loss from batch 425 to 432 is 70.32592248916626
2019-05-22 11:52:57,703 - brc - INFO - Average loss from batch 433 to 440 is 72.390145778656
2019-05-22 11:53:01,933 - brc - INFO - Average loss from batch 441 to 448 is 68.59336566925049
2019-05-22 11:53:06,158 - brc - INFO - Average loss from batch 449 to 456 is 61.8226432800293
2019-05-22 11:53:10,625 - brc - INFO - Average loss from batch 457 to 464 is 65.6745228767395
2019-05-22 11:53:15,007 - brc - INFO - Average loss from batch 465 to 472 is 60.99832725524902
2019-05-22 11:53:19,270 - brc - INFO - Average loss from batch 473 to 480 is 60.85561275482178
2019-05-22 11:53:23,575 - brc - INFO - Average loss from batch 481 to 488 is 68.60184907913208
2019-05-22 11:53:27,860 - brc - INFO - Average loss from batch 489 to 496 is 70.59062957763672
2019-05-22 11:53:32,219 - brc - INFO - Average loss from batch 497 to 504 is 66.61337089538574
2019-05-22 11:53:36,490 - brc - INFO - Average loss from batch 505 to 512 is 67.16186761856079
2019-05-22 11:53:40,874 - brc - INFO - Average loss from batch 513 to 520 is 61.94473218917847
2019-05-22 11:53:45,245 - brc - INFO - Average loss from batch 521 to 528 is 68.75036239624023
2019-05-22 11:53:49,608 - brc - INFO - Average loss from batch 529 to 536 is 68.40306186676025
2019-05-22 11:53:53,993 - brc - INFO - Average loss from batch 537 to 544 is 67.45498180389404
2019-05-22 11:53:54,154 - brc - INFO - Average train loss for epoch 1 is 71.36208373658798
2019-05-22 11:53:54,170 - brc - INFO - Evaluating the model after epoch 1
2019-05-22 11:57:27,505 - brc - INFO - Dev eval loss 1.4272000408185568e+30
2019-05-22 11:57:27,505 - brc - INFO - Dev eval result: {'Bleu-1': 7.710005723407358e-08, 'Bleu-2': 6.065373703311463e-08, 'Bleu-3': 5.085172540749266e-08, 'Bleu-4': 4.460168286026636e-08, 'Rouge-L': 0.05295035954339499}
2019-05-22 11:57:38,577 - brc - INFO - Model saved in data\models, with prefix r-net.
2019-05-22 11:57:39,259 - brc - INFO - Training the model for epoch 2
2019-05-22 11:57:43,590 - brc - INFO - Average loss from batch 1 to 8 is 66.41775417327881
2019-05-22 11:57:47,915 - brc - INFO - Average loss from batch 9 to 16 is 63.32501268386841
2019-05-22 11:57:52,242 - brc - INFO - Average loss from batch 17 to 24 is 71.3919563293457
2019-05-22 11:57:56,556 - brc - INFO - Average loss from batch 25 to 32 is 61.9936900138855
2019-05-22 11:58:00,967 - brc - INFO - Average loss from batch 33 to 40 is 64.73413515090942
2019-05-22 11:58:05,259 - brc - INFO - Average loss from batch 41 to 48 is 64.12859201431274
2019-05-22 11:58:09,722 - brc - INFO - Average loss from batch 49 to 56 is 66.80147171020508
2019-05-22 11:58:14,051 - brc - INFO - Average loss from batch 57 to 64 is 71.50981140136719
2019-05-22 11:58:18,426 - brc - INFO - Average loss from batch 65 to 72 is 68.83851766586304
2019-05-22 11:58:22,786 - brc - INFO - Average loss from batch 73 to 80 is 67.0010986328125
2019-05-22 11:58:27,155 - brc - INFO - Average loss from batch 81 to 88 is 63.65143013000488
2019-05-22 11:58:31,497 - brc - INFO - Average loss from batch 89 to 96 is 68.28794956207275
2019-05-22 11:58:35,787 - brc - INFO - Average loss from batch 97 to 104 is 64.78095197677612
2019-05-22 11:58:40,052 - brc - INFO - Average loss from batch 105 to 112 is 57.5139684677124
2019-05-22 11:58:44,514 - brc - INFO - Average loss from batch 113 to 120 is 62.89634370803833
2019-05-22 11:58:48,967 - brc - INFO - Average loss from batch 121 to 128 is 64.58369207382202
2019-05-22 11:58:53,263 - brc - INFO - Average loss from batch 129 to 136 is 54.03128719329834
2019-05-22 11:58:57,713 - brc - INFO - Average loss from batch 137 to 144 is 62.50358819961548
2019-05-22 11:59:02,109 - brc - INFO - Average loss from batch 145 to 152 is 61.061243534088135
2019-05-22 11:59:06,435 - brc - INFO - Average loss from batch 153 to 160 is 62.41434288024902
2019-05-22 11:59:10,745 - brc - INFO - Average loss from batch 161 to 168 is 63.416447162628174
2019-05-22 11:59:15,029 - brc - INFO - Average loss from batch 169 to 176 is 66.96622228622437
2019-05-22 11:59:19,362 - brc - INFO - Average loss from batch 177 to 184 is 60.425243854522705
2019-05-22 11:59:23,748 - brc - INFO - Average loss from batch 185 to 192 is 67.79476404190063
2019-05-22 11:59:28,066 - brc - INFO - Average loss from batch 193 to 200 is 61.62082242965698
2019-05-22 11:59:32,424 - brc - INFO - Average loss from batch 201 to 208 is 66.68890857696533
2019-05-22 11:59:36,810 - brc - INFO - Average loss from batch 209 to 216 is 67.86765336990356
2019-05-22 11:59:41,088 - brc - INFO - Average loss from batch 217 to 224 is 64.54621505737305
2019-05-22 11:59:45,340 - brc - INFO - Average loss from batch 225 to 232 is 62.068891525268555
2019-05-22 11:59:49,690 - brc - INFO - Average loss from batch 233 to 240 is 61.35607099533081
2019-05-22 11:59:54,140 - brc - INFO - Average loss from batch 241 to 248 is 69.0515775680542
2019-05-22 11:59:58,542 - brc - INFO - Average loss from batch 249 to 256 is 63.72380304336548
2019-05-22 12:00:02,938 - brc - INFO - Average loss from batch 257 to 264 is 64.97650671005249
2019-05-22 12:00:07,214 - brc - INFO - Average loss from batch 265 to 272 is 54.4037971496582
2019-05-22 12:00:11,501 - brc - INFO - Average loss from batch 273 to 280 is 58.09987020492554
2019-05-22 12:00:15,817 - brc - INFO - Average loss from batch 281 to 288 is 64.512930393219
2019-05-22 12:00:20,092 - brc - INFO - Average loss from batch 289 to 296 is 64.9698600769043
2019-05-22 12:00:24,433 - brc - INFO - Average loss from batch 297 to 304 is 62.99723148345947
2019-05-22 12:00:28,726 - brc - INFO - Average loss from batch 305 to 312 is 61.68753433227539
2019-05-22 12:00:33,122 - brc - INFO - Average loss from batch 313 to 320 is 58.19953203201294
2019-05-22 12:00:37,481 - brc - INFO - Average loss from batch 321 to 328 is 65.67390155792236
2019-05-22 12:00:41,903 - brc - INFO - Average loss from batch 329 to 336 is 61.33992290496826
2019-05-22 12:00:46,263 - brc - INFO - Average loss from batch 337 to 344 is 63.47401666641235
2019-05-22 12:00:50,670 - brc - INFO - Average loss from batch 345 to 352 is 62.45338535308838
2019-05-22 12:00:55,029 - brc - INFO - Average loss from batch 353 to 360 is 58.93946409225464
2019-05-22 12:00:59,541 - brc - INFO - Average loss from batch 361 to 368 is 61.94526386260986
2019-05-22 12:01:03,842 - brc - INFO - Average loss from batch 369 to 376 is 50.496497631073
2019-05-22 12:01:08,182 - brc - INFO - Average loss from batch 377 to 384 is 61.50405216217041
2019-05-22 12:01:12,546 - brc - INFO - Average loss from batch 385 to 392 is 61.232529163360596
2019-05-22 12:01:16,891 - brc - INFO - Average loss from batch 393 to 400 is 62.521225452423096
2019-05-22 12:01:21,398 - brc - INFO - Average loss from batch 401 to 408 is 59.45693111419678
2019-05-22 12:01:25,894 - brc - INFO - Average loss from batch 409 to 416 is 57.60922908782959
2019-05-22 12:01:30,427 - brc - INFO - Average loss from batch 417 to 424 is 65.57341146469116
2019-05-22 12:01:34,979 - brc - INFO - Average loss from batch 425 to 432 is 61.96116828918457
2019-05-22 12:01:39,701 - brc - INFO - Average loss from batch 433 to 440 is 63.02586364746094
2019-05-22 12:01:44,212 - brc - INFO - Average loss from batch 441 to 448 is 59.77881574630737
2019-05-22 12:01:48,845 - brc - INFO - Average loss from batch 449 to 456 is 56.13509750366211
2019-05-22 12:01:53,443 - brc - INFO - Average loss from batch 457 to 464 is 63.47752285003662
2019-05-22 12:01:57,970 - brc - INFO - Average loss from batch 465 to 472 is 54.55798149108887
2019-05-22 12:02:02,582 - brc - INFO - Average loss from batch 473 to 480 is 64.93679285049438
2019-05-22 12:02:07,238 - brc - INFO - Average loss from batch 481 to 488 is 60.60773420333862
2019-05-22 12:02:11,797 - brc - INFO - Average loss from batch 489 to 496 is 59.612903118133545
2019-05-22 12:02:16,327 - brc - INFO - Average loss from batch 497 to 504 is 64.58216762542725
2019-05-22 12:02:20,910 - brc - INFO - Average loss from batch 505 to 512 is 62.654964447021484
2019-05-22 12:02:25,498 - brc - INFO - Average loss from batch 513 to 520 is 53.51025056838989
2019-05-22 12:02:30,061 - brc - INFO - Average loss from batch 521 to 528 is 61.24738883972168
2019-05-22 12:02:34,564 - brc - INFO - Average loss from batch 529 to 536 is 64.36088514328003
2019-05-22 12:02:39,168 - brc - INFO - Average loss from batch 537 to 544 is 62.89126110076904
2019-05-22 12:02:39,280 - brc - INFO - Average train loss for epoch 2 is 62.62943158430212
2019-05-22 12:02:39,280 - brc - INFO - Evaluating the model after epoch 2
2019-05-22 12:06:22,194 - brc - INFO - Dev eval loss 1.4272000408185568e+30
2019-05-22 12:06:22,194 - brc - INFO - Dev eval result: {'Bleu-1': 5.5033818051818925e-05, 'Bleu-2': 4.393487236186271e-05, 'Bleu-3': 3.795342618755795e-05, 'Bleu-4': 3.430571315622523e-05, 'Rouge-L': 0.0791352871841538}
2019-05-22 12:06:35,513 - brc - INFO - Model saved in data\models, with prefix r-net.
2019-05-22 12:06:36,183 - brc - INFO - Training the model for epoch 3
2019-05-22 12:06:40,689 - brc - INFO - Average loss from batch 1 to 8 is 57.6937050819397
2019-05-22 12:06:45,285 - brc - INFO - Average loss from batch 9 to 16 is 54.06975698471069
2019-05-22 12:06:49,773 - brc - INFO - Average loss from batch 17 to 24 is 63.65578317642212
2019-05-22 12:06:54,355 - brc - INFO - Average loss from batch 25 to 32 is 61.05308437347412
2019-05-22 12:06:58,847 - brc - INFO - Average loss from batch 33 to 40 is 60.24923372268677
2019-05-22 12:07:03,325 - brc - INFO - Average loss from batch 41 to 48 is 59.371981620788574
2019-05-22 12:07:07,842 - brc - INFO - Average loss from batch 49 to 56 is 58.50333833694458
2019-05-22 12:07:12,389 - brc - INFO - Average loss from batch 57 to 64 is 62.435580253601074
2019-05-22 12:07:16,947 - brc - INFO - Average loss from batch 65 to 72 is 58.89288091659546
2019-05-22 12:07:21,448 - brc - INFO - Average loss from batch 73 to 80 is 54.99903392791748
2019-05-22 12:07:26,085 - brc - INFO - Average loss from batch 81 to 88 is 60.49926233291626
2019-05-22 12:07:30,648 - brc - INFO - Average loss from batch 89 to 96 is 61.57681465148926
2019-05-22 12:07:35,261 - brc - INFO - Average loss from batch 97 to 104 is 66.37991094589233
2019-05-22 12:07:39,916 - brc - INFO - Average loss from batch 105 to 112 is 57.054041385650635
2019-05-22 12:07:44,394 - brc - INFO - Average loss from batch 113 to 120 is 58.82856035232544
2019-05-22 12:07:48,933 - brc - INFO - Average loss from batch 121 to 128 is 59.081899642944336
2019-05-22 12:07:53,465 - brc - INFO - Average loss from batch 129 to 136 is 60.533761978149414
2019-05-22 12:07:57,882 - brc - INFO - Average loss from batch 137 to 144 is 63.51131343841553
2019-05-22 12:08:02,395 - brc - INFO - Average loss from batch 145 to 152 is 59.789135456085205
2019-05-22 12:08:06,939 - brc - INFO - Average loss from batch 153 to 160 is 61.81095552444458
2019-05-22 12:08:11,557 - brc - INFO - Average loss from batch 161 to 168 is 57.363224029541016
2019-05-22 12:08:16,028 - brc - INFO - Average loss from batch 169 to 176 is 61.37624216079712
2019-05-22 12:08:20,540 - brc - INFO - Average loss from batch 177 to 184 is 60.6830792427063
2019-05-22 12:08:25,012 - brc - INFO - Average loss from batch 185 to 192 is 46.35378813743591
2019-05-22 12:08:29,536 - brc - INFO - Average loss from batch 193 to 200 is 59.464669704437256
2019-05-22 12:08:34,063 - brc - INFO - Average loss from batch 201 to 208 is 57.77402353286743
2019-05-22 12:08:38,668 - brc - INFO - Average loss from batch 209 to 216 is 61.276681900024414
2019-05-22 12:08:43,176 - brc - INFO - Average loss from batch 217 to 224 is 58.402748584747314
2019-05-22 12:08:47,722 - brc - INFO - Average loss from batch 225 to 232 is 64.1052598953247
2019-05-22 12:08:52,263 - brc - INFO - Average loss from batch 233 to 240 is 60.61029577255249
2019-05-22 12:08:56,809 - brc - INFO - Average loss from batch 241 to 248 is 55.35980844497681
2019-05-22 12:09:01,431 - brc - INFO - Average loss from batch 249 to 256 is 60.11102867126465
2019-05-22 12:09:06,104 - brc - INFO - Average loss from batch 257 to 264 is 67.06981563568115
2019-05-22 12:09:10,589 - brc - INFO - Average loss from batch 265 to 272 is 53.688788414001465
2019-05-22 12:09:15,113 - brc - INFO - Average loss from batch 273 to 280 is 57.90202283859253
2019-05-22 12:09:19,629 - brc - INFO - Average loss from batch 281 to 288 is 55.178038120269775
2019-05-22 12:09:24,151 - brc - INFO - Average loss from batch 289 to 296 is 54.107643127441406
2019-05-22 12:09:28,648 - brc - INFO - Average loss from batch 297 to 304 is 59.74501895904541
2019-05-22 12:09:33,375 - brc - INFO - Average loss from batch 305 to 312 is 63.196579933166504
2019-05-22 12:09:38,005 - brc - INFO - Average loss from batch 313 to 320 is 55.13957405090332
2019-05-22 12:09:42,580 - brc - INFO - Average loss from batch 321 to 328 is 61.50196647644043
2019-05-22 12:09:47,146 - brc - INFO - Average loss from batch 329 to 336 is 61.829386711120605
2019-05-22 12:09:51,767 - brc - INFO - Average loss from batch 337 to 344 is 59.29239511489868
2019-05-22 12:09:56,328 - brc - INFO - Average loss from batch 345 to 352 is 59.02078914642334
2019-05-22 12:10:00,791 - brc - INFO - Average loss from batch 353 to 360 is 58.13697910308838
2019-05-22 12:10:05,460 - brc - INFO - Average loss from batch 361 to 368 is 66.92859649658203
2019-05-22 12:10:09,971 - brc - INFO - Average loss from batch 369 to 376 is 63.45247173309326
2019-05-22 12:10:14,503 - brc - INFO - Average loss from batch 377 to 384 is 62.62803888320923
2019-05-22 12:10:19,087 - brc - INFO - Average loss from batch 385 to 392 is 59.74758863449097
2019-05-22 12:10:23,586 - brc - INFO - Average loss from batch 393 to 400 is 58.138278007507324
2019-05-22 12:10:28,115 - brc - INFO - Average loss from batch 401 to 408 is 59.36531734466553
2019-05-22 12:10:32,609 - brc - INFO - Average loss from batch 409 to 416 is 62.929030895233154
2019-05-22 12:10:37,180 - brc - INFO - Average loss from batch 417 to 424 is 64.42378234863281
2019-05-22 12:10:41,721 - brc - INFO - Average loss from batch 425 to 432 is 54.355021953582764
2019-05-22 12:10:46,331 - brc - INFO - Average loss from batch 433 to 440 is 59.9893741607666
2019-05-22 12:10:50,865 - brc - INFO - Average loss from batch 441 to 448 is 59.12376165390015
2019-05-22 12:10:55,366 - brc - INFO - Average loss from batch 449 to 456 is 59.53862190246582
2019-05-22 12:10:59,893 - brc - INFO - Average loss from batch 457 to 464 is 59.71581745147705
2019-05-22 12:11:04,438 - brc - INFO - Average loss from batch 465 to 472 is 65.87170839309692
2019-05-22 12:11:08,926 - brc - INFO - Average loss from batch 473 to 480 is 61.17152452468872
2019-05-22 12:11:13,392 - brc - INFO - Average loss from batch 481 to 488 is 61.57504081726074
2019-05-22 12:11:17,870 - brc - INFO - Average loss from batch 489 to 496 is 61.97266674041748
2019-05-22 12:11:22,504 - brc - INFO - Average loss from batch 497 to 504 is 59.399383544921875
2019-05-22 12:11:27,151 - brc - INFO - Average loss from batch 505 to 512 is 56.070557594299316
2019-05-22 12:11:31,746 - brc - INFO - Average loss from batch 513 to 520 is 58.007686614990234
2019-05-22 12:11:36,363 - brc - INFO - Average loss from batch 521 to 528 is 63.25392198562622
2019-05-22 12:11:40,945 - brc - INFO - Average loss from batch 529 to 536 is 56.79927444458008
2019-05-22 12:11:45,476 - brc - INFO - Average loss from batch 537 to 544 is 57.63624286651611
2019-05-22 12:11:45,485 - brc - INFO - Average train loss for epoch 3 is 59.71725868828156
2019-05-22 12:11:45,486 - brc - INFO - Evaluating the model after epoch 3
2019-05-22 12:15:31,514 - brc - INFO - Dev eval loss 1.4272000408185568e+30
2019-05-22 12:15:31,514 - brc - INFO - Dev eval result: {'Bleu-1': 0.00012054832842608379, 'Bleu-2': 9.711717007304264e-05, 'Bleu-3': 8.463517293783363e-05, 'Bleu-4': 7.718604486360024e-05, 'Rouge-L': 0.08050130173927361}
2019-05-22 12:15:44,109 - brc - INFO - Model saved in data\models, with prefix r-net.
2019-05-22 12:15:44,785 - brc - INFO - Training the model for epoch 4
2019-05-22 12:15:49,409 - brc - INFO - Average loss from batch 1 to 8 is 59.15395927429199
2019-05-22 12:15:53,953 - brc - INFO - Average loss from batch 9 to 16 is 60.53393840789795
2019-05-22 12:15:58,535 - brc - INFO - Average loss from batch 17 to 24 is 55.01188945770264
2019-05-22 12:16:03,140 - brc - INFO - Average loss from batch 25 to 32 is 63.33142566680908
2019-05-22 12:16:07,691 - brc - INFO - Average loss from batch 33 to 40 is 58.014723777770996
2019-05-22 12:16:12,194 - brc - INFO - Average loss from batch 41 to 48 is 54.430670738220215
2019-05-22 12:16:16,740 - brc - INFO - Average loss from batch 49 to 56 is 70.28377676010132
2019-05-22 12:16:21,306 - brc - INFO - Average loss from batch 57 to 64 is 53.08823490142822
2019-05-22 12:16:25,856 - brc - INFO - Average loss from batch 65 to 72 is 57.597763538360596
2019-05-22 12:16:30,403 - brc - INFO - Average loss from batch 73 to 80 is 54.84309196472168
2019-05-22 12:16:34,930 - brc - INFO - Average loss from batch 81 to 88 is 64.04197978973389
2019-05-22 12:16:39,539 - brc - INFO - Average loss from batch 89 to 96 is 55.516146183013916
2019-05-22 12:16:44,145 - brc - INFO - Average loss from batch 97 to 104 is 61.822948932647705
2019-05-22 12:16:48,700 - brc - INFO - Average loss from batch 105 to 112 is 58.25303316116333
2019-05-22 12:16:53,238 - brc - INFO - Average loss from batch 113 to 120 is 59.12892770767212
2019-05-22 12:16:57,820 - brc - INFO - Average loss from batch 121 to 128 is 64.46537065505981
2019-05-22 12:17:02,347 - brc - INFO - Average loss from batch 129 to 136 is 49.831472396850586
2019-05-22 12:17:07,020 - brc - INFO - Average loss from batch 137 to 144 is 52.558510303497314
2019-05-22 12:17:11,620 - brc - INFO - Average loss from batch 145 to 152 is 56.45703172683716
2019-05-22 12:17:16,177 - brc - INFO - Average loss from batch 153 to 160 is 59.14913606643677
2019-05-22 12:17:20,663 - brc - INFO - Average loss from batch 161 to 168 is 59.80454397201538
2019-05-22 12:17:25,267 - brc - INFO - Average loss from batch 169 to 176 is 56.633745193481445
2019-05-22 12:17:29,807 - brc - INFO - Average loss from batch 177 to 184 is 54.45586395263672
2019-05-22 12:17:34,434 - brc - INFO - Average loss from batch 185 to 192 is 59.26582431793213
2019-05-22 12:17:38,976 - brc - INFO - Average loss from batch 193 to 200 is 63.97138738632202
2019-05-22 12:17:43,477 - brc - INFO - Average loss from batch 201 to 208 is 52.42203378677368
2019-05-22 12:17:48,015 - brc - INFO - Average loss from batch 209 to 216 is 57.63161563873291
2019-05-22 12:17:52,529 - brc - INFO - Average loss from batch 217 to 224 is 61.98122835159302
2019-05-22 12:17:57,011 - brc - INFO - Average loss from batch 225 to 232 is 49.09296131134033
2019-05-22 12:18:01,597 - brc - INFO - Average loss from batch 233 to 240 is 60.53631639480591
2019-05-22 12:18:06,250 - brc - INFO - Average loss from batch 241 to 248 is 62.537842750549316
2019-05-22 12:18:10,787 - brc - INFO - Average loss from batch 249 to 256 is 52.69623279571533
2019-05-22 12:18:15,282 - brc - INFO - Average loss from batch 257 to 264 is 63.58481740951538
2019-05-22 12:18:19,788 - brc - INFO - Average loss from batch 265 to 272 is 56.093185901641846
2019-05-22 12:18:24,380 - brc - INFO - Average loss from batch 273 to 280 is 58.92648267745972
2019-05-22 12:18:28,986 - brc - INFO - Average loss from batch 281 to 288 is 65.79467582702637
2019-05-22 12:18:33,480 - brc - INFO - Average loss from batch 289 to 296 is 58.48546504974365
2019-05-22 12:18:38,075 - brc - INFO - Average loss from batch 297 to 304 is 57.645540714263916
2019-05-22 12:18:42,641 - brc - INFO - Average loss from batch 305 to 312 is 58.113754749298096
2019-05-22 12:18:47,140 - brc - INFO - Average loss from batch 313 to 320 is 56.587246894836426
2019-05-22 12:18:51,696 - brc - INFO - Average loss from batch 321 to 328 is 51.4570369720459
2019-05-22 12:18:56,336 - brc - INFO - Average loss from batch 329 to 336 is 62.98002481460571
2019-05-22 12:19:00,933 - brc - INFO - Average loss from batch 337 to 344 is 63.79836463928223
2019-05-22 12:19:05,498 - brc - INFO - Average loss from batch 345 to 352 is 57.678138732910156
2019-05-22 12:19:10,012 - brc - INFO - Average loss from batch 353 to 360 is 55.07420349121094
2019-05-22 12:19:14,531 - brc - INFO - Average loss from batch 361 to 368 is 65.88560628890991
2019-05-22 12:19:19,043 - brc - INFO - Average loss from batch 369 to 376 is 51.250383377075195
2019-05-22 12:19:23,574 - brc - INFO - Average loss from batch 377 to 384 is 60.45034742355347
2019-05-22 12:19:28,037 - brc - INFO - Average loss from batch 385 to 392 is 59.27231407165527
2019-05-22 12:19:32,545 - brc - INFO - Average loss from batch 393 to 400 is 54.56007385253906
2019-05-22 12:19:37,112 - brc - INFO - Average loss from batch 401 to 408 is 56.36495304107666
2019-05-22 12:19:41,583 - brc - INFO - Average loss from batch 409 to 416 is 54.89935874938965
2019-05-22 12:19:46,146 - brc - INFO - Average loss from batch 417 to 424 is 56.10257339477539
2019-05-22 12:19:50,695 - brc - INFO - Average loss from batch 425 to 432 is 51.504199504852295
2019-05-22 12:19:55,285 - brc - INFO - Average loss from batch 433 to 440 is 60.53037738800049
2019-05-22 12:19:59,910 - brc - INFO - Average loss from batch 441 to 448 is 62.809863567352295
2019-05-22 12:20:04,464 - brc - INFO - Average loss from batch 449 to 456 is 58.58720302581787
2019-05-22 12:20:08,954 - brc - INFO - Average loss from batch 457 to 464 is 62.447041034698486
2019-05-22 12:20:13,550 - brc - INFO - Average loss from batch 465 to 472 is 53.733062744140625
2019-05-22 12:20:18,208 - brc - INFO - Average loss from batch 473 to 480 is 59.94663763046265
2019-05-22 12:20:22,718 - brc - INFO - Average loss from batch 481 to 488 is 60.18859004974365
2019-05-22 12:20:27,234 - brc - INFO - Average loss from batch 489 to 496 is 61.63736820220947
2019-05-22 12:20:31,706 - brc - INFO - Average loss from batch 497 to 504 is 58.01633405685425
2019-05-22 12:20:36,236 - brc - INFO - Average loss from batch 505 to 512 is 59.29872131347656
2019-05-22 12:20:40,802 - brc - INFO - Average loss from batch 513 to 520 is 58.11491823196411
2019-05-22 12:20:45,353 - brc - INFO - Average loss from batch 521 to 528 is 60.274263858795166
2019-05-22 12:20:49,912 - brc - INFO - Average loss from batch 529 to 536 is 51.9102463722229
2019-05-22 12:20:54,452 - brc - INFO - Average loss from batch 537 to 544 is 52.644290924072266
2019-05-22 12:20:54,462 - brc - INFO - Average train loss for epoch 4 is 58.16457784175873
2019-05-22 12:20:54,462 - brc - INFO - Evaluating the model after epoch 4
2019-05-22 12:24:37,571 - brc - INFO - Dev eval loss 1.4272000408185568e+30
2019-05-22 12:24:37,571 - brc - INFO - Dev eval result: {'Bleu-1': 0.000530685131796038, 'Bleu-2': 0.0004293877341061053, 'Bleu-3': 0.00037503026319202074, 'Bleu-4': 0.000342287262725508, 'Rouge-L': 0.08781894409433855}
2019-05-22 12:24:50,845 - brc - INFO - Model saved in data\models, with prefix r-net.
2019-05-22 12:24:51,530 - brc - INFO - Training the model for epoch 5
2019-05-22 12:24:56,051 - brc - INFO - Average loss from batch 1 to 8 is 53.89859342575073
2019-05-22 12:25:00,815 - brc - INFO - Average loss from batch 9 to 16 is 56.70378494262695
2019-05-22 12:25:05,368 - brc - INFO - Average loss from batch 17 to 24 is 55.61574125289917
2019-05-22 12:25:09,935 - brc - INFO - Average loss from batch 25 to 32 is 54.6405611038208
2019-05-22 12:25:14,510 - brc - INFO - Average loss from batch 33 to 40 is 59.574769020080566
2019-05-22 12:25:19,104 - brc - INFO - Average loss from batch 41 to 48 is 55.43197679519653
2019-05-22 12:25:23,561 - brc - INFO - Average loss from batch 49 to 56 is 55.19842052459717
2019-05-22 12:25:28,069 - brc - INFO - Average loss from batch 57 to 64 is 61.44915819168091
2019-05-22 12:25:32,622 - brc - INFO - Average loss from batch 65 to 72 is 59.035460472106934
2019-05-22 12:25:37,225 - brc - INFO - Average loss from batch 73 to 80 is 58.059603691101074
2019-05-22 12:25:41,752 - brc - INFO - Average loss from batch 81 to 88 is 54.7869610786438
2019-05-22 12:25:46,225 - brc - INFO - Average loss from batch 89 to 96 is 62.397677421569824
2019-05-22 12:25:50,750 - brc - INFO - Average loss from batch 97 to 104 is 61.622000217437744
2019-05-22 12:25:55,278 - brc - INFO - Average loss from batch 105 to 112 is 52.57897329330444
2019-05-22 12:25:59,814 - brc - INFO - Average loss from batch 113 to 120 is 54.07025384902954
2019-05-22 12:26:04,328 - brc - INFO - Average loss from batch 121 to 128 is 59.499980449676514
2019-05-22 12:26:08,914 - brc - INFO - Average loss from batch 129 to 136 is 58.70113801956177
2019-05-22 12:26:13,470 - brc - INFO - Average loss from batch 137 to 144 is 61.128145694732666
2019-05-22 12:26:18,081 - brc - INFO - Average loss from batch 145 to 152 is 60.08944749832153
2019-05-22 12:26:22,574 - brc - INFO - Average loss from batch 153 to 160 is 52.96773624420166
2019-05-22 12:26:27,184 - brc - INFO - Average loss from batch 161 to 168 is 56.62442493438721
2019-05-22 12:26:31,722 - brc - INFO - Average loss from batch 169 to 176 is 54.58387088775635
2019-05-22 12:26:36,223 - brc - INFO - Average loss from batch 177 to 184 is 59.932626724243164
2019-05-22 12:26:40,630 - brc - INFO - Average loss from batch 185 to 192 is 57.5475869178772
2019-05-22 12:26:45,200 - brc - INFO - Average loss from batch 193 to 200 is 61.840275287628174
2019-05-22 12:26:49,751 - brc - INFO - Average loss from batch 201 to 208 is 62.37057638168335
2019-05-22 12:26:54,325 - brc - INFO - Average loss from batch 209 to 216 is 58.03877067565918
2019-05-22 12:26:58,938 - brc - INFO - Average loss from batch 217 to 224 is 64.05927228927612
2019-05-22 12:27:03,470 - brc - INFO - Average loss from batch 225 to 232 is 51.260313510894775
2019-05-22 12:27:07,975 - brc - INFO - Average loss from batch 233 to 240 is 62.64162874221802
2019-05-22 12:27:12,532 - brc - INFO - Average loss from batch 241 to 248 is 59.50345802307129
2019-05-22 12:27:17,102 - brc - INFO - Average loss from batch 249 to 256 is 51.5457649230957
2019-05-22 12:27:21,618 - brc - INFO - Average loss from batch 257 to 264 is 51.79957151412964
2019-05-22 12:27:26,227 - brc - INFO - Average loss from batch 265 to 272 is 57.75647830963135
2019-05-22 12:27:30,712 - brc - INFO - Average loss from batch 273 to 280 is 58.36683416366577
2019-05-22 12:27:35,322 - brc - INFO - Average loss from batch 281 to 288 is 55.61575174331665
2019-05-22 12:27:39,992 - brc - INFO - Average loss from batch 289 to 296 is 58.05460596084595
2019-05-22 12:27:44,562 - brc - INFO - Average loss from batch 297 to 304 is 57.70877647399902
2019-05-22 12:27:49,024 - brc - INFO - Average loss from batch 305 to 312 is 58.18063926696777
2019-05-22 12:27:53,507 - brc - INFO - Average loss from batch 313 to 320 is 55.350162982940674
2019-05-22 12:27:58,036 - brc - INFO - Average loss from batch 321 to 328 is 56.32505798339844
2019-05-22 12:28:02,686 - brc - INFO - Average loss from batch 329 to 336 is 50.64700698852539
2019-05-22 12:28:07,237 - brc - INFO - Average loss from batch 337 to 344 is 58.4156494140625
2019-05-22 12:28:11,780 - brc - INFO - Average loss from batch 345 to 352 is 51.23325777053833
2019-05-22 12:28:16,289 - brc - INFO - Average loss from batch 353 to 360 is 59.657187938690186
2019-05-22 12:28:20,826 - brc - INFO - Average loss from batch 361 to 368 is 61.69992542266846
2019-05-22 12:28:25,405 - brc - INFO - Average loss from batch 369 to 376 is 57.05223798751831
2019-05-22 12:28:29,958 - brc - INFO - Average loss from batch 377 to 384 is 54.893693923950195
2019-05-22 12:28:34,570 - brc - INFO - Average loss from batch 385 to 392 is 59.902931690216064
2019-05-22 12:28:39,099 - brc - INFO - Average loss from batch 393 to 400 is 50.04650068283081
2019-05-22 12:28:43,691 - brc - INFO - Average loss from batch 401 to 408 is 51.2624831199646
2019-05-22 12:28:48,228 - brc - INFO - Average loss from batch 409 to 416 is 57.49097394943237
2019-05-22 12:28:52,818 - brc - INFO - Average loss from batch 417 to 424 is 60.295480728149414
2019-05-22 12:28:57,401 - brc - INFO - Average loss from batch 425 to 432 is 52.11842346191406
2019-05-22 12:29:01,910 - brc - INFO - Average loss from batch 433 to 440 is 54.729947090148926
2019-05-22 12:29:06,482 - brc - INFO - Average loss from batch 441 to 448 is 58.5450119972229
2019-05-22 12:29:10,947 - brc - INFO - Average loss from batch 449 to 456 is 52.27839422225952
2019-05-22 12:29:15,496 - brc - INFO - Average loss from batch 457 to 464 is 50.93279409408569
2019-05-22 12:29:19,951 - brc - INFO - Average loss from batch 465 to 472 is 53.781200885772705
2019-05-22 12:29:24,537 - brc - INFO - Average loss from batch 473 to 480 is 54.76831531524658
2019-05-22 12:29:29,095 - brc - INFO - Average loss from batch 481 to 488 is 56.61683702468872
2019-05-22 12:29:33,639 - brc - INFO - Average loss from batch 489 to 496 is 57.14790105819702
2019-05-22 12:29:38,259 - brc - INFO - Average loss from batch 497 to 504 is 55.97210741043091
2019-05-22 12:29:42,782 - brc - INFO - Average loss from batch 505 to 512 is 62.82880210876465
2019-05-22 12:29:47,367 - brc - INFO - Average loss from batch 513 to 520 is 65.76016902923584
2019-05-22 12:29:51,987 - brc - INFO - Average loss from batch 521 to 528 is 50.24137306213379
2019-05-22 12:29:56,548 - brc - INFO - Average loss from batch 529 to 536 is 59.90886211395264
2019-05-22 12:30:01,200 - brc - INFO - Average loss from batch 537 to 544 is 56.47994375228882
2019-05-22 12:30:01,208 - brc - INFO - Average train loss for epoch 5 is 56.93035651655758
2019-05-22 12:30:01,208 - brc - INFO - Evaluating the model after epoch 5
2019-05-22 12:33:43,483 - brc - INFO - Dev eval loss 1.4272000408185568e+30
2019-05-22 12:33:43,483 - brc - INFO - Dev eval result: {'Bleu-1': 0.0005941118494745791, 'Bleu-2': 0.00048368514178459885, 'Bleu-3': 0.00042514236043366684, 'Bleu-4': 0.0003901954847374765, 'Rouge-L': 0.08994344291410322}
2019-05-22 12:33:54,791 - brc - INFO - Model saved in data\models, with prefix r-net.
2019-05-22 12:33:55,474 - brc - INFO - Training the model for epoch 6
2019-05-22 12:33:59,992 - brc - INFO - Average loss from batch 1 to 8 is 60.54022932052612
2019-05-22 12:34:04,499 - brc - INFO - Average loss from batch 9 to 16 is 60.1020245552063
2019-05-22 12:34:09,091 - brc - INFO - Average loss from batch 17 to 24 is 56.80700731277466
2019-05-22 12:34:13,684 - brc - INFO - Average loss from batch 25 to 32 is 53.787578105926514
2019-05-22 12:34:18,225 - brc - INFO - Average loss from batch 33 to 40 is 58.37535810470581
2019-05-22 12:34:22,862 - brc - INFO - Average loss from batch 41 to 48 is 54.32726192474365
2019-05-22 12:34:27,401 - brc - INFO - Average loss from batch 49 to 56 is 54.1003794670105
2019-05-22 12:34:32,046 - brc - INFO - Average loss from batch 57 to 64 is 54.32209873199463
2019-05-22 12:34:36,583 - brc - INFO - Average loss from batch 65 to 72 is 49.2654185295105
2019-05-22 12:34:41,114 - brc - INFO - Average loss from batch 73 to 80 is 56.96579837799072
2019-05-22 12:34:45,683 - brc - INFO - Average loss from batch 81 to 88 is 56.293107986450195
2019-05-22 12:34:50,232 - brc - INFO - Average loss from batch 89 to 96 is 54.8241605758667
2019-05-22 12:34:54,812 - brc - INFO - Average loss from batch 97 to 104 is 53.6912145614624
2019-05-22 12:34:59,414 - brc - INFO - Average loss from batch 105 to 112 is 57.99371862411499
2019-05-22 12:35:03,959 - brc - INFO - Average loss from batch 113 to 120 is 57.17480421066284
2019-05-22 12:35:08,585 - brc - INFO - Average loss from batch 121 to 128 is 52.63382625579834
2019-05-22 12:35:13,213 - brc - INFO - Average loss from batch 129 to 136 is 58.022706031799316
2019-05-22 12:35:17,824 - brc - INFO - Average loss from batch 137 to 144 is 52.970282554626465
2019-05-22 12:35:22,533 - brc - INFO - Average loss from batch 145 to 152 is 59.40125560760498
2019-05-22 12:35:27,097 - brc - INFO - Average loss from batch 153 to 160 is 53.471370220184326
2019-05-22 12:35:31,651 - brc - INFO - Average loss from batch 161 to 168 is 57.46941328048706
2019-05-22 12:35:36,190 - brc - INFO - Average loss from batch 169 to 176 is 53.70968723297119
2019-05-22 12:35:40,748 - brc - INFO - Average loss from batch 177 to 184 is 54.81498336791992
2019-05-22 12:35:45,349 - brc - INFO - Average loss from batch 185 to 192 is 53.63993549346924
2019-05-22 12:35:49,958 - brc - INFO - Average loss from batch 193 to 200 is 58.145949363708496
2019-05-22 12:35:54,577 - brc - INFO - Average loss from batch 201 to 208 is 55.067806243896484
2019-05-22 12:35:59,122 - brc - INFO - Average loss from batch 209 to 216 is 57.0364089012146
2019-05-22 12:36:03,729 - brc - INFO - Average loss from batch 217 to 224 is 55.5502142906189
2019-05-22 12:36:08,246 - brc - INFO - Average loss from batch 225 to 232 is 57.25100517272949
2019-05-22 12:36:12,874 - brc - INFO - Average loss from batch 233 to 240 is 61.956788539886475
2019-05-22 12:36:17,511 - brc - INFO - Average loss from batch 241 to 248 is 49.150452613830566
2019-05-22 12:36:22,178 - brc - INFO - Average loss from batch 249 to 256 is 55.36211395263672
2019-05-22 12:36:26,727 - brc - INFO - Average loss from batch 257 to 264 is 55.80582904815674
2019-05-22 12:36:31,300 - brc - INFO - Average loss from batch 265 to 272 is 58.20435428619385
2019-05-22 12:36:35,836 - brc - INFO - Average loss from batch 273 to 280 is 55.01883029937744
2019-05-22 12:36:40,289 - brc - INFO - Average loss from batch 281 to 288 is 50.199119567871094
2019-05-22 12:36:44,814 - brc - INFO - Average loss from batch 289 to 296 is 64.24555540084839
2019-05-22 12:36:49,388 - brc - INFO - Average loss from batch 297 to 304 is 50.98215293884277
2019-05-22 12:38:33,704 - brc - INFO - ====== training ======
2019-05-22 12:38:33,704 - brc - INFO - Load data_set and vocab...
2019-05-22 12:38:47,436 - brc - INFO - Train set size: 4353 questions.
2019-05-22 12:38:54,703 - brc - INFO - Dev set size: 5000 questions.
2019-05-22 12:38:54,703 - brc - INFO - Converting text into ids...
2019-05-22 12:39:08,116 - brc - INFO - Initialize the model...
2019-05-22 12:39:15,316 - brc - INFO - Time to build graph: 5.790539979934692 s
2019-05-22 12:39:25,676 - brc - INFO - Training the model...
2019-05-22 12:39:43,169 - brc - INFO - Training the model for epoch 1
2019-05-22 12:40:47,075 - brc - INFO - Average loss from batch 1 to 100 is 89.04564712524414
2019-05-22 12:41:44,906 - brc - INFO - Average loss from batch 101 to 200 is 78.43255275726318
2019-05-22 12:42:42,845 - brc - INFO - Average loss from batch 201 to 300 is 74.66323307037354
2019-05-22 12:43:42,064 - brc - INFO - Average loss from batch 301 to 400 is 73.59731868743897
2019-05-22 12:44:43,290 - brc - INFO - Average loss from batch 401 to 500 is 68.97973163604736
2019-05-22 12:45:10,200 - brc - INFO - Average train loss for epoch 1 is 76.4677377798978
2019-05-22 12:45:10,201 - brc - INFO - Evaluating the model after epoch 1
2019-05-22 12:49:02,460 - brc - INFO - Dev eval loss 1.4272000408185568e+30
2019-05-22 12:49:02,460 - brc - INFO - Dev eval result: {'Bleu-1': 6.36935412364485e-10, 'Bleu-2': 5.21297756101551e-10, 'Bleu-3': 4.4866903192385996e-10, 'Bleu-4': 4.0233645463017645e-10, 'Rouge-L': 0.05240409112542463}
2019-05-22 12:49:14,347 - brc - INFO - Model saved in data\models, with prefix r-net.
2019-05-22 12:49:15,031 - brc - INFO - Training the model for epoch 2
2019-05-22 12:50:16,391 - brc - INFO - Average loss from batch 1 to 100 is 68.38803035736083
2019-05-22 12:51:17,375 - brc - INFO - Average loss from batch 101 to 200 is 67.42619312286376
2019-05-22 12:52:18,125 - brc - INFO - Average loss from batch 201 to 300 is 65.1740860748291
2019-05-22 12:53:19,677 - brc - INFO - Average loss from batch 301 to 400 is 65.97540996551514
2019-05-22 12:54:20,486 - brc - INFO - Average loss from batch 401 to 500 is 66.24515399932861
2019-05-22 12:54:47,369 - brc - INFO - Average train loss for epoch 2 is 66.62475296329049
2019-05-22 12:54:47,369 - brc - INFO - Evaluating the model after epoch 2
2019-05-22 12:58:39,007 - brc - INFO - Dev eval loss 1.4272000408185568e+30
2019-05-22 12:58:39,008 - brc - INFO - Dev eval result: {'Bleu-1': 2.686310339826812e-09, 'Bleu-2': 2.206984680278849e-09, 'Bleu-3': 1.917875224270886e-09, 'Bleu-4': 1.7330583151694197e-09, 'Rouge-L': 0.057801419953503616}
2019-05-22 12:58:52,304 - brc - INFO - Model saved in data\models, with prefix r-net.
2019-05-22 12:58:53,004 - brc - INFO - Training the model for epoch 3
2019-05-22 12:59:54,146 - brc - INFO - Average loss from batch 1 to 100 is 65.65808086395263
2019-05-22 13:00:55,428 - brc - INFO - Average loss from batch 101 to 200 is 64.35449253082275
2019-05-22 13:01:56,666 - brc - INFO - Average loss from batch 201 to 300 is 65.78027423858643
2019-05-22 13:02:58,273 - brc - INFO - Average loss from batch 301 to 400 is 63.61372745513916
2019-05-22 13:03:59,807 - brc - INFO - Average loss from batch 401 to 500 is 63.72156776428223
2019-05-22 13:04:26,726 - brc - INFO - Average train loss for epoch 3 is 64.4225945893456
2019-05-22 13:04:26,726 - brc - INFO - Evaluating the model after epoch 3
2019-05-22 13:08:20,789 - brc - INFO - Dev eval loss 1.4272000408185568e+30
2019-05-22 13:08:20,789 - brc - INFO - Dev eval result: {'Bleu-1': 6.532209545003114e-06, 'Bleu-2': 5.270825066261315e-06, 'Bleu-3': 4.580140200594642e-06, 'Bleu-4': 4.169781493270812e-06, 'Rouge-L': 0.07534753283964818}
2019-05-22 13:08:33,691 - brc - INFO - Model saved in data\models, with prefix r-net.
2019-05-22 13:08:34,379 - brc - INFO - Training the model for epoch 4
2019-05-22 13:09:35,390 - brc - INFO - Average loss from batch 1 to 100 is 63.73233963012695
2019-05-22 13:10:36,754 - brc - INFO - Average loss from batch 101 to 200 is 63.30116291046143
2019-05-22 13:11:37,648 - brc - INFO - Average loss from batch 201 to 300 is 62.319938812255856
2019-05-22 13:12:39,586 - brc - INFO - Average loss from batch 301 to 400 is 63.88490577697754
2019-05-22 13:13:40,706 - brc - INFO - Average loss from batch 401 to 500 is 64.05432437896728
2019-05-22 13:14:07,658 - brc - INFO - Average train loss for epoch 4 is 63.40307159984813
2019-05-22 13:14:07,659 - brc - INFO - Evaluating the model after epoch 4
2019-05-22 13:18:00,911 - brc - INFO - Dev eval loss 1.4272000408185568e+30
2019-05-22 13:18:00,911 - brc - INFO - Dev eval result: {'Bleu-1': 4.60872161050801e-05, 'Bleu-2': 3.7305994011078386e-05, 'Bleu-3': 3.250980188187805e-05, 'Bleu-4': 2.9600340341409458e-05, 'Rouge-L': 0.08297683898800207}
2019-05-22 13:18:13,908 - brc - INFO - Model saved in data\models, with prefix r-net.
2019-05-22 13:18:14,592 - brc - INFO - Training the model for epoch 5
2019-05-22 13:19:16,053 - brc - INFO - Average loss from batch 1 to 100 is 63.598304443359375
2019-05-22 13:20:17,033 - brc - INFO - Average loss from batch 101 to 200 is 63.12489833831787
2019-05-22 13:21:18,197 - brc - INFO - Average loss from batch 201 to 300 is 59.73604125976563
2019-05-22 13:22:19,280 - brc - INFO - Average loss from batch 301 to 400 is 62.55476957321167
2019-05-22 13:23:20,776 - brc - INFO - Average loss from batch 401 to 500 is 61.93209487915039
2019-05-22 13:23:47,541 - brc - INFO - Average train loss for epoch 5 is 62.15787967864205
2019-05-22 13:23:47,541 - brc - INFO - Evaluating the model after epoch 5
2019-05-22 13:27:40,228 - brc - INFO - Dev eval loss 1.4272000408185568e+30
2019-05-22 13:27:40,228 - brc - INFO - Dev eval result: {'Bleu-1': 1.8769435905961513e-05, 'Bleu-2': 1.5193947865958618e-05, 'Bleu-3': 1.3187610341930926e-05, 'Bleu-4': 1.1956878755891793e-05, 'Rouge-L': 0.08007313987626091}
2019-05-22 13:27:41,056 - brc - INFO - Training the model for epoch 6
2019-05-22 13:28:42,499 - brc - INFO - Average loss from batch 1 to 100 is 60.87982051849365
2019-05-22 13:29:44,227 - brc - INFO - Average loss from batch 101 to 200 is 61.63975612640381
2019-05-22 13:30:45,507 - brc - INFO - Average loss from batch 201 to 300 is 60.22964000701904
2019-05-22 13:31:46,548 - brc - INFO - Average loss from batch 301 to 400 is 61.02388816833496
2019-05-22 13:32:47,810 - brc - INFO - Average loss from batch 401 to 500 is 59.56660060882568
2019-05-22 13:33:14,728 - brc - INFO - Average train loss for epoch 6 is 60.84803527242997
2019-05-22 13:33:14,729 - brc - INFO - Evaluating the model after epoch 6
2019-05-22 13:37:09,420 - brc - INFO - Dev eval loss 1.4272000408185568e+30
2019-05-22 13:37:09,420 - brc - INFO - Dev eval result: {'Bleu-1': 1.733381368363077e-05, 'Bleu-2': 1.3963390127716307e-05, 'Bleu-3': 1.2105421695201438e-05, 'Bleu-4': 1.0985165139207978e-05, 'Rouge-L': 0.07414466446361122}
2019-05-22 13:37:10,623 - brc - INFO - Training the model for epoch 7
2019-05-22 13:38:11,849 - brc - INFO - Average loss from batch 1 to 100 is 60.38253307342529
2019-05-22 13:39:13,008 - brc - INFO - Average loss from batch 101 to 200 is 59.5989909362793
2019-05-22 13:40:13,962 - brc - INFO - Average loss from batch 201 to 300 is 61.2302124786377
2019-05-22 13:41:15,038 - brc - INFO - Average loss from batch 301 to 400 is 58.40295742034912
2019-05-22 13:42:15,886 - brc - INFO - Average loss from batch 401 to 500 is 59.60163997650147
2019-05-22 13:42:42,780 - brc - INFO - Average train loss for epoch 7 is 60.07873282011818
2019-05-22 13:42:42,780 - brc - INFO - Evaluating the model after epoch 7
2019-05-22 13:46:36,208 - brc - INFO - Dev eval loss 1.4272000408185568e+30
2019-05-22 13:46:36,208 - brc - INFO - Dev eval result: {'Bleu-1': 0.00023510626400906072, 'Bleu-2': 0.0001903067552972381, 'Bleu-3': 0.00016587057802797863, 'Bleu-4': 0.00015107222199838556, 'Rouge-L': 0.0803397818546183}
2019-05-22 13:46:37,395 - brc - INFO - Training the model for epoch 8
2019-05-22 13:47:38,689 - brc - INFO - Average loss from batch 1 to 100 is 59.93729507446289
2019-05-22 13:48:40,050 - brc - INFO - Average loss from batch 101 to 200 is 58.0086350440979
2019-05-22 13:49:41,023 - brc - INFO - Average loss from batch 201 to 300 is 58.50449798583984
2019-05-22 13:50:42,041 - brc - INFO - Average loss from batch 301 to 400 is 59.12199230194092
2019-05-24 20:41:32,629 - brc - INFO - ====== training ======
2019-05-24 20:41:32,629 - brc - INFO - Load data_set and vocab...
2019-05-24 20:41:46,538 - brc - INFO - Train set size: 4353 questions.
2019-05-24 20:41:53,761 - brc - INFO - Dev set size: 5000 questions.
2019-05-24 20:41:53,761 - brc - INFO - Converting text into ids...
2019-05-24 20:42:07,207 - brc - INFO - Initialize the model...
2019-05-24 20:43:52,288 - brc - INFO - ====== training ======
2019-05-24 20:43:52,288 - brc - INFO - Load data_set and vocab...
2019-05-24 20:43:58,569 - brc - INFO - Train set size: 4353 questions.
2019-05-24 20:44:05,839 - brc - INFO - Dev set size: 5000 questions.
2019-05-24 20:44:05,839 - brc - INFO - Converting text into ids...
2019-05-24 20:44:20,528 - brc - INFO - Initialize the model...
2019-05-24 20:44:30,497 - brc - INFO - Time to build graph: 9.28964352607727 s
2019-05-24 20:44:53,163 - brc - INFO - Training the model...
2019-05-24 20:48:46,182 - brc - INFO - ====== training ======
2019-05-24 20:48:46,182 - brc - INFO - Load data_set and vocab...
2019-05-24 20:48:52,284 - brc - INFO - Train set size: 4353 questions.
2019-05-24 20:48:59,617 - brc - INFO - Dev set size: 5000 questions.
2019-05-24 20:48:59,617 - brc - INFO - Converting text into ids...
2019-05-24 20:49:13,244 - brc - INFO - Initialize the model...
2019-05-24 20:49:19,929 - brc - INFO - Time to build graph: 6.031871557235718 s
2019-05-24 20:49:30,884 - brc - INFO - Training the model...
2019-05-24 20:49:49,764 - brc - INFO - Training the model for epoch 1
2019-05-24 20:50:53,906 - brc - INFO - Average loss from batch 1 to 100 is 91.84775756835937
2019-05-24 20:51:46,611 - brc - INFO - Average loss from batch 101 to 200 is 79.393247756958
2019-05-24 20:52:39,305 - brc - INFO - Average loss from batch 201 to 300 is 75.67795997619629
2019-05-24 20:53:35,870 - brc - INFO - Average loss from batch 301 to 400 is 72.95977146148681
2019-05-24 20:54:32,433 - brc - INFO - Average loss from batch 401 to 500 is 70.72258472442627
2019-05-24 20:54:57,373 - brc - INFO - Average train loss for epoch 1 is 77.06214604658238
2019-05-24 20:54:57,683 - brc - INFO - Evaluating the model after epoch 1
2019-05-24 21:15:16,700 - brc - INFO - ====== training ======
2019-05-24 21:15:16,700 - brc - INFO - Load data_set and vocab...
2019-05-24 21:15:22,960 - brc - INFO - Train set size: 4353 questions.
2019-05-24 21:15:30,397 - brc - INFO - Dev set size: 5000 questions.
2019-05-24 21:15:30,397 - brc - INFO - Converting text into ids...
2019-05-24 21:15:44,261 - brc - INFO - Initialize the model...
2019-05-24 21:15:50,884 - brc - INFO - Time to build graph: 5.972034215927124 s
2019-05-24 21:16:01,616 - brc - INFO - Training the model...
2019-05-24 21:16:18,628 - brc - INFO - Training the model for epoch 1
2019-05-24 21:17:26,879 - brc - INFO - ====== training ======
2019-05-24 21:17:26,879 - brc - INFO - Load data_set and vocab...
2019-05-24 21:17:33,029 - brc - INFO - Train set size: 4353 questions.
2019-05-24 21:17:40,378 - brc - INFO - Dev set size: 5000 questions.
2019-05-24 21:17:40,378 - brc - INFO - Converting text into ids...
2019-05-24 21:17:53,990 - brc - INFO - Initialize the model...
2019-05-24 21:18:00,680 - brc - INFO - Time to build graph: 6.034865379333496 s
2019-05-24 21:18:11,342 - brc - INFO - Training the model...
2019-05-24 21:18:29,542 - brc - INFO - Training the model for epoch 1
2019-05-24 21:19:32,985 - brc - INFO - Average loss from batch 1 to 100 is 89.7864567565918
2019-05-24 21:20:26,973 - brc - INFO - Average loss from batch 101 to 200 is 79.52004005432129
2019-05-24 21:21:20,711 - brc - INFO - Average loss from batch 201 to 300 is 75.39159839630128
2019-05-24 21:22:18,024 - brc - INFO - Average loss from batch 301 to 400 is 72.70015140533447
2019-05-24 21:23:15,831 - brc - INFO - Average loss from batch 401 to 500 is 68.6886754989624
2019-05-24 21:23:40,940 - brc - INFO - Average train loss for epoch 1 is 76.64767724626205
2019-05-24 21:23:41,019 - brc - INFO - Evaluating the model after epoch 1
2019-05-24 21:33:34,089 - brc - INFO - ====== training ======
2019-05-24 21:33:34,089 - brc - INFO - Load data_set and vocab...
2019-05-24 21:33:40,165 - brc - INFO - Train set size: 4353 questions.
2019-05-24 21:33:47,517 - brc - INFO - Dev set size: 5000 questions.
2019-05-24 21:33:47,517 - brc - INFO - Converting text into ids...
2019-05-24 21:34:01,098 - brc - INFO - Initialize the model...
2019-05-24 21:34:07,614 - brc - INFO - Time to build graph: 5.8673131465911865 s
2019-05-24 21:34:18,138 - brc - INFO - Training the model...
2019-05-24 21:34:35,234 - brc - INFO - Training the model for epoch 1
2019-05-24 21:52:09,665 - brc - INFO - ====== training ======
2019-05-24 21:52:09,665 - brc - INFO - Load data_set and vocab...
2019-05-24 21:52:15,798 - brc - INFO - Train set size: 4353 questions.
2019-05-24 21:52:23,169 - brc - INFO - Dev set size: 5000 questions.
2019-05-24 21:52:23,170 - brc - INFO - Converting text into ids...
2019-05-24 21:52:36,996 - brc - INFO - Initialize the model...
2019-05-24 21:52:43,610 - brc - INFO - Time to build graph: 5.955078840255737 s
2019-05-24 21:52:54,266 - brc - INFO - Training the model...
2019-05-24 21:53:13,401 - brc - INFO - Training the model for epoch 1
2019-05-24 21:54:09,941 - brc - INFO - ====== training ======
2019-05-24 21:54:09,941 - brc - INFO - Load data_set and vocab...
2019-05-24 21:54:16,114 - brc - INFO - Train set size: 4353 questions.
2019-05-24 21:54:23,414 - brc - INFO - Dev set size: 5000 questions.
2019-05-24 21:54:23,414 - brc - INFO - Converting text into ids...
2019-05-24 21:54:37,054 - brc - INFO - Initialize the model...
2019-05-24 21:54:44,135 - brc - INFO - Time to build graph: 6.430110692977905 s
2019-05-24 21:54:54,612 - brc - INFO - Training the model...
2019-05-24 21:55:13,082 - brc - INFO - Training the model for epoch 1
2019-05-24 21:56:00,660 - brc - INFO - ====== training ======
2019-05-24 21:56:00,660 - brc - INFO - Load data_set and vocab...
2019-05-24 21:56:06,929 - brc - INFO - Train set size: 4353 questions.
2019-05-24 21:56:14,427 - brc - INFO - Dev set size: 5000 questions.
2019-05-24 21:56:14,427 - brc - INFO - Converting text into ids...
2019-05-24 21:57:17,300 - brc - INFO - ====== training ======
2019-05-24 21:57:17,300 - brc - INFO - Load data_set and vocab...
2019-05-24 21:57:23,394 - brc - INFO - Train set size: 4353 questions.
2019-05-24 21:57:30,704 - brc - INFO - Dev set size: 5000 questions.
2019-05-24 21:57:30,704 - brc - INFO - Converting text into ids...
2019-05-24 21:57:44,409 - brc - INFO - Initialize the model...
2019-05-24 21:57:50,992 - brc - INFO - Time to build graph: 5.932142734527588 s
2019-05-24 21:58:01,471 - brc - INFO - Training the model...
2019-05-24 21:58:19,319 - brc - INFO - Training the model for epoch 1
2019-05-24 21:59:47,001 - brc - INFO - ====== training ======
2019-05-24 21:59:47,001 - brc - INFO - Load data_set and vocab...
2019-05-24 22:00:36,766 - brc - INFO - ====== training ======
2019-05-24 22:00:36,766 - brc - INFO - Load data_set and vocab...
2019-05-24 22:00:42,882 - brc - INFO - Train set size: 4353 questions.
2019-05-24 22:00:50,238 - brc - INFO - Dev set size: 5000 questions.
2019-05-24 22:00:50,238 - brc - INFO - Converting text into ids...
2019-05-24 22:01:03,881 - brc - INFO - Initialize the model...
2019-05-24 22:01:10,508 - brc - INFO - Time to build graph: 5.984967231750488 s
2019-05-24 22:01:21,188 - brc - INFO - Training the model...
2019-05-24 22:01:38,863 - brc - INFO - Training the model for epoch 1
2019-05-24 22:02:39,502 - brc - INFO - Average loss from batch 1 to 100 is 91.3790548324585
2019-05-24 22:03:32,548 - brc - INFO - Average loss from batch 101 to 200 is 79.67282234191894
2019-05-24 22:04:25,449 - brc - INFO - Average loss from batch 201 to 300 is 75.36171844482422
2019-05-24 22:05:21,663 - brc - INFO - Average loss from batch 301 to 400 is 69.43757858276368
2019-05-24 22:06:18,388 - brc - INFO - Average loss from batch 401 to 500 is 69.5612886428833
2019-05-24 22:06:43,406 - brc - INFO - Average train loss for epoch 1 is 76.10816029941334
2019-05-24 22:06:43,406 - brc - INFO - Evaluating the model after epoch 1
2019-05-24 22:12:17,762 - brc - INFO - ====== training ======
2019-05-24 22:12:17,762 - brc - INFO - Load data_set and vocab...
2019-05-24 22:12:23,903 - brc - INFO - Train set size: 4353 questions.
2019-05-24 22:12:31,209 - brc - INFO - Dev set size: 5000 questions.
2019-05-24 22:12:31,209 - brc - INFO - Converting text into ids...
2019-05-24 22:12:44,832 - brc - INFO - Initialize the model...
2019-05-24 22:12:51,358 - brc - INFO - Time to build graph: 5.878281593322754 s
2019-05-24 22:13:01,808 - brc - INFO - Training the model...
2019-05-24 22:13:18,484 - brc - INFO - Training the model for epoch 1
2019-05-24 22:14:17,458 - brc - INFO - Average loss from batch 1 to 100 is 90.63739784240722
2019-05-24 22:15:10,524 - brc - INFO - Average loss from batch 101 to 200 is 81.40492374420165
2019-05-24 22:16:03,890 - brc - INFO - Average loss from batch 201 to 300 is 74.39252662658691
2019-05-24 22:17:00,446 - brc - INFO - Average loss from batch 301 to 400 is 68.82763832092286
2019-05-24 22:17:57,108 - brc - INFO - Average loss from batch 401 to 500 is 68.20688331604003
2019-05-24 22:18:22,287 - brc - INFO - Average train loss for epoch 1 is 76.2360856813543
2019-05-24 22:18:22,287 - brc - INFO - Evaluating the model after epoch 1
2019-05-24 22:20:05,112 - brc - INFO - ====== training ======
2019-05-24 22:20:05,112 - brc - INFO - Load data_set and vocab...
2019-05-24 22:20:11,285 - brc - INFO - Train set size: 4353 questions.
2019-05-24 22:20:18,621 - brc - INFO - Dev set size: 5000 questions.
2019-05-24 22:20:18,621 - brc - INFO - Converting text into ids...
2019-05-24 22:20:32,322 - brc - INFO - Initialize the model...
2019-05-24 22:20:38,887 - brc - INFO - Time to build graph: 5.916211843490601 s
2019-05-24 22:20:49,454 - brc - INFO - Training the model...
2019-05-24 22:21:07,532 - brc - INFO - Training the model for epoch 1
2019-05-24 22:22:06,801 - brc - INFO - Average loss from batch 1 to 100 is 89.58734420776368
2019-05-24 22:23:00,638 - brc - INFO - Average loss from batch 101 to 200 is 77.61068408966065
2019-05-24 22:23:57,047 - brc - INFO - Average loss from batch 201 to 300 is 76.72745853424072
2019-05-24 22:24:53,814 - brc - INFO - Average loss from batch 301 to 400 is 73.43196773529053
2019-05-24 22:25:50,648 - brc - INFO - Average loss from batch 401 to 500 is 71.29791381835938
2019-05-24 22:26:15,624 - brc - INFO - Average train loss for epoch 1 is 76.94655413487378
2019-05-24 22:26:15,624 - brc - INFO - Evaluating the model after epoch 1
2019-05-24 22:31:17,140 - brc - INFO - ====== training ======
2019-05-24 22:31:17,140 - brc - INFO - Load data_set and vocab...
2019-05-24 22:31:23,280 - brc - INFO - Train set size: 4353 questions.
2019-05-24 22:31:30,627 - brc - INFO - Dev set size: 5000 questions.
2019-05-24 22:31:30,628 - brc - INFO - Converting text into ids...
2019-05-24 22:31:44,301 - brc - INFO - Initialize the model...
2019-05-24 22:31:50,946 - brc - INFO - Time to build graph: 5.994972229003906 s
2019-05-24 22:32:01,681 - brc - INFO - Training the model...
2019-05-24 22:32:20,511 - brc - INFO - Training the model for epoch 1
2019-05-24 22:33:20,078 - brc - INFO - Average loss from batch 1 to 100 is 89.214609375
2019-05-24 22:34:13,112 - brc - INFO - Average loss from batch 101 to 200 is 80.99761745452881
2019-05-24 22:34:48,672 - brc - INFO - ====== training ======
2019-05-24 22:34:48,672 - brc - INFO - Load data_set and vocab...
2019-05-24 22:34:54,914 - brc - INFO - Train set size: 4353 questions.
2019-05-24 22:35:02,401 - brc - INFO - Dev set size: 5000 questions.
2019-05-24 22:35:02,401 - brc - INFO - Converting text into ids...
2019-05-24 22:35:16,314 - brc - INFO - Initialize the model...
2019-05-24 22:35:22,989 - brc - INFO - Time to build graph: 6.030875205993652 s
2019-05-24 22:35:33,522 - brc - INFO - Training the model...
2019-05-24 22:35:51,765 - brc - INFO - Training the model for epoch 1
2019-05-24 22:36:54,667 - brc - INFO - Average loss from batch 1 to 100 is 88.31726516723633
2019-05-24 22:37:51,008 - brc - INFO - Average loss from batch 101 to 200 is 79.13310123443604
2019-05-24 22:38:47,821 - brc - INFO - Average loss from batch 201 to 300 is 76.19953315734864
2019-05-24 22:39:44,344 - brc - INFO - Average loss from batch 301 to 400 is 74.81983890533448
2019-05-24 22:40:40,735 - brc - INFO - Average loss from batch 401 to 500 is 69.7086234664917
2019-05-24 22:41:05,900 - brc - INFO - Average train loss for epoch 1 is 76.94984674453735
2019-05-24 22:41:05,900 - brc - INFO - Evaluating the model after epoch 1
2019-05-24 22:42:32,207 - brc - INFO - ====== training ======
2019-05-24 22:42:32,207 - brc - INFO - Load data_set and vocab...
2019-05-24 22:42:38,294 - brc - INFO - Train set size: 4353 questions.
2019-05-24 22:42:45,632 - brc - INFO - Dev set size: 5000 questions.
2019-05-24 22:42:45,632 - brc - INFO - Converting text into ids...
2019-05-24 22:42:59,220 - brc - INFO - Initialize the model...
2019-05-24 22:43:05,765 - brc - INFO - Time to build graph: 5.885265111923218 s
2019-05-24 22:43:16,191 - brc - INFO - Training the model...
2019-05-24 22:43:33,932 - brc - INFO - Training the model for epoch 1
2019-05-24 22:46:43,539 - brc - INFO - ====== training ======
2019-05-24 22:46:43,539 - brc - INFO - Load data_set and vocab...
2019-05-24 22:46:49,626 - brc - INFO - Train set size: 4353 questions.
2019-05-24 22:46:56,961 - brc - INFO - Dev set size: 5000 questions.
2019-05-24 22:46:56,961 - brc - INFO - Converting text into ids...
2019-05-24 22:47:10,505 - brc - INFO - Initialize the model...
2019-05-24 22:47:17,039 - brc - INFO - Time to build graph: 5.8832714557647705 s
2019-05-24 22:47:27,434 - brc - INFO - Training the model...
2019-05-24 22:47:44,871 - brc - INFO - Training the model for epoch 1
2019-05-24 22:48:43,788 - brc - INFO - Average loss from batch 1 to 100 is 89.45936073303223
2019-05-24 22:49:36,892 - brc - INFO - Average loss from batch 101 to 200 is 82.62249454498291
2019-05-24 22:50:31,705 - brc - INFO - Average loss from batch 201 to 300 is 76.03805568695068
2019-05-24 22:51:28,294 - brc - INFO - Average loss from batch 301 to 400 is 73.3659663772583
2019-05-24 22:52:24,839 - brc - INFO - Average loss from batch 401 to 500 is 74.01192279815673
2019-05-24 22:52:49,988 - brc - INFO - Average train loss for epoch 1 is 78.19109617962556
2019-05-24 22:52:49,988 - brc - INFO - Evaluating the model after epoch 1
2019-05-24 22:57:19,049 - brc - INFO - Dev eval loss 1.4272000408185568e+30
2019-05-24 22:57:19,049 - brc - INFO - Dev eval result: {'Bleu-1': 4.694958243215299e-12, 'Bleu-2': 3.853480858684745e-12, 'Bleu-3': 3.2531511793034277e-12, 'Bleu-4': 2.867806232036346e-12, 'Rouge-L': 0.02025723515477632}
2019-05-24 22:57:31,906 - brc - INFO - Model saved in data\models, with prefix r-net.
2019-05-24 22:57:32,623 - brc - INFO - Training the model for epoch 2
2019-05-24 22:58:29,402 - brc - INFO - Average loss from batch 1 to 100 is 69.73952739715577
2019-05-24 22:59:25,686 - brc - INFO - Average loss from batch 101 to 200 is 67.29088306427002
2019-05-24 23:00:22,562 - brc - INFO - Average loss from batch 201 to 300 is 69.0642639541626
2019-05-24 23:01:19,323 - brc - INFO - Average loss from batch 301 to 400 is 65.87214485168457
2019-05-24 23:02:15,902 - brc - INFO - Average loss from batch 401 to 500 is 66.8572566986084
2019-05-24 23:02:40,653 - brc - INFO - Average train loss for epoch 2 is 67.41421078934388
2019-05-24 23:02:40,653 - brc - INFO - Evaluating the model after epoch 2
2019-05-24 23:07:10,920 - brc - INFO - Dev eval loss 1.4272000408185568e+30
2019-05-24 23:07:10,920 - brc - INFO - Dev eval result: {'Bleu-1': 5.871753424681885e-14, 'Bleu-2': 4.607336356218735e-14, 'Bleu-3': 3.9309775032014545e-14, 'Bleu-4': 3.4706428122416556e-14, 'Rouge-L': 0.02558330811994837}
2019-05-24 23:07:24,756 - brc - INFO - Model saved in data\models, with prefix r-net.
2019-05-24 23:07:25,485 - brc - INFO - Training the model for epoch 3
2019-05-24 23:08:22,069 - brc - INFO - Average loss from batch 1 to 100 is 67.03781158447265
2019-05-24 23:09:18,646 - brc - INFO - Average loss from batch 101 to 200 is 66.04587898254394
2019-05-24 23:10:15,083 - brc - INFO - Average loss from batch 201 to 300 is 64.51821701049805
2019-05-24 23:11:11,588 - brc - INFO - Average loss from batch 301 to 400 is 65.57768283843994
2019-05-24 23:12:08,252 - brc - INFO - Average loss from batch 401 to 500 is 63.02623168945313
2019-05-24 23:12:33,338 - brc - INFO - Average train loss for epoch 3 is 65.0860268719056
2019-05-24 23:12:33,338 - brc - INFO - Evaluating the model after epoch 3
2019-05-24 23:17:07,201 - brc - INFO - Dev eval loss 1.4272000408185568e+30
2019-05-24 23:17:07,201 - brc - INFO - Dev eval result: {'Bleu-1': 0.00439390576456891, 'Bleu-2': 0.0030158012784098237, 'Bleu-3': 0.0023904816100109466, 'Bleu-4': 0.0020503903583401666, 'Rouge-L': 0.056703771306887134}
2019-05-24 23:17:21,656 - brc - INFO - Model saved in data\models, with prefix r-net.
2019-05-24 23:17:22,349 - brc - INFO - Training the model for epoch 4
2019-05-24 23:18:18,749 - brc - INFO - Average loss from batch 1 to 100 is 65.60736236572265
2019-05-24 23:19:15,272 - brc - INFO - Average loss from batch 101 to 200 is 64.856280708313
2019-05-24 23:20:11,726 - brc - INFO - Average loss from batch 201 to 300 is 63.608215522766116
2019-05-24 23:21:08,260 - brc - INFO - Average loss from batch 301 to 400 is 62.94568042755127
2019-05-24 23:22:04,537 - brc - INFO - Average loss from batch 401 to 500 is 63.37747207641601
2019-05-24 23:22:30,079 - brc - INFO - Average train loss for epoch 4 is 63.770010471343994
2019-05-24 23:22:30,079 - brc - INFO - Evaluating the model after epoch 4
2019-05-24 23:27:04,866 - brc - INFO - Dev eval loss 1.4272000408185568e+30
2019-05-24 23:27:04,866 - brc - INFO - Dev eval result: {'Bleu-1': 0.022947714393138443, 'Bleu-2': 0.015798563033008552, 'Bleu-3': 0.012582238274814386, 'Bleu-4': 0.010839797868914964, 'Rouge-L': 0.09203727909738167}
2019-05-24 23:27:16,145 - brc - INFO - Model saved in data\models, with prefix r-net.
2019-05-24 23:27:16,848 - brc - INFO - Training the model for epoch 5
2019-05-24 23:28:13,556 - brc - INFO - Average loss from batch 1 to 100 is 62.930894737243655
2019-05-25 08:42:26,423 - brc - INFO - ====== training ======
2019-05-25 08:42:26,438 - brc - INFO - Load data_set and vocab...
2019-05-25 08:56:40,756 - brc - INFO - Train set size: 83646 questions.
2019-05-25 09:03:28,715 - brc - INFO - Dev set size: 5000 questions.
2019-05-25 09:03:28,803 - brc - INFO - Converting text into ids...
2019-05-25 09:23:43,249 - brc - INFO - ====== training ======
2019-05-25 09:23:43,249 - brc - INFO - Load data_set and vocab...
2019-05-25 09:23:57,317 - brc - INFO - Train set size: 4353 questions.
2019-05-25 09:24:04,718 - brc - INFO - Dev set size: 5000 questions.
2019-05-25 09:24:04,718 - brc - INFO - Converting text into ids...
2019-05-25 09:24:18,492 - brc - INFO - Initialize the model...
2019-05-25 09:24:26,734 - brc - INFO - Time to build graph: 6.951078414916992 s
2019-05-25 09:24:37,880 - brc - INFO - Training the model...
2019-05-25 09:24:55,126 - brc - INFO - Training the model for epoch 1
2019-05-25 09:30:21,399 - brc - INFO - Average train loss for epoch 1 is 77.22505950226503
2019-05-25 09:30:21,400 - brc - INFO - Evaluating the model after epoch 1
2019-05-25 09:34:59,524 - brc - INFO - Dev eval loss 1.4272000408185568e+30
2019-05-25 09:34:59,525 - brc - INFO - Dev eval result: {'Bleu-1': 4.3122647548918825e-09, 'Bleu-2': 3.4397335620686768e-09, 'Bleu-3': 3.004554868954801e-09, 'Bleu-4': 2.8035096361100165e-09, 'Rouge-L': 0.03341700108373835}
2019-05-25 09:35:10,876 - brc - INFO - Model saved in data\models, with prefix r-net.
2019-05-25 09:35:11,571 - brc - INFO - Training the model for epoch 2
2019-05-25 09:40:45,323 - brc - INFO - Average train loss for epoch 2 is 67.33619471858529
2019-05-25 09:40:45,323 - brc - INFO - Evaluating the model after epoch 2
2019-05-25 09:45:24,770 - brc - INFO - Dev eval loss 1.4272000408185568e+30
2019-05-25 09:45:24,770 - brc - INFO - Dev eval result: {'Bleu-1': 2.2848349090452276e-09, 'Bleu-2': 1.5982457976326648e-09, 'Bleu-3': 1.2883540884701915e-09, 'Bleu-4': 1.1103019947201233e-09, 'Rouge-L': 0.031737388412028326}
2019-05-25 09:45:25,439 - brc - INFO - Training the model for epoch 3
2019-05-25 09:50:59,296 - brc - INFO - Average train loss for epoch 3 is 64.74819822171155
2019-05-25 09:50:59,296 - brc - INFO - Evaluating the model after epoch 3
2019-05-25 09:55:42,811 - brc - INFO - Dev eval loss 1.4272000408185568e+30
2019-05-25 09:55:42,811 - brc - INFO - Dev eval result: {'Bleu-1': 0.0017174868828001735, 'Bleu-2': 0.0011914867738303215, 'Bleu-3': 0.000955645910485461, 'Bleu-4': 0.0008258857676747239, 'Rouge-L': 0.0656339912360089}
2019-05-25 09:55:56,487 - brc - INFO - Model saved in data\models, with prefix r-net.
2019-05-25 09:55:57,177 - brc - INFO - Training the model for epoch 4
2019-05-25 10:01:36,167 - brc - INFO - Average train loss for epoch 4 is 62.45447852331049
2019-05-25 10:01:36,167 - brc - INFO - Evaluating the model after epoch 4
2019-05-25 10:06:27,942 - brc - INFO - Dev eval loss 1.4272000408185568e+30
2019-05-25 10:06:27,942 - brc - INFO - Dev eval result: {'Bleu-1': 0.013198725929548901, 'Bleu-2': 0.008858511934550176, 'Bleu-3': 0.007004296389759763, 'Bleu-4': 0.006003493548994768, 'Rouge-L': 0.07052606455865133}
2019-05-25 10:06:41,970 - brc - INFO - Model saved in data\models, with prefix r-net.
2019-05-25 10:06:42,661 - brc - INFO - Training the model for epoch 5
2019-05-25 10:12:17,209 - brc - INFO - Average train loss for epoch 5 is 61.24640337158652
2019-05-25 10:12:17,209 - brc - INFO - Evaluating the model after epoch 5
2019-05-25 10:17:09,638 - brc - INFO - Dev eval loss 1.4272000408185568e+30
2019-05-25 10:17:09,639 - brc - INFO - Dev eval result: {'Bleu-1': 0.06615668583941636, 'Bleu-2': 0.04546124564424519, 'Bleu-3': 0.03601965633326675, 'Bleu-4': 0.030890610503140844, 'Rouge-L': 0.09426001593045388}
2019-05-25 10:17:20,892 - brc - INFO - Model saved in data\models, with prefix r-net.
2019-05-25 10:17:21,576 - brc - INFO - Training the model for epoch 6
2019-05-25 10:22:57,402 - brc - INFO - Average train loss for epoch 6 is 60.607132638201996
2019-05-25 10:22:57,402 - brc - INFO - Evaluating the model after epoch 6
2019-05-25 10:28:01,870 - brc - INFO - Dev eval loss 1.4272000408185568e+30
2019-05-25 10:28:01,870 - brc - INFO - Dev eval result: {'Bleu-1': 0.14190670861894136, 'Bleu-2': 0.09943843822575721, 'Bleu-3': 0.07981781932231274, 'Bleu-4': 0.06907316024186054, 'Rouge-L': 0.10173063781911047}
2019-05-25 10:28:16,097 - brc - INFO - Model saved in data\models, with prefix r-net.
2019-05-25 10:28:16,798 - brc - INFO - Training the model for epoch 7
2019-05-25 10:33:51,601 - brc - INFO - Average train loss for epoch 7 is 59.88262642131132
2019-05-25 10:33:51,601 - brc - INFO - Evaluating the model after epoch 7
2019-05-25 10:38:49,253 - brc - INFO - Dev eval loss 1.4272000408185568e+30
2019-05-25 10:38:49,253 - brc - INFO - Dev eval result: {'Bleu-1': 0.08282611769761129, 'Bleu-2': 0.0563584025581119, 'Bleu-3': 0.044472085597994336, 'Bleu-4': 0.03802543315040233, 'Rouge-L': 0.09617646188940289}
2019-05-25 10:38:49,980 - brc - INFO - Training the model for epoch 8
2019-05-25 10:44:24,735 - brc - INFO - Average train loss for epoch 8 is 59.17136551352108
2019-05-25 10:44:24,735 - brc - INFO - Evaluating the model after epoch 8
2019-05-25 10:49:17,945 - brc - INFO - Dev eval loss 1.4272000408185568e+30
2019-05-25 10:49:17,945 - brc - INFO - Dev eval result: {'Bleu-1': 0.06121466502649541, 'Bleu-2': 0.043554921458804435, 'Bleu-3': 0.03530885874061155, 'Bleu-4': 0.030784023539839667, 'Rouge-L': 0.08718395636529457}
2019-05-25 10:49:18,647 - brc - INFO - Training the model for epoch 9
2019-05-25 10:54:53,021 - brc - INFO - Average train loss for epoch 9 is 58.87266317886465
2019-05-25 10:54:53,021 - brc - INFO - Evaluating the model after epoch 9
2019-05-25 10:59:50,834 - brc - INFO - Dev eval loss 1.4272000408185568e+30
2019-05-25 10:59:50,834 - brc - INFO - Dev eval result: {'Bleu-1': 0.1448957511814363, 'Bleu-2': 0.10192786426854664, 'Bleu-3': 0.08210872105261043, 'Bleu-4': 0.07124047288418967, 'Rouge-L': 0.11200539808879172}
2019-05-25 11:00:04,391 - brc - INFO - Model saved in data\models, with prefix r-net.
2019-05-25 11:00:05,082 - brc - INFO - Training the model for epoch 10
2019-05-25 11:05:40,492 - brc - INFO - Average train loss for epoch 10 is 58.51966155276579
2019-05-25 11:05:40,492 - brc - INFO - Evaluating the model after epoch 10
2019-05-25 11:10:29,287 - brc - INFO - Dev eval loss 1.4272000408185568e+30
2019-05-25 11:10:29,287 - brc - INFO - Dev eval result: {'Bleu-1': 0.02290166780974827, 'Bleu-2': 0.015650317167943677, 'Bleu-3': 0.012447630201820449, 'Bleu-4': 0.010726784340586206, 'Rouge-L': 0.07995789483095252}
2019-05-25 11:10:30,021 - brc - INFO - Training the model for epoch 11
2019-05-25 11:16:04,128 - brc - INFO - Average train loss for epoch 11 is 58.07162957331713
2019-05-25 11:16:04,128 - brc - INFO - Evaluating the model after epoch 11
2019-05-25 11:21:01,031 - brc - INFO - Dev eval loss 1.4272000408185568e+30
2019-05-25 11:21:01,031 - brc - INFO - Dev eval result: {'Bleu-1': 0.10506548588226305, 'Bleu-2': 0.07308294256959683, 'Bleu-3': 0.05844717638909675, 'Bleu-4': 0.050420586269094556, 'Rouge-L': 0.09859999453515873}
2019-05-25 11:21:01,721 - brc - INFO - Training the model for epoch 12
2019-05-25 11:26:38,695 - brc - INFO - Average train loss for epoch 12 is 57.80440836093005
2019-05-25 11:26:38,695 - brc - INFO - Evaluating the model after epoch 12
2019-05-25 11:31:52,030 - brc - INFO - Dev eval loss 1.4272000408185568e+30
2019-05-25 11:31:52,031 - brc - INFO - Dev eval result: {'Bleu-1': 0.21591256819053103, 'Bleu-2': 0.15431973463594675, 'Bleu-3': 0.12480894547559514, 'Bleu-4': 0.10844954655240607, 'Rouge-L': 0.11724435089675471}
2019-05-25 11:32:07,548 - brc - INFO - Model saved in data\models, with prefix r-net.
2019-05-25 11:32:08,367 - brc - INFO - Training the model for epoch 13
2019-05-25 11:37:51,970 - brc - INFO - Average train loss for epoch 13 is 57.45921868436477
2019-05-25 11:37:51,971 - brc - INFO - Evaluating the model after epoch 13
2019-05-25 11:43:02,748 - brc - INFO - Dev eval loss 1.4272000408185568e+30
2019-05-25 11:43:02,748 - brc - INFO - Dev eval result: {'Bleu-1': 0.15079733067230136, 'Bleu-2': 0.10734492234748269, 'Bleu-3': 0.08699493163392177, 'Bleu-4': 0.07575869603012741, 'Rouge-L': 0.11745856649068427}
2019-05-25 11:43:17,400 - brc - INFO - Model saved in data\models, with prefix r-net.
2019-05-25 11:43:18,203 - brc - INFO - Training the model for epoch 14
2019-05-25 11:49:04,106 - brc - INFO - Average train loss for epoch 14 is 57.14628069190418
2019-05-25 11:49:04,106 - brc - INFO - Evaluating the model after epoch 14
2019-05-25 11:54:10,496 - brc - INFO - Dev eval loss 1.4272000408185568e+30
2019-05-25 11:54:10,496 - brc - INFO - Dev eval result: {'Bleu-1': 0.10090011668400213, 'Bleu-2': 0.0708147910903643, 'Bleu-3': 0.05684544295302803, 'Bleu-4': 0.049275017055178304, 'Rouge-L': 0.09509410319697922}
2019-05-25 11:54:11,284 - brc - INFO - Training the model for epoch 15
2019-05-25 11:59:57,144 - brc - INFO - Average train loss for epoch 15 is 57.23150156175389
2019-05-25 11:59:57,144 - brc - INFO - Evaluating the model after epoch 15
2019-05-25 12:05:01,638 - brc - INFO - Dev eval loss 1.4272000408185568e+30
2019-05-25 12:05:01,639 - brc - INFO - Dev eval result: {'Bleu-1': 0.09809764243949742, 'Bleu-2': 0.06975727514081563, 'Bleu-3': 0.056404093125504616, 'Bleu-4': 0.04908068430710387, 'Rouge-L': 0.09315248955814813}
2019-05-25 12:05:02,452 - brc - INFO - Training the model for epoch 16
2019-05-25 12:10:47,846 - brc - INFO - Average train loss for epoch 16 is 56.94367969036102
2019-05-25 12:10:47,846 - brc - INFO - Evaluating the model after epoch 16
2019-05-25 12:15:43,108 - brc - INFO - Dev eval loss 1.4272000408185568e+30
2019-05-25 12:15:43,108 - brc - INFO - Dev eval result: {'Bleu-1': 0.0026796048468320835, 'Bleu-2': 0.0016878549919383708, 'Bleu-3': 0.0012755894474964417, 'Bleu-4': 0.0010584485407754037, 'Rouge-L': 0.05160301254308482}
2019-05-25 12:15:43,913 - brc - INFO - Training the model for epoch 17
2019-05-25 12:21:29,410 - brc - INFO - Average train loss for epoch 17 is 57.04743832700393
2019-05-25 12:21:29,411 - brc - INFO - Evaluating the model after epoch 17
2019-05-25 12:26:24,395 - brc - INFO - Dev eval loss 1.4272000408185568e+30
2019-05-25 12:26:24,396 - brc - INFO - Dev eval result: {'Bleu-1': 0.012205216162021783, 'Bleu-2': 0.008647402375829396, 'Bleu-3': 0.006987145983748143, 'Bleu-4': 0.006067679907325418, 'Rouge-L': 0.07607780647045376}
2019-05-25 12:26:25,188 - brc - INFO - Training the model for epoch 18
2019-05-25 12:32:10,515 - brc - INFO - Average train loss for epoch 18 is 56.43284134654438
2019-05-25 12:32:10,515 - brc - INFO - Evaluating the model after epoch 18
2019-05-25 18:01:23,458 - brc - INFO - ====== training ======
2019-05-25 18:01:23,467 - brc - INFO - Load data_set and vocab...
2019-05-25 18:01:39,289 - brc - INFO - Train set size: 4353 questions.
2019-05-25 18:01:47,688 - brc - INFO - Dev set size: 5000 questions.
2019-05-25 18:01:47,688 - brc - INFO - Converting text into ids...
2019-05-25 18:02:03,432 - brc - INFO - Initialize the model...
2019-05-25 18:02:26,541 - brc - INFO - Time to build graph: 8.08459186553955 s
2019-05-25 18:02:47,323 - brc - INFO - Training the model...
2019-05-25 18:03:07,003 - brc - INFO - Training the model for epoch 1
2019-05-25 18:08:18,885 - brc - INFO - Average train loss for epoch 1 is 76.05048058313481
2019-05-25 18:08:18,885 - brc - INFO - Evaluating the model after epoch 1
2019-05-25 18:12:53,655 - brc - INFO - Dev eval loss 1.4272000408185568e+30
2019-05-25 18:12:53,656 - brc - INFO - Dev eval result: {'Bleu-1': 2.499211944152163e-12, 'Bleu-2': 1.9611086976154996e-12, 'Bleu-3': 1.701802601301763e-12, 'Bleu-4': 1.5378500217325836e-12, 'Rouge-L': 0.030382862581751713}
2019-05-25 18:13:06,532 - brc - INFO - Model saved in data\models, with prefix r-net.
2019-05-25 18:13:07,330 - brc - INFO - Training the model for epoch 2
2019-05-25 18:18:23,889 - brc - INFO - Average train loss for epoch 2 is 67.13105179983027
2019-05-25 18:18:23,889 - brc - INFO - Evaluating the model after epoch 2
2019-05-25 18:23:00,145 - brc - INFO - Dev eval loss 1.4272000408185568e+30
2019-05-25 18:23:00,145 - brc - INFO - Dev eval result: {'Bleu-1': 4.6721191773562993e-08, 'Bleu-2': 3.005922527079372e-08, 'Bleu-3': 2.272869062060262e-08, 'Bleu-4': 1.8738283764135192e-08, 'Rouge-L': 0.031053784304543943}
2019-05-25 18:23:14,695 - brc - INFO - Model saved in data\models, with prefix r-net.
2019-05-25 18:23:15,481 - brc - INFO - Training the model for epoch 3
2019-05-25 18:28:31,854 - brc - INFO - Average train loss for epoch 3 is 65.27788224641014
2019-05-25 18:28:31,854 - brc - INFO - Evaluating the model after epoch 3
2019-05-25 18:33:09,814 - brc - INFO - Dev eval loss 1.4272000408185568e+30
2019-05-25 18:33:09,814 - brc - INFO - Dev eval result: {'Bleu-1': 0.0045485242735848535, 'Bleu-2': 0.0031354695969684123, 'Bleu-3': 0.002502231392264138, 'Bleu-4': 0.0021542099692346884, 'Rouge-L': 0.08021745979130991}
2019-05-25 18:33:24,830 - brc - INFO - Model saved in data\models, with prefix r-net.
2019-05-25 18:33:25,639 - brc - INFO - Training the model for epoch 4
2019-05-25 18:38:41,435 - brc - INFO - Average train loss for epoch 4 is 63.675903383423304
2019-05-25 18:38:41,435 - brc - INFO - Evaluating the model after epoch 4
2019-05-25 18:43:41,701 - brc - INFO - Dev eval loss 1.4272000408185568e+30
2019-05-25 18:43:41,701 - brc - INFO - Dev eval result: {'Bleu-1': 0.2070901478072634, 'Bleu-2': 0.1471775478457959, 'Bleu-3': 0.11926228517661168, 'Bleu-4': 0.10399883384453382, 'Rouge-L': 0.11004611776337571}
2019-05-25 18:43:54,216 - brc - INFO - Model saved in data\models, with prefix r-net.
2019-05-25 18:43:55,023 - brc - INFO - Training the model for epoch 5
2019-05-25 18:49:11,290 - brc - INFO - Average train loss for epoch 5 is 61.97200287089628
2019-05-25 18:49:11,290 - brc - INFO - Evaluating the model after epoch 5
2019-05-25 18:53:49,419 - brc - INFO - Dev eval loss 1.4272000408185568e+30
2019-05-25 18:53:49,419 - brc - INFO - Dev eval result: {'Bleu-1': 0.004025350952008008, 'Bleu-2': 0.0028573465264419584, 'Bleu-3': 0.002331631802006394, 'Bleu-4': 0.0020476172291286473, 'Rouge-L': 0.07163210559346886}
2019-05-25 18:53:50,208 - brc - INFO - Training the model for epoch 6
2019-05-25 18:58:56,793 - brc - INFO - Average train loss for epoch 6 is 60.556973814964294
2019-05-25 18:58:56,793 - brc - INFO - Evaluating the model after epoch 6
2019-05-25 19:03:28,747 - brc - INFO - Dev eval loss 1.4272000408185568e+30
2019-05-25 19:03:28,747 - brc - INFO - Dev eval result: {'Bleu-1': 0.053884847287112535, 'Bleu-2': 0.03813393005908449, 'Bleu-3': 0.030810814035583365, 'Bleu-4': 0.026804515194844766, 'Rouge-L': 0.09413722952953132}
2019-05-25 19:03:29,417 - brc - INFO - Training the model for epoch 7
2019-05-25 19:08:35,054 - brc - INFO - Average train loss for epoch 7 is 60.078698337078094
2019-05-25 19:08:35,054 - brc - INFO - Evaluating the model after epoch 7
2019-05-25 19:13:01,427 - brc - INFO - Dev eval loss 1.4272000408185568e+30
2019-05-25 19:13:01,427 - brc - INFO - Dev eval result: {'Bleu-1': 0.010101518132421489, 'Bleu-2': 0.0071208199841080394, 'Bleu-3': 0.005791114809612685, 'Bleu-4': 0.005072307081725356, 'Rouge-L': 0.06148215358687986}
2019-05-25 19:13:02,092 - brc - INFO - Training the model for epoch 8
2019-05-25 19:18:07,792 - brc - INFO - Average train loss for epoch 8 is 59.33419431658352
2019-05-25 19:18:07,792 - brc - INFO - Evaluating the model after epoch 8
2019-05-25 19:22:55,531 - brc - INFO - Dev eval loss 1.4272000408185568e+30
2019-05-25 19:22:55,531 - brc - INFO - Dev eval result: {'Bleu-1': 0.23630589324237997, 'Bleu-2': 0.17091491150671295, 'Bleu-3': 0.1397587986299194, 'Bleu-4': 0.12244383391245268, 'Rouge-L': 0.11186485089676058}
2019-05-25 19:23:08,494 - brc - INFO - Model saved in data\models, with prefix r-net.
2019-05-25 19:23:09,164 - brc - INFO - Training the model for epoch 9
2019-05-25 19:28:14,732 - brc - INFO - Average train loss for epoch 9 is 58.97972048380796
2019-05-25 19:28:14,732 - brc - INFO - Evaluating the model after epoch 9
2019-05-25 19:32:49,949 - brc - INFO - Dev eval loss 1.4272000408185568e+30
2019-05-25 19:32:49,949 - brc - INFO - Dev eval result: {'Bleu-1': 0.0992148528076514, 'Bleu-2': 0.06953329332857855, 'Bleu-3': 0.055550007163274934, 'Bleu-4': 0.047906434967718396, 'Rouge-L': 0.08968707109124928}
2019-05-25 19:32:50,882 - brc - INFO - Training the model for epoch 10
2019-05-25 19:37:56,374 - brc - INFO - Average train loss for epoch 10 is 58.5537747074576
2019-05-25 19:37:56,374 - brc - INFO - Evaluating the model after epoch 10
2019-05-25 19:42:30,989 - brc - INFO - Dev eval loss 1.4272000408185568e+30
2019-05-25 19:42:30,990 - brc - INFO - Dev eval result: {'Bleu-1': 0.10453569765523359, 'Bleu-2': 0.07358596339071308, 'Bleu-3': 0.0592000916550565, 'Bleu-4': 0.05135046444550282, 'Rouge-L': 0.09985533897628916}
2019-05-25 19:42:31,922 - brc - INFO - Training the model for epoch 11
2019-05-25 19:47:37,372 - brc - INFO - Average train loss for epoch 11 is 58.14039946303648
2019-05-25 19:47:37,373 - brc - INFO - Evaluating the model after epoch 11
2019-05-25 19:52:07,612 - brc - INFO - Dev eval loss 1.4272000408185568e+30
2019-05-25 19:52:07,613 - brc - INFO - Dev eval result: {'Bleu-1': 0.04246795502849334, 'Bleu-2': 0.02956190657895076, 'Bleu-3': 0.023519758059112644, 'Bleu-4': 0.020204327855366393, 'Rouge-L': 0.09368335353982238}
2019-05-25 19:52:08,285 - brc - INFO - Training the model for epoch 12
2019-05-25 19:57:13,387 - brc - INFO - Average train loss for epoch 12 is 57.908540816868054
2019-05-25 19:57:13,388 - brc - INFO - Evaluating the model after epoch 12
2019-05-25 20:01:37,336 - brc - INFO - Dev eval loss 1.4272000408185568e+30
2019-05-25 20:01:37,336 - brc - INFO - Dev eval result: {'Bleu-1': 0.00046544896036979154, 'Bleu-2': 0.000333591176700862, 'Bleu-3': 0.0002713732150644127, 'Bleu-4': 0.00023658571729656574, 'Rouge-L': 0.06178116749998235}
2019-05-25 20:01:38,016 - brc - INFO - Training the model for epoch 13
2019-05-25 20:06:43,047 - brc - INFO - Average train loss for epoch 13 is 57.66631671961616
2019-05-25 20:06:43,047 - brc - INFO - Evaluating the model after epoch 13
2019-05-25 20:11:13,488 - brc - INFO - Dev eval loss 1.4272000408185568e+30
2019-05-25 20:11:13,488 - brc - INFO - Dev eval result: {'Bleu-1': 0.036678680374891526, 'Bleu-2': 0.02530688041435686, 'Bleu-3': 0.020105382385698676, 'Bleu-4': 0.01728882929514596, 'Rouge-L': 0.07964353576898558}
2019-05-25 20:11:14,161 - brc - INFO - Training the model for epoch 14
2019-05-25 20:16:19,508 - brc - INFO - Average train loss for epoch 14 is 57.57032787799835
2019-05-25 20:16:19,508 - brc - INFO - Evaluating the model after epoch 14
2019-05-25 20:20:51,264 - brc - INFO - Dev eval loss 1.4272000408185568e+30
2019-05-25 20:20:51,264 - brc - INFO - Dev eval result: {'Bleu-1': 0.054751085457122664, 'Bleu-2': 0.03842390714902043, 'Bleu-3': 0.030712082598861573, 'Bleu-4': 0.026451811368081446, 'Rouge-L': 0.08654144365679697}
2019-05-25 20:20:51,928 - brc - INFO - Training the model for epoch 15
2019-05-25 20:25:57,553 - brc - INFO - Average train loss for epoch 15 is 57.466733038425446
2019-05-25 20:25:57,553 - brc - INFO - Evaluating the model after epoch 15
2019-05-25 20:30:23,586 - brc - INFO - Dev eval loss 1.4272000408185568e+30
2019-05-25 20:30:23,586 - brc - INFO - Dev eval result: {'Bleu-1': 0.005153744202183131, 'Bleu-2': 0.003592551199004115, 'Bleu-3': 0.002859080874905466, 'Bleu-4': 0.0024663089786907404, 'Rouge-L': 0.0723878923742672}
2019-05-25 20:30:24,275 - brc - INFO - Training the model for epoch 16
2019-05-25 20:35:29,689 - brc - INFO - Average train loss for epoch 16 is 57.18876941765056
2019-05-25 20:35:29,689 - brc - INFO - Evaluating the model after epoch 16
2019-05-25 20:39:56,127 - brc - INFO - Dev eval loss 1.4272000408185568e+30
2019-05-25 20:39:56,127 - brc - INFO - Dev eval result: {'Bleu-1': 0.0073087783583059614, 'Bleu-2': 0.004983177261529471, 'Bleu-3': 0.003908951938596104, 'Bleu-4': 0.00332061334196301, 'Rouge-L': 0.07603284768904663}
2019-05-25 20:39:56,796 - brc - INFO - Training the model for epoch 17
2019-05-25 20:45:02,101 - brc - INFO - Average train loss for epoch 17 is 56.68157412374721
2019-05-25 20:45:02,102 - brc - INFO - Evaluating the model after epoch 17
2019-05-25 20:49:25,608 - brc - INFO - Dev eval loss 1.4272000408185568e+30
2019-05-25 20:49:25,608 - brc - INFO - Dev eval result: {'Bleu-1': 0.0001606727761489881, 'Bleu-2': 0.00010963782111264834, 'Bleu-3': 8.743113479932974e-05, 'Bleu-4': 7.539282050416206e-05, 'Rouge-L': 0.049477603582017825}
2019-05-25 20:49:26,279 - brc - INFO - Training the model for epoch 18
2019-05-25 20:54:31,782 - brc - INFO - Average train loss for epoch 18 is 56.78354875831043
2019-05-25 20:54:31,782 - brc - INFO - Evaluating the model after epoch 18
2019-05-25 20:58:59,249 - brc - INFO - Dev eval loss 1.4272000408185568e+30
2019-05-25 20:58:59,249 - brc - INFO - Dev eval result: {'Bleu-1': 0.00632980290230749, 'Bleu-2': 0.004275934330388781, 'Bleu-3': 0.0033309951188157136, 'Bleu-4': 0.002805743312459308, 'Rouge-L': 0.07442909127063166}
2019-05-25 20:58:59,916 - brc - INFO - Training the model for epoch 19
2019-05-27 09:25:16,152 - brc - INFO - ====== training ======
2019-05-27 09:25:16,152 - brc - INFO - Load data_set and vocab...
2019-05-27 09:25:30,178 - brc - INFO - Train set size: 4353 questions.
2019-05-27 09:25:37,688 - brc - INFO - Dev set size: 5000 questions.
2019-05-27 09:25:37,688 - brc - INFO - Converting text into ids...
2019-05-27 09:25:51,478 - brc - INFO - Initialize the model...
2019-05-27 09:26:12,080 - brc - INFO - Time to build graph: 7.209993124008179 s
2019-05-27 09:26:31,573 - brc - INFO - Training the model...
2019-05-27 09:26:49,300 - brc - INFO - Training the model for epoch 1
2019-05-27 09:32:17,432 - brc - INFO - Average train loss for epoch 1 is 76.02774403375737
2019-05-27 09:32:17,432 - brc - INFO - Evaluating the model after epoch 1
2019-05-27 09:36:57,759 - brc - INFO - Dev eval loss 1.4272000408185568e+30
2019-05-27 09:36:57,759 - brc - INFO - Dev eval result: {'Bleu-1': 0.00017964077109742155, 'Bleu-2': 0.00012481995461591382, 'Bleu-3': 9.893318039523496e-05, 'Bleu-4': 8.49299050651274e-05, 'Rouge-L': 0.051627952090267056}
2019-05-27 09:37:11,249 - brc - INFO - Model saved in data\models, with prefix r-net.
2019-05-27 09:37:12,110 - brc - INFO - Training the model for epoch 2
2019-05-27 09:42:51,897 - brc - INFO - Average train loss for epoch 2 is 66.58507091157577
2019-05-27 09:42:51,897 - brc - INFO - Evaluating the model after epoch 2
2019-05-27 09:47:48,878 - brc - INFO - Dev eval loss 1.4272000408185568e+30
2019-05-27 09:47:48,878 - brc - INFO - Dev eval result: {'Bleu-1': 0.0026806149556129824, 'Bleu-2': 0.0018260104276396146, 'Bleu-3': 0.001428313810302364, 'Bleu-4': 0.0012042750576403377, 'Rouge-L': 0.0791474106972834}
2019-05-27 09:48:04,377 - brc - INFO - Model saved in data\models, with prefix r-net.
2019-05-27 09:48:05,237 - brc - INFO - Training the model for epoch 3
2019-05-27 09:53:51,987 - brc - INFO - Average train loss for epoch 3 is 64.73779858561123
2019-05-27 09:53:51,987 - brc - INFO - Evaluating the model after epoch 3
2019-05-27 09:58:57,091 - brc - INFO - Dev eval loss 1.4272000408185568e+30
2019-05-27 09:58:57,091 - brc - INFO - Dev eval result: {'Bleu-1': 0.07927779432566144, 'Bleu-2': 0.05594019873329108, 'Bleu-3': 0.044923733927238176, 'Bleu-4': 0.03877103371739421, 'Rouge-L': 0.11014427104826262}
2019-05-27 09:59:11,727 - brc - INFO - Model saved in data\models, with prefix r-net.
2019-05-27 09:59:12,562 - brc - INFO - Training the model for epoch 4
2019-05-27 10:04:58,529 - brc - INFO - Average train loss for epoch 4 is 63.15355734264149
2019-05-27 10:04:58,529 - brc - INFO - Evaluating the model after epoch 4
2019-05-27 10:09:57,378 - brc - INFO - Dev eval loss 1.4272000408185568e+30
2019-05-27 10:09:57,378 - brc - INFO - Dev eval result: {'Bleu-1': 0.02787125275588521, 'Bleu-2': 0.019348087445066626, 'Bleu-3': 0.015391111435197112, 'Bleu-4': 0.013169693625256716, 'Rouge-L': 0.09354875448442872}
2019-05-27 10:09:58,208 - brc - INFO - Training the model for epoch 5
2019-05-27 10:15:44,929 - brc - INFO - Average train loss for epoch 5 is 61.77185780861799
2019-05-27 10:15:44,929 - brc - INFO - Evaluating the model after epoch 5
2019-05-27 10:20:43,675 - brc - INFO - Dev eval loss 1.4272000408185568e+30
2019-05-27 10:20:43,675 - brc - INFO - Dev eval result: {'Bleu-1': 0.04469951472261231, 'Bleu-2': 0.03167010086982266, 'Bleu-3': 0.025540957543059274, 'Bleu-4': 0.02214662146112992, 'Rouge-L': 0.09450977530239556}
2019-05-27 10:20:44,509 - brc - INFO - Training the model for epoch 6
2019-05-27 10:26:31,040 - brc - INFO - Average train loss for epoch 6 is 61.00560886018417
2019-05-27 10:26:31,040 - brc - INFO - Evaluating the model after epoch 6
2019-05-27 10:31:30,562 - brc - INFO - Dev eval loss 1.4272000408185568e+30
2019-05-27 10:31:30,563 - brc - INFO - Dev eval result: {'Bleu-1': 0.03149729188553981, 'Bleu-2': 0.02219906699135115, 'Bleu-3': 0.017828384970390104, 'Bleu-4': 0.015401318582960519, 'Rouge-L': 0.0988320796589688}
2019-05-27 10:31:31,383 - brc - INFO - Training the model for epoch 7
2019-05-27 10:37:18,229 - brc - INFO - Average train loss for epoch 7 is 60.407343703157764
2019-05-27 10:37:18,229 - brc - INFO - Evaluating the model after epoch 7
2019-05-27 10:42:00,664 - brc - INFO - Dev eval loss 1.4272000408185568e+30
2019-05-27 10:42:00,664 - brc - INFO - Dev eval result: {'Bleu-1': 0.04967428814415652, 'Bleu-2': 0.03510593969705925, 'Bleu-3': 0.028262027539638752, 'Bleu-4': 0.024442872018259287, 'Rouge-L': 0.10035525462188491}
2019-05-27 10:42:01,363 - brc - INFO - Training the model for epoch 8
2019-05-27 10:47:09,887 - brc - INFO - Average train loss for epoch 8 is 59.70974840136135
2019-05-27 10:47:09,887 - brc - INFO - Evaluating the model after epoch 8
2019-05-27 10:51:50,646 - brc - INFO - Dev eval loss 1.4272000408185568e+30
2019-05-27 10:51:50,646 - brc - INFO - Dev eval result: {'Bleu-1': 0.13408108631788743, 'Bleu-2': 0.09549405825054566, 'Bleu-3': 0.07713352940449313, 'Bleu-4': 0.06685315431035037, 'Rouge-L': 0.11582111755964121}
2019-05-27 10:52:04,417 - brc - INFO - Model saved in data\models, with prefix r-net.
2019-05-27 10:52:05,110 - brc - INFO - Training the model for epoch 9
2019-05-27 10:57:13,851 - brc - INFO - Average train loss for epoch 9 is 59.43007297375623
2019-05-27 10:57:13,851 - brc - INFO - Evaluating the model after epoch 9
2019-05-27 11:01:41,923 - brc - INFO - Dev eval loss 1.4272000408185568e+30
2019-05-27 11:01:41,923 - brc - INFO - Dev eval result: {'Bleu-1': 0.00706864939198009, 'Bleu-2': 0.0049700215235906516, 'Bleu-3': 0.004001113514453728, 'Bleu-4': 0.0034613987494725488, 'Rouge-L': 0.0830778863393346}
2019-05-27 11:01:42,626 - brc - INFO - Training the model for epoch 10
2019-05-27 11:06:51,313 - brc - INFO - Average train loss for epoch 10 is 58.84825259797714
2019-05-27 11:06:51,313 - brc - INFO - Evaluating the model after epoch 10
2019-05-27 11:11:23,754 - brc - INFO - Dev eval loss 1.4272000408185568e+30
2019-05-27 11:11:23,754 - brc - INFO - Dev eval result: {'Bleu-1': 0.046982827298996874, 'Bleu-2': 0.033184750484927084, 'Bleu-3': 0.026843218697880013, 'Bleu-4': 0.0233441882697038, 'Rouge-L': 0.09406523240614723}
2019-05-27 11:11:24,449 - brc - INFO - Training the model for epoch 11
2019-05-27 11:16:32,864 - brc - INFO - Average train loss for epoch 11 is 58.55304817592396
2019-05-27 11:16:32,865 - brc - INFO - Evaluating the model after epoch 11
2019-05-27 11:21:06,193 - brc - INFO - Dev eval loss 1.4272000408185568e+30
2019-05-27 11:21:06,193 - brc - INFO - Dev eval result: {'Bleu-1': 0.06283421819282135, 'Bleu-2': 0.04338408849974711, 'Bleu-3': 0.034713371468335676, 'Bleu-4': 0.030018724619000764, 'Rouge-L': 0.09487090347231392}
2019-05-27 11:21:06,891 - brc - INFO - Training the model for epoch 12
2019-05-27 11:26:15,775 - brc - INFO - Average train loss for epoch 12 is 58.19673725436716
2019-05-27 11:26:15,775 - brc - INFO - Evaluating the model after epoch 12
2019-05-27 11:30:47,839 - brc - INFO - Dev eval loss 1.4272000408185568e+30
2019-05-27 11:30:47,839 - brc - INFO - Dev eval result: {'Bleu-1': 0.051486950978821305, 'Bleu-2': 0.03682786932886404, 'Bleu-3': 0.030128975431717074, 'Bleu-4': 0.02648290559402741, 'Rouge-L': 0.0918213274873414}
2019-05-27 11:30:48,535 - brc - INFO - Training the model for epoch 13
2019-05-27 11:35:56,870 - brc - INFO - Average train loss for epoch 13 is 57.828269958496094
2019-05-27 11:35:56,870 - brc - INFO - Evaluating the model after epoch 13
2019-05-27 11:40:26,462 - brc - INFO - Dev eval loss 1.4272000408185568e+30
2019-05-27 11:40:26,462 - brc - INFO - Dev eval result: {'Bleu-1': 0.022608889232709744, 'Bleu-2': 0.01600014123486789, 'Bleu-3': 0.01295957999833507, 'Bleu-4': 0.011302639606504817, 'Rouge-L': 0.08526982702885566}
2019-05-27 11:40:27,415 - brc - INFO - Training the model for epoch 14
2019-05-27 11:45:35,633 - brc - INFO - Average train loss for epoch 14 is 57.73362301377689
2019-05-27 11:45:35,633 - brc - INFO - Evaluating the model after epoch 14
2019-05-27 11:50:23,674 - brc - INFO - Dev eval loss 1.4272000408185568e+30
2019-05-27 11:50:23,674 - brc - INFO - Dev eval result: {'Bleu-1': 0.0373993150701595, 'Bleu-2': 0.026864582048881296, 'Bleu-3': 0.022038131684391397, 'Bleu-4': 0.01940853592101916, 'Rouge-L': 0.09012777392570646}
2019-05-27 11:50:24,537 - brc - INFO - Training the model for epoch 15
2019-05-27 11:56:06,352 - brc - INFO - Average train loss for epoch 15 is 57.59504906219595
2019-05-27 11:56:06,354 - brc - INFO - Evaluating the model after epoch 15
2019-05-27 12:01:05,280 - brc - INFO - Dev eval loss 1.4272000408185568e+30
2019-05-27 12:01:05,280 - brc - INFO - Dev eval result: {'Bleu-1': 0.058702451343938464, 'Bleu-2': 0.041748881870401953, 'Bleu-3': 0.033789866537862076, 'Bleu-4': 0.029429829757563204, 'Rouge-L': 0.08279435647248991}
2019-05-27 12:01:06,093 - brc - INFO - Training the model for epoch 16
2019-05-27 12:06:40,775 - brc - INFO - Average train loss for epoch 16 is 57.57134506982916
2019-05-27 12:06:40,775 - brc - INFO - Evaluating the model after epoch 16
2019-05-27 12:12:00,385 - brc - INFO - Dev eval loss 1.4272000408185568e+30
2019-05-27 12:12:00,387 - brc - INFO - Dev eval result: {'Bleu-1': 0.2876296504020152, 'Bleu-2': 0.2107068131737575, 'Bleu-3': 0.17309584554625784, 'Bleu-4': 0.15211024019405664, 'Rouge-L': 0.11027866473405314}
2019-05-27 12:12:01,260 - brc - INFO - Training the model for epoch 17
2019-05-27 12:17:37,478 - brc - INFO - Average train loss for epoch 17 is 57.30527488273733
2019-05-27 12:17:37,478 - brc - INFO - Evaluating the model after epoch 17
2019-05-27 12:22:43,086 - brc - INFO - Dev eval loss 1.4272000408185568e+30
2019-05-27 12:22:43,087 - brc - INFO - Dev eval result: {'Bleu-1': 0.18447547318740135, 'Bleu-2': 0.13330334744146335, 'Bleu-3': 0.1090487407618468, 'Bleu-4': 0.09570180966604527, 'Rouge-L': 0.11376592388299822}
2019-05-27 12:22:43,829 - brc - INFO - Training the model for epoch 18
2019-05-27 12:28:17,790 - brc - INFO - Average train loss for epoch 18 is 57.08610216309042
2019-05-27 12:28:17,790 - brc - INFO - Evaluating the model after epoch 18
2019-05-27 12:33:34,699 - brc - INFO - Dev eval loss 1.4272000408185568e+30
2019-05-27 12:33:34,699 - brc - INFO - Dev eval result: {'Bleu-1': 0.29728701391925955, 'Bleu-2': 0.21225509184254482, 'Bleu-3': 0.1707818737545363, 'Bleu-4': 0.14775681450121217, 'Rouge-L': 0.11048474722284603}
2019-05-27 12:33:35,448 - brc - INFO - Training the model for epoch 19
2019-05-27 12:39:09,810 - brc - INFO - Average train loss for epoch 19 is 57.12345000224955
2019-05-27 12:39:09,810 - brc - INFO - Evaluating the model after epoch 19
2019-05-27 12:44:00,111 - brc - INFO - Dev eval loss 1.4272000408185568e+30
2019-05-27 12:44:00,111 - brc - INFO - Dev eval result: {'Bleu-1': 0.047573510991930995, 'Bleu-2': 0.03393662518375865, 'Bleu-3': 0.027551104837500968, 'Bleu-4': 0.02405445406392937, 'Rouge-L': 0.07560567009607363}
2019-05-27 12:44:00,839 - brc - INFO - Training the model for epoch 20
2019-05-27 12:49:40,071 - brc - INFO - Average train loss for epoch 20 is 56.86300515076693
2019-05-27 12:49:40,071 - brc - INFO - Evaluating the model after epoch 20
2019-05-27 12:54:32,230 - brc - INFO - Dev eval loss 1.4272000408185568e+30
2019-05-27 12:54:32,231 - brc - INFO - Dev eval result: {'Bleu-1': 0.022099279705353764, 'Bleu-2': 0.016515677911409815, 'Bleu-3': 0.01377801640252763, 'Bleu-4': 0.012206945095305788, 'Rouge-L': 0.06736799017573877}
2019-05-27 12:54:32,994 - brc - INFO - Training the model for epoch 21
2019-05-27 13:00:14,902 - brc - INFO - Average train loss for epoch 21 is 56.68294791614308
2019-05-27 13:00:14,902 - brc - INFO - Evaluating the model after epoch 21
2019-05-27 13:05:07,863 - brc - INFO - Dev eval loss 1.4272000408185568e+30
2019-05-27 13:05:07,863 - brc - INFO - Dev eval result: {'Bleu-1': 0.03215247520573897, 'Bleu-2': 0.022730667749291344, 'Bleu-3': 0.018382904578938507, 'Bleu-4': 0.016019298322360483, 'Rouge-L': 0.07324622466050462}
2019-05-27 13:05:08,601 - brc - INFO - Training the model for epoch 22
2019-05-27 13:10:51,554 - brc - INFO - Average train loss for epoch 22 is 56.67655933604521
2019-05-27 13:10:51,557 - brc - INFO - Evaluating the model after epoch 22
2019-05-27 13:16:04,254 - brc - INFO - Dev eval loss 1.4272000408185568e+30
2019-05-27 13:16:04,254 - brc - INFO - Dev eval result: {'Bleu-1': 0.16201634991779815, 'Bleu-2': 0.11660711805763305, 'Bleu-3': 0.09458482332947904, 'Bleu-4': 0.08221818109433826, 'Rouge-L': 0.0865180334482523}
2019-05-27 13:16:05,006 - brc - INFO - Training the model for epoch 23
2019-05-27 13:21:42,128 - brc - INFO - Average train loss for epoch 23 is 56.475408915211176
2019-05-27 13:21:42,131 - brc - INFO - Evaluating the model after epoch 23
2019-05-27 13:26:44,692 - brc - INFO - Dev eval loss 1.4272000408185568e+30
2019-05-27 13:26:44,692 - brc - INFO - Dev eval result: {'Bleu-1': 0.11873408074417902, 'Bleu-2': 0.08586625724730237, 'Bleu-3': 0.07017628209308666, 'Bleu-4': 0.06141954522042436, 'Rouge-L': 0.08841042612846893}
2019-05-27 13:26:45,424 - brc - INFO - Training the model for epoch 24
2019-05-27 13:32:19,518 - brc - INFO - Average train loss for epoch 24 is 56.433948674622705
2019-05-27 13:32:19,518 - brc - INFO - Evaluating the model after epoch 24
2019-05-27 13:37:13,817 - brc - INFO - Dev eval loss 1.4272000408185568e+30
2019-05-27 13:37:13,817 - brc - INFO - Dev eval result: {'Bleu-1': 0.08988701221531419, 'Bleu-2': 0.06704660449836439, 'Bleu-3': 0.05589815601920164, 'Bleu-4': 0.04957091852099711, 'Rouge-L': 0.0808213157826422}
2019-05-27 13:37:14,549 - brc - INFO - Training the model for epoch 25
2019-05-27 13:42:48,498 - brc - INFO - Average train loss for epoch 25 is 56.51898582192028
2019-05-27 13:42:48,499 - brc - INFO - Evaluating the model after epoch 25
2019-05-27 13:47:45,588 - brc - INFO - Dev eval loss 1.4272000408185568e+30
2019-05-27 13:47:45,588 - brc - INFO - Dev eval result: {'Bleu-1': 0.13638502881269615, 'Bleu-2': 0.10106809234192386, 'Bleu-3': 0.0838244586445163, 'Bleu-4': 0.07409702502693447, 'Rouge-L': 0.08439337669778768}
2019-05-27 13:47:46,297 - brc - INFO - Training the model for epoch 26
2019-05-27 13:53:20,188 - brc - INFO - Average train loss for epoch 26 is 56.451188771163714
2019-05-27 13:53:20,188 - brc - INFO - Evaluating the model after epoch 26
2019-05-27 13:57:53,310 - brc - INFO - Dev eval loss 1.4272000408185568e+30
2019-05-27 13:57:53,310 - brc - INFO - Dev eval result: {'Bleu-1': 0.0025582684378943747, 'Bleu-2': 0.0018891750014556705, 'Bleu-3': 0.001566168841742331, 'Bleu-4': 0.0013826840443943694, 'Rouge-L': 0.059344239751604695}
2019-05-27 13:57:54,023 - brc - INFO - Training the model for epoch 27
2019-05-27 14:03:15,907 - brc - INFO - Average train loss for epoch 27 is 56.296958825167486
2019-05-27 14:03:15,907 - brc - INFO - Evaluating the model after epoch 27
2019-05-27 14:07:56,856 - brc - INFO - Dev eval loss 1.4272000408185568e+30
2019-05-27 14:07:56,856 - brc - INFO - Dev eval result: {'Bleu-1': 2.5345719834798595e-05, 'Bleu-2': 1.8344873588948036e-05, 'Bleu-3': 1.5057862467685316e-05, 'Bleu-4': 1.3241982677588906e-05, 'Rouge-L': 0.04397639916663659}
2019-05-27 14:07:57,590 - brc - INFO - Training the model for epoch 28
2019-05-27 14:13:31,852 - brc - INFO - Average train loss for epoch 28 is 56.621478641734406
2019-05-27 14:13:31,852 - brc - INFO - Evaluating the model after epoch 28
2019-05-27 14:18:13,213 - brc - INFO - Dev eval loss 1.4272000408185568e+30
2019-05-27 14:18:13,213 - brc - INFO - Dev eval result: {'Bleu-1': 0.0011661384241925697, 'Bleu-2': 0.0008295534282525644, 'Bleu-3': 0.0006700831583758861, 'Bleu-4': 0.0005815393593577912, 'Rouge-L': 0.05973161339820325}
2019-05-27 14:18:13,930 - brc - INFO - Training the model for epoch 29
2019-05-27 14:23:48,581 - brc - INFO - Average train loss for epoch 29 is 56.551268970265106
2019-05-27 14:23:48,581 - brc - INFO - Evaluating the model after epoch 29
2019-05-27 14:28:32,231 - brc - INFO - Dev eval loss 1.4272000408185568e+30
2019-05-27 14:28:32,232 - brc - INFO - Dev eval result: {'Bleu-1': 0.006077310815417949, 'Bleu-2': 0.004258340055892179, 'Bleu-3': 0.0033963505449772155, 'Bleu-4': 0.002928159958713523, 'Rouge-L': 0.0609561820776056}
2019-05-27 14:28:32,938 - brc - INFO - Training the model for epoch 30
2019-05-27 14:33:51,695 - brc - INFO - Average train loss for epoch 30 is 56.490729205748615
2019-05-27 14:33:51,695 - brc - INFO - Evaluating the model after epoch 30
2019-05-27 14:38:20,969 - brc - INFO - Dev eval loss 1.4272000408185568e+30
2019-05-27 14:38:20,969 - brc - INFO - Dev eval result: {'Bleu-1': 0.003715738892221766, 'Bleu-2': 0.002669236222172669, 'Bleu-3': 0.002168192927194459, 'Bleu-4': 0.0018898794078966927, 'Rouge-L': 0.07473425207379061}
2019-05-27 14:38:21,693 - brc - INFO - ====== Done with model training! ======
2019-05-27 15:24:51,728 - brc - INFO - ====== evaluating ======
2019-05-27 15:24:51,728 - brc - INFO - Load data_set and vocab...
2019-05-27 15:25:08,291 - brc - INFO - Dev set size: 5000 questions.
2019-05-27 15:25:08,291 - brc - INFO - Converting text into ids...
2019-05-27 15:25:15,432 - brc - INFO - Restoring the model...
2019-05-27 15:25:20,557 - brc - INFO - Time to build graph: 3.605330228805542 s
2019-05-27 15:31:43,263 - brc - INFO - ====== evaluating ======
2019-05-27 15:31:43,263 - brc - INFO - Load data_set and vocab...
2019-05-27 15:31:51,470 - brc - INFO - Dev set size: 5000 questions.
2019-05-27 15:31:51,470 - brc - INFO - Converting text into ids...
2019-05-27 15:31:58,493 - brc - INFO - Restoring the model...
2019-05-27 15:32:02,481 - brc - INFO - Time to build graph: 3.2832210063934326 s
